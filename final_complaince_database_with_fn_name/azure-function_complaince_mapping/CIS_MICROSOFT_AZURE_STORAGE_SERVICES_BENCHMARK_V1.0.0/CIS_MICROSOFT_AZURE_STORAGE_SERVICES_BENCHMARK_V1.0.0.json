[
  {
    "id": "2.1.1.1",
    "title": "Ensure 'Allowed Protocols' for shared access signature (SAS) tokens is set to 'HTTPS Only'",
    "assessment": "Manual",
    "description": "Shared access signatures (SAS) can be used to grant limited access to Azure Storage resources. When generating a SAS, it is possible to specify the allowed protocols for a request made with the SAS. It is recommended to allow requests over HTTPS only.",
    "rationale": "If a SAS is passed over HTTP and intercepted, an attacker performing a man-in-the- middle attack can read the SAS. Then, they can use that SAS just as the intended user could have. This can potentially compromise sensitive data or allow for data corruption by the malicious user. Impact: SAS can pose security risks if they are not managed carefully.",
    "audit": "",
    "remediation": "Default Value: When generating a SAS, the default selection for Allowed protocols is HTTPS only. References: 1. https://learn.microsoft.com/en-us/azure/storage/common/storage-sas-overview 2. https://learn.microsoft.com/en-us/azure/storage/common/storage-account-keys- manage Additional Information: This recommendation forms the basis for the recommendations with the same title in the following sections: • Azure Blob Storage • Queue Storage • Storage Accounts > Secrets and Keys",
    "profile_applicability": "•  Level 1",
    "impact": "SAS can pose security risks if they are not managed carefully.",
    "references": "1. https://learn.microsoft.com/en-us/azure/storage/common/storage-sas-overview 2. https://learn.microsoft.com/en-us/azure/storage/common/storage-account-keys- manage Additional Information: This recommendation forms the basis for the recommendations with the same title in the following sections: • Azure Blob Storage • Queue Storage • Storage Accounts > Secrets and Keys",
    "function_names": [
      "storage_account_sas_https_only",
      "storage_sas_token_protocol_https",
      "sas_token_allowed_protocols_https",
      "storage_shared_access_https_required",
      "sas_protocol_restriction_https_only"
    ]
  },
  {
    "id": "2.1.1.2",
    "title": "Ensure that shared access signature (SAS) tokens expire within an hour",
    "assessment": "Manual",
    "description": "Shared access signature (SAS) tokens provide restricted access to Azure Storage resources (such as blobs, files, queues, or tables) for a defined time period with specific permissions. It enables users to interact with the resources without exposing account keys, offering precise control over the permitted actions (e.g., read, write) and the duration of access. To minimize security risks, SAS tokens should be configured with the shortest possible lifespan, ideally lasting no longer than an hour.",
    "rationale": "A short lifespan for SAS tokens is recommended to minimize the risk of unauthorized access. SAS tokens grant time-limited access to resources, and a longer duration increases the opportunity for misuse if the token is compromised. By setting a shorter lifespan, the potential for security breaches is reduced. Impact: SAS can pose security risks if they are not managed carefully.",
    "audit": "",
    "remediation": "Default Value: By default, expiration for shared access signature is set to 8 hours. References: 1. https://docs.microsoft.com/en-us/azure/storage/common/storage-sas-overview 2. https://docs.microsoft.com/en-us/rest/api/storageservices/delegating-access- with-a-shared-access-signature Additional Information: This recommendation forms the basis for the recommendations with the same title in the following sections: • Azure Blob Storage • Queue Storage • Storage Accounts > Secrets and Keys • Storage Explorer",
    "profile_applicability": "•  Level 1",
    "impact": "SAS can pose security risks if they are not managed carefully.",
    "references": "1. https://docs.microsoft.com/en-us/azure/storage/common/storage-sas-overview 2. https://docs.microsoft.com/en-us/rest/api/storageservices/delegating-access- with-a-shared-access-signature Additional Information: This recommendation forms the basis for the recommendations with the same title in the following sections: • Azure Blob Storage • Queue Storage • Storage Accounts > Secrets and Keys • Storage Explorer",
    "function_names": [
      "storage_account_sas_token_expiry_within_1h",
      "storage_sas_token_short_lived",
      "storage_sas_token_max_duration_1h",
      "storage_account_sas_token_lifetime_limited",
      "storage_sas_token_expiry_time_restricted"
    ]
  },
  {
    "id": "2.1.1.3",
    "title": "Ensure stored access policies (SAP) are used when generating shared access signature (SAS) tokens",
    "assessment": "Manual",
    "description": "Use stored access policies (SAP) when generating shared access signature (SAS) tokens in Azure to centrally manage permissions, expiration, and revocation settings for resource access. Stored access policies can be applied to blob containers, file shares, queues, and tables.",
    "rationale": "Stored access policies provide centralized control over SAS token access, allowing administrators to update permissions or revoke access. This approach strengthens security by reducing the risk of unauthorized access to storage resources. Impact: There is no cost for creating stored access policies, however there is some administrative overhead involved in managing these policies.",
    "audit": "",
    "remediation": "Default Value: By default, stored access policies are not associated with SAS. To use a stored access policy, it must be explicitly created and linked to the SAS at the time of creation. References: 1. https://learn.microsoft.com/en-us/azure/storage/common/storage-sas- overview#best-practices-when-using-sas 2. https://learn.microsoft.com/en-us/rest/api/storageservices/define-stored-access- policy Additional Information: This recommendation forms the basis for the recommendations with the same title in the following sections: • Azure Blob Storage • Queue Storage • Storage Explorer",
    "profile_applicability": "•  Level 1",
    "impact": "There is no cost for creating stored access policies, however there is some administrative overhead involved in managing these policies.",
    "references": "1. https://learn.microsoft.com/en-us/azure/storage/common/storage-sas- overview#best-practices-when-using-sas 2. https://learn.microsoft.com/en-us/rest/api/storageservices/define-stored-access- policy Additional Information: This recommendation forms the basis for the recommendations with the same title in the following sections: • Azure Blob Storage • Queue Storage • Storage Explorer",
    "function_names": [
      "storage_container_sap_required_for_sas",
      "storage_file_share_sap_required_for_sas",
      "storage_queue_sap_required_for_sas",
      "storage_table_sap_required_for_sas",
      "storage_sas_token_sap_enforced",
      "storage_sas_policy_centralized_management",
      "storage_sas_token_expiration_enforced_via_sap",
      "storage_sas_token_revocation_enabled_via_sap"
    ]
  },
  {
    "id": "2.1.2.1.1",
    "title": "Ensure Critical Data is Encrypted with Microsoft Managed Keys (MMK)",
    "assessment": "Manual",
    "description": "Microsoft Managed Keys (MMK) [also known as Platform-managed keys (PMK)] provides a very low overhead method of encrypting data at rest and implementing encryption key management. Keys maintained in an MMK implementation are automatically managed by Azure and require no customer interaction.",
    "rationale": "The encryption of data at rest is a foundational component of data security. Data at rest without encryption is easily compromised through loss or theft. Encrypting data at rest introduces confidentiality to the data by obfuscating the data contents with a cipher algorithm and provides an authentication requirement through the use of cryptographic keys. MMK makes the encryption of data at rest very easy to implement and maintain.",
    "audit": "",
    "remediation": "Default Value: By default, Encryption type is set to Microsoft Managed Keys. References: 1. https://docs.microsoft.com/en-us/azure/security/fundamentals/data-encryption- best-practices#protect-data-at-rest 2. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-data- protection#dp-5-use-customer-managed-key-option-in-data-at-rest-encryption- when-required 3. https://learn.microsoft.com/en-us/azure/security/fundamentals/key-management",
    "profile_applicability": "•  Level 1",
    "references": "1. https://docs.microsoft.com/en-us/azure/security/fundamentals/data-encryption- best-practices#protect-data-at-rest 2. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-data- protection#dp-5-use-customer-managed-key-option-in-data-at-rest-encryption- when-required 3. https://learn.microsoft.com/en-us/azure/security/fundamentals/key-management",
    "function_names": [
      "storage_account_blob_encryption_enabled",
      "storage_account_file_encryption_enabled",
      "storage_account_table_encryption_enabled",
      "storage_account_queue_encryption_enabled",
      "storage_account_mmk_encryption_enabled",
      "storage_account_platform_managed_key_enabled",
      "storage_account_data_encryption_with_mmk",
      "storage_account_automatic_key_management_enabled",
      "storage_account_default_encryption_mmk",
      "storage_account_encryption_at_rest_mmk"
    ]
  },
  {
    "id": "2.1.2.2.1",
    "title": "Ensure Critical Data is Encrypted with Customer Managed Keys (CMK)",
    "assessment": "Manual",
    "description": "Customer Managed Keys introduce additional depth to security by providing a means to manage access control for encryption keys. Where compliance and security frameworks indicate the need, and organizational capacity allows, sensitive data at rest can be encrypted using Customer Managed Keys (CMK) rather than Microsoft Managed keys.",
    "rationale": "By default in Azure, data at rest tends to be encrypted using Microsoft Managed Keys. If your organization want to control and manage encryption keys for compliance and defense-in-depth, Customer Managed Keys can be established. While it is possible to automate the assessment of this recommendation, the assessment status for this recommendation remains 'Manual' due to ideally limited scope. The scope of application - which workloads CMK is applied to - should be carefully considered to account for organizational capacity and targeted to workloads with specific need for CMK. Impact: If the key expires due to setting the 'activation date' and 'expiration date', the key must be rotated manually. Using Customer Managed Keys may also incur additional man-hour requirements to create, store, manage, and protect the keys as needed.",
    "audit": "",
    "remediation": "Default Value: By default, Encryption type is set to Microsoft Managed Keys. References: 1. https://docs.microsoft.com/en-us/azure/security/fundamentals/data-encryption- best-practices#protect-data-at-rest 2. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-data- protection#dp-5-use-customer-managed-key-option-in-data-at-rest-encryption- when-required",
    "profile_applicability": "•  Level 2",
    "impact": "If the key expires due to setting the 'activation date' and 'expiration date', the key must be rotated manually. Using Customer Managed Keys may also incur additional man-hour requirements to create, store, manage, and protect the keys as needed.",
    "references": "1. https://docs.microsoft.com/en-us/azure/security/fundamentals/data-encryption- best-practices#protect-data-at-rest 2. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-data- protection#dp-5-use-customer-managed-key-option-in-data-at-rest-encryption- when-required",
    "function_names": [
      "storage_account_blob_encryption_cmk_enabled",
      "storage_account_file_encryption_cmk_enabled",
      "storage_account_table_encryption_cmk_enabled",
      "storage_account_queue_encryption_cmk_enabled",
      "sql_server_database_encryption_cmk_enabled",
      "cosmos_db_account_encryption_cmk_enabled",
      "virtual_machine_disk_encryption_cmk_enabled",
      "key_vault_secret_encryption_cmk_enabled",
      "data_lake_store_encryption_cmk_enabled",
      "container_registry_encryption_cmk_enabled"
    ]
  },
  {
    "id": "2.2.1.1",
    "title": "Ensure public network access is Disabled",
    "assessment": "Automated",
    "description": "Disable public network access to prevent exposure to the internet and reduce the risk of unauthorized access. Use private endpoints and Azure Role-Based Access Control (RBAC) to securely manage access within trusted networks.",
    "rationale": "Disabling public network access improves security by ensuring that a service is not exposed on the public internet. Impact: Disabling public network access restricts access to the service. This enhances security but may require the configuration of private endpoints for any services or users needing access within trusted networks.",
    "audit": "",
    "remediation": "Additional Information: This Common Reference Recommendation is referenced in the following Service Recommendations: • Storage Services > Storage Accounts > Networking > \"Ensure that 'Public Network Access' is 'Disabled' for storage accounts\" • Storage Services > Azure Elastic SAN > \"Ensure 'Public network access' is set to 'Disabled' on Azure Elastic SAN\" • Storage Services > Azure Backup > Recovery Services Vaults > \"Ensure public network access on Recovery Services vaults is Disabled\"",
    "profile_applicability": "•  Level 1",
    "impact": "Disabling public network access restricts access to the service. This enhances security but may require the configuration of private endpoints for any services or users needing access within trusted networks.",
    "function_names": [
      "storage_account_public_network_access_disabled",
      "storage_account_private_endpoint_enabled",
      "storage_account_network_access_restricted",
      "storage_account_public_access_blocked",
      "storage_account_internet_exposure_disabled",
      "storage_account_private_link_enabled",
      "storage_account_firewall_rules_configured",
      "storage_account_network_acl_restricted"
    ]
  },
  {
    "id": "2.2.1.2",
    "title": "Ensure Network Access Rules are set to Deny-by-default",
    "assessment": "Automated",
    "description": "Restricting default network access provides a foundational level of security to networked resources. To limit access to selected networks, the default action must be changed.",
    "rationale": "Resources using Virtual Network interfaces should be configured to deny-by-default all access from all networks (including internet traffic). Access can be granted to traffic from specific Azure Virtual networks, allowing a secure network boundary for specific applications to be built. If necessary, access can also be granted to public internet IP address ranges to enable connections from specific internet or on-premises clients. For all traffic inbound from- and outbound to- the internet, a NAT Gateway is recommended at minimum, and ideally all traffic flows through a security gateway device such as a firewall. Security gateway devices will provide an additional level of visibility to inbound and outbound traffic and usually perform advanced monitoring and response activity such as intrusion detection and prevention (IDP), and deep packet inspection (DPI) which help detect activity indicating vulnerabilities and threats. Impact: All allowed networks and protocols will need to be allow-listed which creates some administrative overhead. Implementing a deny-by-default rule may result in a loss of network connectivity. Careful planning and a scheduled implementation window allowing for downtime is highly recommended.",
    "audit": "",
    "remediation": "Default Value: By default, interfaces attached to virtual networks will accept connections from clients on any network and have a default outbound access rule which allows access to the internet. The default outbound access rule is scheduled for retirement on September 30th, 2025: https://azure.microsoft.com/en-us/updates?id=default-outbound-access-for-vms-in- azure-will-be-retired-transition-to-a-new-method-of-internet-access References: 1. https://docs.microsoft.com/en-us/azure/storage/common/storage-network- security 2. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-governance- strategy#gs-2-define-and-implement-enterprise-segmentationseparation-of- duties-strategy 3. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-network- security#ns-2-secure-cloud-native-services-with-network-controls Additional Information: This Common Reference Recommendation is referenced in the following Service Recommendations: • Storage Services > Storage Accounts > Networking > \"Ensure Default Network Access Rule for Storage Accounts is Set to Deny\" •",
    "profile_applicability": "•  Level 1",
    "impact": "All allowed networks and protocols will need to be allow-listed which creates some administrative overhead. Implementing a deny-by-default rule may result in a loss of network connectivity. Careful planning and a scheduled implementation window allowing for downtime is highly recommended.",
    "references": "1. https://docs.microsoft.com/en-us/azure/storage/common/storage-network- security 2. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-governance- strategy#gs-2-define-and-implement-enterprise-segmentationseparation-of- duties-strategy 3. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-network- security#ns-2-secure-cloud-native-services-with-network-controls Additional Information: This Common Reference Recommendation is referenced in the following Service Recommendations: • Storage Services > Storage Accounts > Networking > \"Ensure Default Network Access Rule for Storage Accounts is Set to Deny\" •",
    "function_names": [
      "network_security_group_default_deny",
      "network_acl_default_deny",
      "firewall_policy_default_deny",
      "vpc_network_default_deny",
      "subnet_network_default_deny",
      "network_security_rule_default_deny",
      "cloud_firewall_default_deny",
      "network_access_policy_default_deny"
    ]
  },
  {
    "id": "2.2.2.1",
    "title": "Ensure Private Endpoints are used to access {service}",
    "assessment": "Automated",
    "description": "Use private endpoints to allow clients and services to securely access data located over a network via an encrypted Private Link. To do this, the private endpoint uses an IP address from the VNet for each service. Network traffic between disparate services securely traverses encrypted over the VNet. This VNet can also link addressing space, extending your network and accessing resources on it. Similarly, it can be a tunnel through public networks to connect remote infrastructures together. This creates further security through segmenting network traffic and preventing outside sources from accessing it.",
    "rationale": "Securing traffic between services through encryption protects the data from easy interception and reading. Impact: A Private Endpoint costs approximately US$7.30 per month. If an Azure Virtual Network is not implemented correctly, this may result in the loss of critical network traffic.",
    "audit": "",
    "remediation": "Default Value: By default, Private Endpoints are not created for services. References: 1. https://docs.microsoft.com/en-us/azure/virtual-network/virtual-networks-overview 2. https://docs.microsoft.com/en-us/azure/private-link/create-private-endpoint-portal 3. https://docs.microsoft.com/en-us/azure/private-link/create-private-endpoint- cli?tabs=dynamic-ip 4. https://docs.microsoft.com/en-us/azure/private-link/create-private-endpoint- powershell?tabs=dynamic-ip 5. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-network- security#ns-2-secure-cloud-native-services-with-network-controls Additional Information: A NAT gateway is the recommended solution for outbound internet access.",
    "profile_applicability": "•  Level 2",
    "impact": "A Private Endpoint costs approximately US$7.30 per month. If an Azure Virtual Network is not implemented correctly, this may result in the loss of critical network traffic.",
    "references": "1. https://docs.microsoft.com/en-us/azure/virtual-network/virtual-networks-overview 2. https://docs.microsoft.com/en-us/azure/private-link/create-private-endpoint-portal 3. https://docs.microsoft.com/en-us/azure/private-link/create-private-endpoint- cli?tabs=dynamic-ip 4. https://docs.microsoft.com/en-us/azure/private-link/create-private-endpoint- powershell?tabs=dynamic-ip 5. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-network- security#ns-2-secure-cloud-native-services-with-network-controls Additional Information: A NAT gateway is the recommended solution for outbound internet access.",
    "function_names": [
      "network_private_endpoint_enabled",
      "network_private_link_encrypted",
      "network_vnet_ip_used",
      "network_traffic_vnet_encrypted",
      "network_address_space_linked",
      "network_remote_infrastructure_tunneled",
      "network_traffic_segmented",
      "network_outside_access_blocked"
    ]
  },
  {
    "id": "4.1",
    "title": "Ensure 'Key encryption key' is set to a customer-managed key for Azure Managed Lustre file systems",
    "assessment": "Automated",
    "description": "Enable customer-managed encryption keys (CMEK) for Azure Managed Lustre file systems to enhance data security and provide greater control over encryption processes. By using CMEK, organizations can manage their own encryption keys within Azure Key Vault, allowing them to rotate, revoke, or otherwise control access to these keys in accordance with their security policies.",
    "rationale": "Using customer-managed encryption keys (CMEK) gives organizations complete control over encryption keys, ensuring compliance and enhancing data security. CMEK allows for key rotation, revocation, and lifecycle management, thus improving data protection and facilitating immediate control over data access in Azure Managed Lustre file systems. Impact: There are costs and configuration overhead associated with setting up and managing customer-managed keys.",
    "audit": "Audit from Azure Portal 1. Go to Azure Managed Lustre. 2. Click the name of a file system. 3. Under Settings, click Properties. 4. Under Encryption settings, ensure that the value next to Key encryption key is View value as JSON. 5. Repeat steps 1-4 for each file system. Audit from Azure CLI Run the following command to lust Azure Managed Lustre file systems: az amlfs list For each file system, run the following command: az amlfs show --resource-group <resource-group> --name <file-system> Ensure that under encryptionSettings > keyEncryptionKey, keyUrl is set to a customer-managed key URL. Audit from PowerShell Run the following command to install the Az.StorageCache module: Install-Module Az.StorageCache Enter Y when prompted. Run the following command to list Azure Managed Lustre file systems: Get-AzStorageCacheAmlFileSystem Run the following command to get the file system in a resource group with a given name: $filesystem = Get-AzStorageCacheAmlFileSystem -ResourceGroupName <resource- group> -Name <file-system> Run the following command to get the key encryption key URL for the file system: $filesystem.KeyEncryptionKeyUrl Ensure that the command returns a customer-managed key URL. Repeat for each file system.",
    "remediation": "To create an Azure Managed Lustre file system that uses a customer-managed encryption key: Remediate from Azure Portal 1. Go to Azure Managed Lustre. 2. Click + Create. 3. Provide the required information on the Basics tab. 4. Configure the Advanced tab if necessary. 5. Click the Disk encryption keys tab. 6. Next to Disk encryption key type, select the radio button next to Customer managed. 7. Next to Key vault, key and version, click Select or create a key vault, key, or version. 8. Select a key vault, key, and version. 9. Click Select. 10. Next to User assigned identities, click Add user assigned managed identities. 11. In the filter box, type to filter by identity name and/or resource group name. 12. Check the box next to a managed identity. 13. Click Add. 14. Click Review + create. 15. Click Create. Remediate from Azure CLI Run the following command to create an Azure Managed Lustre file system with a customer-managed encryption key: az amlfs create --resource-group <resource-group> --name <file-system> --sku <sku> --storage-capacity <size-in-tib> --zones [<availability-zone>] -- maintenance-window \"{dayOfWeek:<day>,timeOfDayUtc:'<time>'}\" --mi-user- assigned \"<user-assigned-identity-id>\" --filesystem-subnet \"<subnet-id>\" -- encryption-setting \"{'keyUrl': '<key-url>', 'sourceVault': {'id': '<key- vault>'}}\" Remediate from PowerShell Run the following command to install the Az.StorageCache module: Install-Module Az.StorageCache Enter Y when prompted. Run the following command to create an Azure Manage Lustre file system with a customer-managed encryption key: New-AzStorageCacheAmlFileSystem -ResourceGroupName <resource-group> -Name <file-system> -Location <location> -MaintenanceWindowDayOfWeek '<day>' - MaintenanceWindowTimeOfDayUtc \"<time>\" -FilesystemSubnet \"<subnet-id>\" - SkuName \"<sku>\" -StorageCapacityTiB <size-in-tib> -Zone <availability-zone> - IdentityType 'UserAssigned' -IdentityUserAssignedIdentity @{\"<user-assigned- identity-id>\" = @{}} -KeyEncryptionKeyUrl \"<key-url>\" -SourceVaultId \"<key- vault>\" Default Value: By default, data in Azure Managed Lustre file systems is encrypted using Microsoft- managed keys. References: 1. https://learn.microsoft.com/en-us/azure/azure-managed-lustre/customer- managed-encryption-keys 2. https://learn.microsoft.com/en-us/cli/azure/amlfs 3. https://learn.microsoft.com/en-us/powershell/module/az.storagecache/get- azstoragecacheamlfilesystem 4. https://learn.microsoft.com/en-us/powershell/module/az.storagecache/new- azstoragecacheamlfilesystem",
    "profile_applicability": "•  Level 2",
    "impact": "There are costs and configuration overhead associated with setting up and managing customer-managed keys.",
    "references": "1. https://learn.microsoft.com/en-us/azure/azure-managed-lustre/customer- managed-encryption-keys 2. https://learn.microsoft.com/en-us/cli/azure/amlfs 3. https://learn.microsoft.com/en-us/powershell/module/az.storagecache/get- azstoragecacheamlfilesystem 4. https://learn.microsoft.com/en-us/powershell/module/az.storagecache/new- azstoragecacheamlfilesystem",
    "function_names": [
      "lustre_file_system_key_encryption_customer_managed",
      "lustre_file_system_encryption_key_customer_managed",
      "managed_lustre_encryption_key_customer_managed",
      "lustre_file_system_cmek_enabled",
      "managed_lustre_cmek_enabled"
    ]
  },
  {
    "id": "5.1.1",
    "title": "Ensure soft delete on Backup vaults is Enabled",
    "assessment": "Automated",
    "description": "Soft delete provides additional protection for Backup vault data. With soft delete enabled, deleted backup data can be recovered within the retention period.",
    "rationale": "Important backup data could be accidentally deleted or removed by a malicious actor. With soft delete enabled, data is retained for at least 14 days before permanent deletion, allowing for the recovery of the backup data. Impact: There is no additional cost for backup data in the soft delete state for up to and including 14 days. However, retention beyond 14 days may incur additional charges.",
    "audit": "Audit from Azure Portal 1. Go to Backup vaults. 2. Click the name of a Backup vault. 3. Under Manage, click Properties. 4. Ensure Soft delete is set to Enabled or Enabled with Always-On. 5. Next to Soft delete, click Update. 6. Ensure that the Retention period is set to an appropriate value between 14 and 180, inclusive. 7. Repeat steps 1-6 for each Backup vault. Audit from Azure CLI Run the following command to list Backup vaults: az dataprotection backup-vault list For each Backup vault, run the following command: az dataprotection backup-vault show --resource-group <resource-group> -- vault-name <backup-vault> Ensure that under softDeleteSettings, state is set to on or alwayson, and retentionDurationInDays is set to an appropriate value between 14 and 180, inclusive. Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: 9798d31d-6028-4dee-8643-46102185c016 • Name: '[Preview]: Soft delete should be enabled for Backup Vaults'",
    "remediation": "Remediate from Azure Portal 1. Go to Backup vaults. 2. Click the name of a Backup vault. 3. Under Manage, click Properties. 4. Next to Soft delete, click Update. 5. Check the box next to Soft delete. 6. In the box next to Retention period, set an appropriate number of days for deleted data to be retained, between 14 and 180, inclusive. 7. If it is appropriate for your organization, check the box next to Enable always- on soft delete. Note: Once enabled, this setting cannot be disabled. 8. Click Update. 9. Repeat steps 1-8 for each Backup vault requiring remediation. Remediate from Azure CLI Run the following command to list Backup vaults: az dataprotection backup-vault list For each Backup vault requiring remediation, run the following command to enable soft delete and set an appropriate number of days for deleted data to be retained, between 14 and 180, inclusive: az dataprotection backup-vault update --resource-group <resource-group> -- vault-name <backup-vault> --soft-delete-state On --retention-duration-in-days <retention-duration> Note: To enable always-on soft delete, the above command can be executed with -- soft-delete-state AlwaysOn. Once enabled, this setting cannot be disabled. Default Value: Soft delete is enabled by default on newly created Backup vaults. References: 1. https://learn.microsoft.com/en-us/azure/backup/backup-vault-overview 2. https://learn.microsoft.com/en-us/azure/backup/backup-azure-enhanced-soft- delete-about 3. https://learn.microsoft.com/en-us/cli/azure/dataprotection/backup-vault",
    "profile_applicability": "•  Level 1",
    "impact": "There is no additional cost for backup data in the soft delete state for up to and including 14 days. However, retention beyond 14 days may incur additional charges.",
    "references": "1. https://learn.microsoft.com/en-us/azure/backup/backup-vault-overview 2. https://learn.microsoft.com/en-us/azure/backup/backup-azure-enhanced-soft- delete-about 3. https://learn.microsoft.com/en-us/cli/azure/dataprotection/backup-vault",
    "function_names": [
      "backup_vault_soft_delete_enabled",
      "backup_vault_recovery_retention_configured",
      "backup_vault_protection_enabled",
      "backup_vault_deletion_recovery_enabled",
      "backup_vault_retention_policy_enabled"
    ]
  },
  {
    "id": "5.1.2",
    "title": "Ensure immutability for Backup vaults is Enabled",
    "assessment": "Automated",
    "description": "Immutable vaults safeguard backup data by preventing any operations that could result in the loss of recovery points. The immutable vault setting can be locked, making it irreversible and preventing malicious actors from disabling it and deleting backups.",
    "rationale": "Enabling the immutable vault ensures that backup data is protected from unauthorized or accidental deletion. By locking the setting and making it irreversible, malicious actors are prevented from disabling the setting and deleting backups. Impact: There is no additional cost for enabling vault immutability; however, a vault with locked immutability cannot be deleted without contacting Azure support and will incur the standard vault costs.",
    "audit": "Audit from Azure Portal 1. Go to Backup vaults. 2. From the list of vaults, ensure that the value in the Immutability column for each vault is Not locked or Locked. Audit from Azure CLI Run the following command to list Backup vaults: az dataprotection backup-vault list For each Backup vault, run the following command: az dataprotection backup-vault show --resource-group <resource-group> -- vault-name <backup-vault> Ensure that under immutabilitySettings, state is set to Unlocked or Locked.  Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: 2514263b-bc0d-4b06-ac3e-f262c0979018 • Name: '[Preview]: Immutability must be enabled for backup vaults'",
    "remediation": "Remediate from Azure Portal 1. Go to Backup vaults. 2. Click the name of a Backup vault. 3. Under Manage, click Properties. 4. Under the Immutable vault setting value, click Settings. 5. Check the box under Enable vault immutability. Note: It is not possible to lock immutability until immutability has been enabled. 6. Click Apply. 7. If it is appropriate for your organization to lock immutability, under the Immutable vault setting value, click Settings. 8. Click the toggle under Lock immutability for this vault to set it to Locked. 9. Check the box next to Confirm locking immutability. 10. Click Apply. 11. Repeat steps 1-10 for each Backup vault requiring remediation. Remediate from Azure CLI Run the following command to list Backup vaults: az dataprotection backup-vault list For each Backup vault requiring remediation, run the following command to enable vault immutability: az dataprotection backup-vault update --resource-group <resource-group> -- vault-name <backup-vault> --immutability-state Unlocked Note: To lock the Backup vault immutability state, the above command can be executed with --immutability-state Locked. Once enabled, this setting cannot be disabled and it will not be possible to delete the vault. Default Value: Immutability is disabled by default on Backup vaults. References: 1. https://learn.microsoft.com/en-us/azure/backup/backup-azure-immutable-vault- concept?tabs=backup-vault 2. https://learn.microsoft.com/en-us/azure/backup/backup-azure-immutable-vault- how-to-manage?tabs=backup-vault 3. https://learn.microsoft.com/en-us/cli/azure/dataprotection/backup-vault 4. https://learn.microsoft.com/en-us/azure/backup/backup-vault-overview",
    "profile_applicability": "•  Level 1",
    "impact": "There is no additional cost for enabling vault immutability; however, a vault with locked immutability cannot be deleted without contacting Azure support and will incur the standard vault costs.",
    "references": "1. https://learn.microsoft.com/en-us/azure/backup/backup-azure-immutable-vault- concept?tabs=backup-vault 2. https://learn.microsoft.com/en-us/azure/backup/backup-azure-immutable-vault- how-to-manage?tabs=backup-vault 3. https://learn.microsoft.com/en-us/cli/azure/dataprotection/backup-vault 4. https://learn.microsoft.com/en-us/azure/backup/backup-vault-overview",
    "function_names": [
      "backup_vault_immutability_enabled",
      "backup_vault_immutability_locked",
      "backup_vault_recovery_points_protected",
      "backup_vault_deletion_protection_enabled",
      "backup_vault_immutability_irreversible"
    ]
  },
  {
    "id": "5.1.3",
    "title": "Ensure backup data in Backup vaults is encrypted using customer-managed keys (CMK)",
    "assessment": "Automated",
    "description": "Backup vaults offer two encryption options: Microsoft-managed keys, which provide automatic encryption without user intervention, and customer-managed keys (CMK), which allow organizations to retain full control over their encryption keys for enhanced security and compliance.",
    "rationale": "Using customer-managed keys (CMKs) to encrypt Backup vaults enhances security by granting organizations complete control over their encryption keys. Impact: There are costs and configuration overhead associated with setting up and managing customer-managed keys.",
    "audit": "Audit from Azure Portal 1. Go to Backup vaults. 2. Click the name of a Backup vault. 3. Under Manage, click Properties. 4. Ensure Encryption Settings is set to Using 'Customer-managed keys'. 5. Repeat steps 1-4 for each Backup vault. Audit from Azure CLI Run the following command to list Backup vaults: az dataprotection backup-vault list For each Backup vault, run the following command: az dataprotection backup-vault show --resource-group <resource-group> -- vault-name <backup-vault> Ensure that under properties > securitySettings > encryptionSettings > keyVaultProperties, a key keyUri exists with the value set to a customer-managed key URI. Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: d6588149-9f06-462c-a076-56aece45b5ba • Name: '[Preview]: Azure Backup Vaults should use customer-managed keys for encrypting backup data. Also an option to enforce Infra Encryption.'",
    "remediation": "Note: Once encryption is configured to use a customer-managed key, this setting cannot be reversed. Remediate from Azure Portal 1. Go to Backup vaults. 2. Click the name of a Backup vault. 3. Under Manage, click Properties. 4. Under Using 'Microsoft-managed keys', click Update. 5. Check the box next to Use your own key. 6. Under Encryption key, click the radio button next to Enter key URI to provide a known key URI, or click the radio button next to Select from Key Vault to select a key from a Key Vault. 7. If entering a key URI, provide the key URI in the text box under Key URI. 8. If selecting a key from a Key Vault, click select key from Key Vault. 1. Select Key vault or Managed HSM. 2. Select a key vault or managed HSM. 3. Select a key. 4. Click Select. 9. Select a managed identity to use for the encryption key. 10. Click Update. 11. Repeat steps 1-10 for each Backup vault. Remediate from Azure CLI For each Backup vault requiring remediation, run the following command to assign a customer-managed encryption key: az dataprotection backup-vault update --resource-group <resource-group> -- vault-name <backup-vault> --cmk-encryption-key-uri <cmk-uri> --cmk- encryption-state \"Enabled\" --cmk-identity-type \"SystemAssigned\" Note: Use --cmk-identity-type \"UserAssigned\" --cmk-user-assigned- identity-id <user-assigned-identity-id> with the above command to provide a UserAssigned Identity Id. Default Value: By default, data in the Backup vault is encrypted using Microsoft-managed keys. References: 1. https://learn.microsoft.com/en-us/azure/backup/encryption-at-rest-with-cmk-for- backup-vault 2. https://learn.microsoft.com/en-us/cli/azure/dataprotection/backup-vault 3. https://learn.microsoft.com/en-us/entra/identity/managed-identities-azure- resources/how-manage-user-assigned-managed-identities Additional Information: • To enable encryption, it is necessary to grant the Backup vault the appropriate permissions to access the encryption key in the key vault. The key can be modified as needed. Refer to the following guide for details: https://learn.microsoft.com/en-us/azure/backup/encryption-at-rest-with-cmk-for- backup-vault#assign-permissions-to-the-backup-vault-to-access-the-encryption- key-in-azure-key-vault. • Azure Backup uses system-assigned managed identities and user-assigned managed identities to authenticate the Backup vault to access encryption keys stored in Azure Key Vault. Refer to the following guide for details: https://learn.microsoft.com/en-us/azure/backup/encryption-at-rest-with-cmk-for- backup-vault#enable-a-managed-identity-for-your-backup-vault.",
    "profile_applicability": "•  Level 2",
    "impact": "There are costs and configuration overhead associated with setting up and managing customer-managed keys.",
    "references": "1. https://learn.microsoft.com/en-us/azure/backup/encryption-at-rest-with-cmk-for- backup-vault 2. https://learn.microsoft.com/en-us/cli/azure/dataprotection/backup-vault 3. https://learn.microsoft.com/en-us/entra/identity/managed-identities-azure- resources/how-manage-user-assigned-managed-identities Additional Information: • To enable encryption, it is necessary to grant the Backup vault the appropriate permissions to access the encryption key in the key vault. The key can be modified as needed. Refer to the following guide for details: https://learn.microsoft.com/en-us/azure/backup/encryption-at-rest-with-cmk-for- backup-vault#assign-permissions-to-the-backup-vault-to-access-the-encryption- key-in-azure-key-vault. • Azure Backup uses system-assigned managed identities and user-assigned managed identities to authenticate the Backup vault to access encryption keys stored in Azure Key Vault. Refer to the following guide for details: https://learn.microsoft.com/en-us/azure/backup/encryption-at-rest-with-cmk-for- backup-vault#enable-a-managed-identity-for-your-backup-vault.",
    "function_names": [
      "backup_vault_encryption_cmk_enabled",
      "backup_vault_data_encryption_customer_managed",
      "backup_vault_cmk_encryption_required",
      "backup_vault_encryption_no_default_keys",
      "backup_vault_storage_encryption_cmk_only"
    ]
  },
  {
    "id": "5.1.4",
    "title": "Ensure 'Use infrastructure encryption for this vault' is enabled on Backup vaults",
    "assessment": "Automated",
    "description": "In addition to using customer-managed keys for encryption at rest in the Backup vault, you can enable an additional layer of platform-managed infrastructure encryption. This dual-layer approach enhances the protection of your backup data.",
    "rationale": "Enabling infrastructure encryption on a Backup vault adds a second layer of protection to backup data, enhancing security and ensuring compliance for sensitive data storage. This dual-layer strategy reduces the risk of unauthorized access by keeping data encrypted even if one layer is compromised. Impact: Enabling infrastructure encryption on a backup vault does not incur additional costs; however, infrastructure encryption must be configured when creating the vault and requires customer-managed keys for encryption at rest. This recommendation is linked to Ensure backup data in Backup vaults is encrypted using customer- managed keys (CMK) and should be applied alongside it if you choose to implement this recommendation.",
    "audit": "Audit from Azure Portal 1. Go to Backup vaults. 2. Click the name of a Backup vault. 3. Under Manage, click Properties. 4. Under Encryption Settings, click Update. 5. Under Infrastructure encryption, ensure the box next to Use infrastructure encryption for this vault is checked. 6. Repeat steps 1-5 for each Backup vault. Audit from Azure CLI Run the following command to list Backup vaults: az dataprotection backup-vault list For each Backup vault, run the following command: az dataprotection backup-vault show --resource-group <resource-group> -- vault-name <backup-vault> Ensure that under properties > securitySettings > encryptionSettings, infrastructureEncryption is set to Enabled. Audit from PowerShell Run the following command to list Backup vaults: Get-AzDataProtectionBackupVault Run the following command to get the Backup vault in a resource group with a given name: $vault = Get-AzDataProtectionBackupVault -ResourceGroupName <resource-group> -VaultName <backup-vault> Run the following command to get the infrastructure encryption setting for the Backup vault: $vault.EncryptionSetting.CmkInfrastructureEncryption Ensure that the command returns Enabled. Repeat for each Backup vault. Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: d6588149-9f06-462c-a076-56aece45b5ba • Name: '[Preview]: Azure Backup Vaults should use customer-managed keys for encrypting backup data. Also an option to enforce Infra Encryption.'",
    "remediation": "Remediate from Azure CLI Run the following command to create a locally redundant Backup vault with a customer- managed encryption key and infrastructure encryption enabled: az dataprotection backup-vault create --resource-group <resource-group> -- vault-name <backup-vault> --location <location> --storage-setting \"[{type:'LocallyRedundant',datastore-type:'VaultStore'}]\" --type \"UserAssigned\" --user-assigned-identities '{\"<user-assigned-identity- id>\":{}}' --cmk-encryption-key-uri <cmk-uri> --cmk-encryption-state Enabled - -cmk-identity-type \"UserAssigned\" --cmk-user-assigned-identity-id <cmk-user- assigned-identity-id> --cmk-infrastructure-encryption Enabled Remediate from PowerShell Run the following commands to create a locally redundant Backup vault with a customer-managed encryption key and infrastructure encryption enabled: $sub = \"<subscription-id>\" $storagesetting = New-AzDataProtectionBackupVaultStorageSettingObject - DataStoreType VaultStore -Type LocallyRedundant $userAssignedIdentity = @{ \"<user-assigned-identity-id>\" = @{ clientId = \"<user-assigned-identity-client-id>\" principalId = \"<user-assigned-identity-principal-id>\" } } $cmkIdentityId = \"<cmk-user-assigned-identity-id>\" $cmkKeyUri = \"<cmk-uri>\" New-AzDataProtectionBackupVault -SubscriptionId $sub -ResourceGroupName <resource-group> -VaultName <backup-vault> -Location <location> - StorageSetting $storagesetting -IdentityType UserAssigned - UserAssignedIdentity $userAssignedIdentity -CmkEncryptionState Enabled - CmkIdentityType UserAssigned -CmkUserAssignedIdentityId $cmkIdentityId - CmkEncryptionKeyUri $cmkKeyUri -CmkInfrastructureEncryption Enabled Default Value: Infrastructure encryption is disabled by default on Backup vaults. References: 1. https://learn.microsoft.com/en-us/cli/azure/dataprotection/backup-vault 2. https://learn.microsoft.com/en-us/powershell/module/az.dataprotection/get- azdataprotectionbackupvault 3. https://learn.microsoft.com/en-us/powershell/module/az.dataprotection/new- azdataprotectionbackupvault 4. https://learn.microsoft.com/en-us/entra/identity/managed-identities-azure- resources/how-manage-user-assigned-managed-identities Additional Information: Backup vaults use user-assigned managed identities to authenticate the Backup vault to access encryption keys stored in Azure Key Vault when creating the vault with a customer-managed encryption key and infrastructure encryption enabled. Refer to the following guides for details: • https://learn.microsoft.com/en-us/entra/identity/managed-identities-azure- resources/how-manage-user-assigned-managed-identities • https://learn.microsoft.com/en-us/azure/backup/encryption-at-rest-with-cmk-for- backup-vault",
    "profile_applicability": "•  Level 2",
    "impact": "Enabling infrastructure encryption on a backup vault does not incur additional costs; however, infrastructure encryption must be configured when creating the vault and requires customer-managed keys for encryption at rest. This recommendation is linked to Ensure backup data in Backup vaults is encrypted using customer- managed keys (CMK) and should be applied alongside it if you choose to implement this recommendation.",
    "references": "1. https://learn.microsoft.com/en-us/cli/azure/dataprotection/backup-vault 2. https://learn.microsoft.com/en-us/powershell/module/az.dataprotection/get- azdataprotectionbackupvault 3. https://learn.microsoft.com/en-us/powershell/module/az.dataprotection/new- azdataprotectionbackupvault 4. https://learn.microsoft.com/en-us/entra/identity/managed-identities-azure- resources/how-manage-user-assigned-managed-identities Additional Information: Backup vaults use user-assigned managed identities to authenticate the Backup vault to access encryption keys stored in Azure Key Vault when creating the vault with a customer-managed encryption key and infrastructure encryption enabled. Refer to the following guides for details: • https://learn.microsoft.com/en-us/entra/identity/managed-identities-azure- resources/how-manage-user-assigned-managed-identities • https://learn.microsoft.com/en-us/azure/backup/encryption-at-rest-with-cmk-for- backup-vault",
    "function_names": [
      "backup_vault_infrastructure_encryption_enabled",
      "backup_vault_dual_layer_encryption_enabled",
      "backup_vault_platform_encryption_enabled",
      "backup_vault_infrastructure_encryption_required",
      "backup_vault_encryption_infrastructure_enabled"
    ]
  },
  {
    "id": "5.1.5",
    "title": "Ensure 'Cross Region Restore' is set to 'Enabled' on Backup vaults",
    "assessment": "Automated",
    "description": "Cross region restore enables data restoration in a secondary Azure paired region, even when the primary region is fully operational. This allows organizations to conduct drills and validate regional resiliency, thereby ensuring preparedness for potential outages.",
    "rationale": "Enabling cross region restore facilitates proactive resilience testing and disaster recovery planning by allowing data restoration drills in a secondary region without needing a primary region outage. This capability helps organizations validate recovery processes, identify gaps in regional failover, and ensures critical data can be accessed and restored during real disruptions. Impact: Enabling cross region restore on a Backup vault incurs additional costs, and once it is enabled, it cannot be disabled. • Cross region restore is an irreversible storage property. • Cross region restore is currently supported for limited workloads. • Cross region restore can only be enabled if the redundancy of the vault is GRS.",
    "audit": "Audit from Azure Portal 1. Go to Backup vaults. 2. Click the name of a Backup vault. 3. Under Manage, click Properties. 4. Under Vault Settings, ensure that Cross Region Restore is set to Enabled. 5. Repeat steps 1-4 for each Backup vault. Audit from Azure CLI Run the following command to list Backup vaults: az dataprotection backup-vault list For each Backup vault, run the following command: az dataprotection backup-vault show --resource-group <resource-group> -- vault-name <backup-vault> Ensure that under properties > featureSettings > crossRegionRestoreSettings, state is set to Enabled. Audit from PowerShell Run the following command to list Backup vaults: Get-AzDataProtectionBackupVault Run the following command to get the Backup vault in a resource group with a given name: $vault = Get-AzDataProtectionBackupVault -ResourceGroupName <resource-group> -VaultName <backup-vault> Run the following command to get the cross region restore setting for the Backup vault: $vault.CrossRegionRestoreState Ensure that the command returns Enabled. Repeat for each Backup vault.",
    "remediation": "Remediate from Azure Portal 1. Go to Backup vaults. 2. Click the name of a Backup vault. 3. Under Manage, click Properties. 4. Under Vault Settings, next to Cross Region Restore, click Update. 5. Click the toggle switch under Cross Region Restore to set it to Enable. 6. Click Apply. 7. Repeat steps 1-6 for each Backup vault requiring remediation. Remediate from Azure CLI For each Backup vault requiring remediation, run the following command to enable cross region restore: az dataprotection backup-vault update --resource-group <resource-group> -- vault-name <backup-vault> --cross-region-restore-state Enabled Remediate from PowerShell For each Backup vault requiring remediation, run the following command to enable cross region restore: Update-AzDataProtectionBackupVault -ResourceGroupName <resource-group> - VaultName <backup-vault> -CrossRegionRestoreState Enabled Default Value: Cross region restore is disabled by default on Backup vaults.  References: 1. https://learn.microsoft.com/en-gb/azure/backup/backup-vault-overview#cross- region-restore-support-for-postgresql-using-azure-backup 2. https://learn.microsoft.com/en-us/azure/backup/tutorial-cross-region-restore 3. https://azure.microsoft.com/en-gb/pricing/details/backup/ 4. https://learn.microsoft.com/en-us/cli/azure/dataprotection/backup-vault 5. https://learn.microsoft.com/en-us/powershell/module/az.dataprotection/get- azdataprotectionbackupvault 6. https://learn.microsoft.com/en-us/powershell/module/az.dataprotection/update- azdataprotectionbackupvault",
    "profile_applicability": "•  Level 2",
    "impact": "Enabling cross region restore on a Backup vault incurs additional costs, and once it is enabled, it cannot be disabled. • Cross region restore is an irreversible storage property. • Cross region restore is currently supported for limited workloads. • Cross region restore can only be enabled if the redundancy of the vault is GRS.",
    "references": "1. https://learn.microsoft.com/en-gb/azure/backup/backup-vault-overview#cross- region-restore-support-for-postgresql-using-azure-backup 2. https://learn.microsoft.com/en-us/azure/backup/tutorial-cross-region-restore 3. https://azure.microsoft.com/en-gb/pricing/details/backup/ 4. https://learn.microsoft.com/en-us/cli/azure/dataprotection/backup-vault 5. https://learn.microsoft.com/en-us/powershell/module/az.dataprotection/get- azdataprotectionbackupvault 6. https://learn.microsoft.com/en-us/powershell/module/az.dataprotection/update- azdataprotectionbackupvault",
    "function_names": [
      "backup_vault_cross_region_restore_enabled",
      "backup_vault_restore_multi_region_enabled",
      "backup_vault_secondary_region_restore_enabled",
      "backup_vault_regional_resiliency_enabled",
      "backup_vault_cross_region_recovery_enabled"
    ]
  },
  {
    "id": "5.1.6",
    "title": "Ensure 'Cross Subscription Restore' is set to 'Disabled' or 'Permanently Disabled' on Backup vaults",
    "assessment": "Automated",
    "description": "Disable cross subscription restore for Backup vaults to ensure that backup data can only be restored within the same subscription as the Backup vault, preventing restoration to targets in other subscriptions.",
    "rationale": "Cross subscription restores increases security risks by widening access to sensitive backup data, potentially leading to accidental or intentional exposure, unauthorized access, or data exfiltration across environments. Impact: Organizations may need to consider alternatives for disaster recovery scenarios, and if utilizing multiple subscriptions, may need to make adjustments or consider alternatives for data access. Costs could be incurred if alternative or additional backup infrastructure is required to account for the disabling of cross subscription restore.",
    "audit": "Audit from Azure Portal 1. Go to Backup vaults. 2. Click the name of a Backup vault. 3. Under Manage, click Properties. 4. Under Vault Settings, ensure that Cross Subscription Restore is set to Disabled or Permanently Disabled. 5. Repeat steps 1-4 for each Backup vault. Audit from Azure CLI Run the following command to list Backup vaults: az dataprotection backup-vault list For each Backup vault, run the following command: az dataprotection backup-vault show --resource-group <resource-group> -- vault-name <backup-vault> Ensure that under properties > featureSettings > crossSubscriptionRestoreSettings, state is set to Disabled or PermanentlyDisabled. Audit from PowerShell Run the following command to list Backup vaults: Get-AzDataProtectionBackupVault Run the following command to get the Backup vault in a resource group with a given name: $vault = Get-AzDataProtectionBackupVault -ResourceGroupName <resource-group> -VaultName <backup-vault> Run the following command to get the cross subscription restore setting for the Backup vault: $vault.CrossSubscriptionRestoreState Ensure that the command returns Disabled or PermanentlyDisabled. Repeat for each Backup vault. Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: 4d479a11-f2b5-4f0a-bb1e-d2332aa95cda • Name: '[Preview]: Disable Cross Subscription Restore for Backup Vaults'",
    "remediation": "Remediate from Azure Portal 1. Go to Backup vaults. 2. Click the name of a Backup vault. 3. Under Manage, click Properties. 4. Under Vault Settings, next to Cross Subscription Restore, click Update. 5. Select the radio button next to Disable Cross Subscription Restore or Permanently disable Cross Subscription Restore on this vault. 6. If selecting to permanently disable cross subscription restore, check the box next to Are you sure you want to permanently disable Cross Subscription Restore? Once disabled, it cannot be re-enabled. 7. Click Update. 8. Repeat steps 1-7 for each Backup vault requiring remediation. Remediate from Azure CLI For each Backup vault requiring remediation, run the following command to disable cross subscription restore: az dataprotection backup-vault update --resource-group <resource-group> -- vault-name <backup-vault> --cross-subscription-restore-state Disabled Note: Use --cross-subscription-restore-state PermanentlyDisabled with the above command to permanently disable cross subscription restore. Remediate from PowerShell For each Backup vault requiring remediation, run the following command to disable cross subscription restore: Update-AzDataProtectionBackupVault -ResourceGroupName <resource-group> - VaultName <backup-vault> -CrossSubscriptionRestoreState Disabled Note: Use -CrossSubscriptionRestoreState PermanentlyDisabled with the above command to permanently disable cross subscription restore. Default Value: Cross subscription restore is enabled by default on Backup vaults. References: 1. https://learn.microsoft.com/en-us/cli/azure/dataprotection/backup-vault 2. https://learn.microsoft.com/en-us/powershell/module/az.dataprotection/get- azdataprotectionbackupvault 3. https://learn.microsoft.com/en-us/powershell/module/az.dataprotection/update- azdataprotectionbackupvault 4. https://learn.microsoft.com/en-us/azure/backup/create-manage-backup- vault#cross-subscription-restore-using-azure-portal Additional Information: If cross subscription restore is permanently disabled on a vault, it cannot be re-enabled.",
    "profile_applicability": "•  Level 1",
    "impact": "Organizations may need to consider alternatives for disaster recovery scenarios, and if utilizing multiple subscriptions, may need to make adjustments or consider alternatives for data access. Costs could be incurred if alternative or additional backup infrastructure is required to account for the disabling of cross subscription restore.",
    "references": "1. https://learn.microsoft.com/en-us/cli/azure/dataprotection/backup-vault 2. https://learn.microsoft.com/en-us/powershell/module/az.dataprotection/get- azdataprotectionbackupvault 3. https://learn.microsoft.com/en-us/powershell/module/az.dataprotection/update- azdataprotectionbackupvault 4. https://learn.microsoft.com/en-us/azure/backup/create-manage-backup- vault#cross-subscription-restore-using-azure-portal Additional Information: If cross subscription restore is permanently disabled on a vault, it cannot be re-enabled.",
    "function_names": [
      "backup_vault_cross_subscription_restore_disabled",
      "backup_vault_cross_subscription_restore_permanently_disabled",
      "backup_vault_restore_scope_same_subscription_only"
    ]
  },
  {
    "id": "5.2.1",
    "title": "Ensure soft delete on Recovery Services vaults is Enabled",
    "assessment": "Automated",
    "description": "Soft delete provides additional protection for Recovery Services vault data. With soft delete enabled, deleted backup data can be recovered within the retention period.",
    "rationale": "Important backup data could be accidentally deleted or removed by a malicious actor. With soft delete enabled, data is retained for at least 14 days before permanent deletion, allowing for the recovery of the backup data. Impact: There is no additional cost for backup data in the soft delete state for up to and including 14 days. However, retention beyond 14 days may incur additional charges.",
    "audit": "Audit from Azure Portal 1. Go to Recovery Services vaults. 2. Click the name of a Recovery Services vault. 3. Under Settings, click Properties. 4. Under Soft Delete and security settings, click Update. 5. Ensure the box next to Enable soft delete for cloud workloads is checked. 6. Ensure the box next to Enable soft delete and security settings for hybrid workloads is checked. 7. Ensure that the Soft delete retention period is set to an appropriate value between 14 and 180, inclusive. 8. Repeat steps 1-7 for each Recovery Services vault. Audit from Azure CLI Run the following command to list Recovery Services vaults: az backup vault list For each Recovery Services vault, run the following command: az backup vault show --resource-group <resource-group> --name <recovery- services-vault> Ensure that under softDeleteSettings, softDeleteState is set to Enabled, enhancedSecurityState is set to Enabled, and softDeleteRetentionPeriodInDays is set to an appropriate value between 14 and 180, inclusive. Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: 31b8092a-36b8-434b-9af7-5ec844364148 • Name: '[Preview]: Soft delete must be enabled for Recovery Services Vaults.'",
    "remediation": "Remediate from Azure Portal 1. Go to Recovery Services vaults. 2. Click the name of a Recovery Services vault. 3. Under Settings, click Properties. 4. Under Soft Delete and security settings, click Update. 5. Check the box next to Enable soft delete for cloud workloads. 6. Check the box next to Enable soft delete and security settings for hybrid workloads. 7. In the box next to Soft delete retention period, set an appropriate number of days for deleted data to be retained, between 14 and 180, inclusive. 8. If it is appropriate for your organization, check the box next to Enable always- on soft delete. Note: Once enabled, this setting cannot be disabled. 9. If enabling always-on soft delete, check the box next to Confirm enabling always-on soft delete. 10. Click Update. 11. Repeat steps 1-10 for each Recovery Services vault requiring remediation. Remediate from Azure CLI Run the following command to list Recovery Services vaults: az backup vault list For each Recovery Services vault requiring remediation, run the following command to enable soft delete and set an appropriate number of days for deleted data to be retained, between 14 and 180, inclusive: az backup vault backup-properties set --resource-group <resource-group> -- name <recovery-services-vault> --soft-delete-feature-state Enable --hybrid- backup-security-features Enable --soft-delete-duration <retention-duration> Note: To enable always-on soft delete, the above command can be executed with -- soft-delete-feature-state AlwaysOn. Once enabled, this setting cannot be disabled. Default Value: Soft delete is enabled by default on newly created Recovery Services vaults. References: 1. https://learn.microsoft.com/en-us/azure/backup/backup-azure-recovery-services- vault-overview 2. https://learn.microsoft.com/en-us/azure/backup/backup-azure-security-feature- cloud 3. https://learn.microsoft.com/en-us/azure/backup/backup-azure-enhanced-soft- delete-about 4. https://learn.microsoft.com/en-us/azure/backup/soft-delete-virtual-machines 5. https://learn.microsoft.com/en-us/azure/backup/soft-delete-sql-saphana-in-azure- vm 6. https://learn.microsoft.com/en-us/cli/azure/backup/vault Additional Information: Azure Backup soft delete protection is available for the following services: • Azure virtual machines • SQL server in Azure VM and SAP HANA in Azure VM workloads",
    "profile_applicability": "•  Level 1",
    "impact": "There is no additional cost for backup data in the soft delete state for up to and including 14 days. However, retention beyond 14 days may incur additional charges.",
    "references": "1. https://learn.microsoft.com/en-us/azure/backup/backup-azure-recovery-services- vault-overview 2. https://learn.microsoft.com/en-us/azure/backup/backup-azure-security-feature- cloud 3. https://learn.microsoft.com/en-us/azure/backup/backup-azure-enhanced-soft- delete-about 4. https://learn.microsoft.com/en-us/azure/backup/soft-delete-virtual-machines 5. https://learn.microsoft.com/en-us/azure/backup/soft-delete-sql-saphana-in-azure- vm 6. https://learn.microsoft.com/en-us/cli/azure/backup/vault Additional Information: Azure Backup soft delete protection is available for the following services: • Azure virtual machines • SQL server in Azure VM and SAP HANA in Azure VM workloads",
    "function_names": [
      "recovery_services_vault_soft_delete_enabled",
      "recovery_services_vault_soft_delete_retention_configured",
      "recovery_services_vault_soft_delete_protection_enabled",
      "recovery_services_vault_soft_delete_recovery_period_set",
      "recovery_services_vault_soft_delete_policy_enabled"
    ]
  },
  {
    "id": "5.2.2",
    "title": "Ensure immutability for Recovery Services vaults is Enabled",
    "assessment": "Automated",
    "description": "Immutable vaults safeguard backup data by preventing any operations that could result in the loss of recovery points. The immutable vault setting can be locked, making it irreversible and preventing malicious actors from disabling it and deleting backups.",
    "rationale": "Enabling the immutable vault ensures that backup data is protected from unauthorized or accidental deletion. By locking the setting and making it irreversible, malicious actors are prevented from disabling the setting and deleting backups. Impact: There is no additional cost for enabling vault immutability; however, a vault with locked immutability cannot be deleted without contacting Azure support and will incur the standard vault costs.",
    "audit": "Audit from Azure Portal 1. Go to Recovery Services vaults. 2. From the list of vaults, ensure that the value in the Immutability column for each vault is Not locked or Locked. Audit from Azure CLI Run the following command to list Recovery Services vaults: az backup vault list For each Recovery Services vault, run the following command: az backup vault show --resource-group <resource-group> --name <recovery- services-vault> Ensure that under immutabilitySettings, state is set to Unlocked or Locked.  Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: d6f6f560-14b7-49a4-9fc8-d2c3a9807868 • Name: '[Preview]: Immutability must be enabled for Recovery Services vaults'",
    "remediation": "Remediate from Azure Portal 1. Go to Recovery Services vaults. 2. Click the name of a Recovery Services vault. 3. Under Settings, click Properties. 4. Under Immutable vault, click Settings. 5. Check the box under Enable vault immutability. Note: It is not possible to lock immutability until immutability has been enabled. 6. Click Apply. 7. If it is appropriate for your organization to lock immutability, under Immutable vault, click Settings. 8. Click the toggle under Lock immutability for this vault to set it to Locked. 9. Check the box next to Confirm locking immutability. 10. Click Apply. 11. Repeat steps 1-10 for each Recovery Services vault requiring remediation. Remediate from Azure CLI Run the following command to list Recovery Services vaults: az backup vault list For each Recovery Services vault requiring remediation, run the following command to enable vault immutability: az backup vault update --resource-group <resource-group> --name <recovery- services-vault> --immutability-state Unlocked Note: To lock the Recovery Services vault immutability state, the above command can be executed with --immutability-state Locked. Once enabled, this setting cannot be disabled and it will not be possible to delete the vault. Default Value: Immutability is disabled by default on Recovery Services vaults.",
    "profile_applicability": "•  Level 1",
    "impact": "There is no additional cost for enabling vault immutability; however, a vault with locked immutability cannot be deleted without contacting Azure support and will incur the standard vault costs.",
    "function_names": [
      "recovery_services_vault_immutability_enabled",
      "recovery_services_vault_immutability_locked",
      "recovery_services_vault_immutability_irreversible",
      "recovery_services_vault_backup_protection_enabled",
      "recovery_services_vault_recovery_point_locked"
    ]
  },
  {
    "id": "5.2.3",
    "title": "Ensure backup data in Recovery Services vaults is encrypted using customer-managed keys (CMK)",
    "assessment": "Automated",
    "description": "Recovery Services vaults offer two encryption options: Microsoft-managed keys, which provide automatic encryption without user intervention, and customer-managed keys (CMK), which allow organizations to retain full control over their encryption keys for enhanced security and compliance.",
    "rationale": "Using customer-managed keys (CMKs) to encrypt Recovery Services vaults enhances security by granting organizations complete control over their encryption keys. Impact: There are costs and configuration overhead associated with setting up and managing customer-managed keys.",
    "audit": "Audit from Azure Portal 1. Go to Recovery Services vaults. 2. Click the name of a Recovery Services vault. 3. Under Settings, click Properties. 4. Under Encryption Settings, click Update. 5. Ensure the box next to Use your own key is checked, and a key URI is displayed under Encryption key. 6. Repeat steps 1-5 for each Recovery Services vault. Audit from Azure CLI Run the following command to list Recovery Services vaults: az backup vault list For each Recovery Services vault, run the following command: az backup vault encryption show --resource-group <resource-group> --name <recovery-services-vault> Ensure that under properties, encryptionAtRestType is set to CustomerManaged, and a key keyUri exists with the value set to a customer-managed key URI.  Audit from PowerShell Run the following command to list Recovery Services vaults: Get-AzRecoveryServicesVault Run the following command to get the Recovery Services vault in a resource group with a given name: $vault = Get-AzRecoveryServicesVault -ResourceGroupName <resource-group> - Name <recovery-services-vault> Run the following command to get the encryption setting for the Recovery Services vault: $vault.Properties.EncryptionProperty.KeyVaultProperties Ensure that the command returns a customer-managed key URI. Repeat for each Recovery Services vault. Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: 2e94d99a-8a36-4563-bc77-810d8893b671 • Name: '[Preview]: Azure Recovery Services vaults should use customer- managed keys for encrypting backup data'",
    "remediation": "Note: Once encryption is configured to use a customer-managed key, this setting cannot be reversed. Remediate from Azure Portall 1. Go to Recovery Services vaults. 2. Click the name of a Recovery Services vault. 3. Under Settings, click Properties. 4. Under Encryption Settings, click Update. 5. Check the box next to Use your own key. 6. Under Encryption key, click the radio button next to Enter key URI to provide a known key URI, or click the radio button next to Select from Key Vault to select a key from a Key Vault. 7. If entering a key URI, provide the key URI in the text box under Key URI. 8. If selecting a key from a Key Vault, click select key from Key Vault. 1. Select Key vault or Managed HSM. 2. Select a key vault or managed HSM. 3. Select a key. 4. Click Select. 9. Select a managed identity to use for the encryption key. 10. Click Update. 11. Repeat steps 1-10 for each Recovery Services vault. Remediate from Azure CLI For each Recovery Services vault requiring remediation, run the following command to assign a customer-managed encryption key: az backup vault encryption update --resource-group <resource-group> --name <recovery-services-vault> --encryption-key-id <cmk-uri> --mi-system-assigned Note: Use --mi-user-assigned with the above command to provide a UserAssigned Identity Id. Remediate from PowerShell For each Recovery Services vault requiring remediation, run the following command to assign a customer-managed encryption key: Set-AzRecoveryServicesVaultProperty -VaultId <recovery-services-vault-id> - EncryptionKeyId <cmk-uri> -UseSystemAssignedIdentity $true Note: Use -UseSystemAssignedIdentity $false with the above command and - UserAssignedIdentity to provide a UserAssigned Identity Id. Default Value: By default, data in the Recovery Services vault is encrypted using Microsoft-managed keys. References: 1. https://learn.microsoft.com/en-us/azure/backup/encryption-at-rest-with-cmk 2. https://learn.microsoft.com/en-us/cli/azure/backup/vault 3. https://learn.microsoft.com/en-us/powershell/module/az.recoveryservices/get- azrecoveryservicesvault 4. https://learn.microsoft.com/en-us/powershell/module/az.recoveryservices/set- azrecoveryservicesvaultproperty 5. https://learn.microsoft.com/en-us/entra/identity/managed-identities-azure- resources/how-manage-user-assigned-managed-identities Additional Information: • This feature can only be applied to new Recovery Services vaults. Unfortunately, vaults that currently contain existing items that are registered or have previously attempted registration are not supported. • To enable encryption, it is necessary to grant the Recovery Services vault the appropriate permissions to access the encryption key in the key vault. The key can be modified as needed. Refer to the following guide for details: https://learn.microsoft.com/en-us/azure/backup/encryption-at-rest-with- cmk#assign-permissions-to-the-recovery-services-vault-to-access-the- encryption-key-in-azure-key-vault. • Azure Backup uses system-assigned managed identities and user-assigned managed identities to authenticate the Recovery Services vault to access encryption keys stored in Azure Key Vault. Refer to the following guide for details: https://learn.microsoft.com/en-us/azure/backup/encryption-at-rest-with- cmk#enable-a-managed-identity-for-your-recovery-services-vault.",
    "profile_applicability": "•  Level 2",
    "impact": "There are costs and configuration overhead associated with setting up and managing customer-managed keys.",
    "references": "1. https://learn.microsoft.com/en-us/azure/backup/encryption-at-rest-with-cmk 2. https://learn.microsoft.com/en-us/cli/azure/backup/vault 3. https://learn.microsoft.com/en-us/powershell/module/az.recoveryservices/get- azrecoveryservicesvault 4. https://learn.microsoft.com/en-us/powershell/module/az.recoveryservices/set- azrecoveryservicesvaultproperty 5. https://learn.microsoft.com/en-us/entra/identity/managed-identities-azure- resources/how-manage-user-assigned-managed-identities Additional Information: • This feature can only be applied to new Recovery Services vaults. Unfortunately, vaults that currently contain existing items that are registered or have previously attempted registration are not supported. • To enable encryption, it is necessary to grant the Recovery Services vault the appropriate permissions to access the encryption key in the key vault. The key can be modified as needed. Refer to the following guide for details: https://learn.microsoft.com/en-us/azure/backup/encryption-at-rest-with- cmk#assign-permissions-to-the-recovery-services-vault-to-access-the- encryption-key-in-azure-key-vault. • Azure Backup uses system-assigned managed identities and user-assigned managed identities to authenticate the Recovery Services vault to access encryption keys stored in Azure Key Vault. Refer to the following guide for details: https://learn.microsoft.com/en-us/azure/backup/encryption-at-rest-with- cmk#enable-a-managed-identity-for-your-recovery-services-vault.",
    "function_names": [
      "recovery_services_vault_backup_cmk_encryption_enabled",
      "recovery_services_vault_backup_microsoft_managed_key_disabled",
      "recovery_services_vault_backup_customer_managed_key_required",
      "recovery_services_vault_backup_encryption_key_controlled",
      "recovery_services_vault_backup_cmk_encryption_enforced"
    ]
  },
  {
    "id": "5.2.4",
    "title": "Ensure 'Use infrastructure encryption for this vault' is enabled on Recovery Services vaults",
    "assessment": "Automated",
    "description": "In addition to using customer-managed keys for encryption at rest in the Recovery Services vault, you can enable an additional layer of platform-managed infrastructure encryption. This dual-layer approach enhances the protection of your backup data.",
    "rationale": "Enabling infrastructure encryption on an Azure Recovery Services vault adds a second layer of protection to backup data, enhancing security and ensuring compliance for sensitive data storage. This dual-layer strategy reduces the risk of unauthorized access by keeping data encrypted even if one layer is compromised. Impact: Enabling infrastructure encryption on an Azure Recovery Services vault does not incur additional costs; however infrastructure encryption must be set when configuring the encryption of the vault for the first time and requires customer-managed keys for encryption at rest. Once configured, the infrastructure encryption setting cannot be changed. This recommendation is linked to Ensure that backup data in Recovery Services vaults is encrypted using customer-managed keys (CMK) and should be applied alongside it if you choose to implement this recommendation.",
    "audit": "Audit from Azure Portal 1. Go to Recovery Services vaults. 2. Click the name of a Recovery Services vault. 3. Under Settings, click Properties. 4. Under Encryption Settings, click Update. 5. Under Infrastructure encryption, ensure the box next to Use infrastructure encryption for this vault is checked. 6. Repeat steps 1-5 for each Recovery Services vault. Audit from Azure CLI Run the following command to list Recovery Services vaults: az backup vault list For each Recovery Services vault, run the following command: az backup vault encryption show --resource-group <resource-group> --name <recovery-services-vault> Ensure that infrastructureEncryptionState is set to Enabled. Audit from PowerShell Run the following command to list Recovery Services vaults: Get-AzRecoveryServicesVault Run the following command to get the Recovery Services vault in a resource group with a given name: $vault = Get-AzRecoveryServicesVault -ResourceGroupName <resource-group> - Name <recovery-services-vault> Run the following command to get the infrastructure encryption setting for the Recovery Services vault: $vault.Properties.EncryptionProperty.InfrastructureEncryption Ensure that the command returns Enabled. Repeat for each Recovery Services vault.",
    "remediation": "Remediate from Azure Portal After configuring a customer-managed key for encryption, next to Infrastructure Encryption, click the radio button next to Enabled. Remediate from Azure CLI For each Recovery Services vault requiring remediation, run the following command to assign a customer-managed encryption key and enable infrastructure encryption: az backup vault encryption update --resource-group <resource-group> --name <recovery-services-vault> --encryption-key-id <cmk-uri> --mi-system-assigned --infrastructure-encryption Enabled Note: Use --mi-user-assigned with the above command to provide a UserAssigned Identity Id. Remediate from PowerShell For each Recovery Services vault requiring remediation, run the following command to assign a customer-managed encryption key and enable infrastructure encryption: Set-AzRecoveryServicesVaultProperty -VaultId <recovery-services-vault-id> - EncryptionKeyId <cmk-uri> -UseSystemAssignedIdentity $true - InfrastructureEncryption Note: Use -UseSystemAssignedIdentity $false with the above command and - UserAssignedIdentity to provide a UserAssigned Identity Id. Default Value: Infrastructure encryption is disabled by default on Azure Recovery Services vaults.  References: 1. https://learn.microsoft.com/en-us/azure/backup/backup-encryption 2. https://learn.microsoft.com/en-us/cli/azure/backup/vault/encryption 3. https://learn.microsoft.com/en-us/powershell/module/az.recoveryservices/get- azrecoveryservicesvault 4. https://learn.microsoft.com/en-us/powershell/module/az.recoveryservices/set- azrecoveryservicesvaultproperty",
    "profile_applicability": "•  Level 2",
    "impact": "Enabling infrastructure encryption on an Azure Recovery Services vault does not incur additional costs; however infrastructure encryption must be set when configuring the encryption of the vault for the first time and requires customer-managed keys for encryption at rest. Once configured, the infrastructure encryption setting cannot be changed. This recommendation is linked to Ensure that backup data in Recovery Services vaults is encrypted using customer-managed keys (CMK) and should be applied alongside it if you choose to implement this recommendation.",
    "references": "1. https://learn.microsoft.com/en-us/azure/backup/backup-encryption 2. https://learn.microsoft.com/en-us/cli/azure/backup/vault/encryption 3. https://learn.microsoft.com/en-us/powershell/module/az.recoveryservices/get- azrecoveryservicesvault 4. https://learn.microsoft.com/en-us/powershell/module/az.recoveryservices/set- azrecoveryservicesvaultproperty",
    "function_names": [
      "recovery_services_vault_infrastructure_encryption_enabled",
      "recovery_services_vault_dual_layer_encryption_enabled",
      "recovery_services_vault_platform_encryption_enabled",
      "recovery_services_vault_infra_encryption_enabled"
    ]
  },
  {
    "id": "5.2.5",
    "title": "Ensure public network access on Recovery Services vaults is Disabled",
    "assessment": "Automated",
    "description": "Disable public network access on Recovery Services vaults to prevent exposure to the internet and reduce the risk of unauthorized access. Use private endpoints and Azure Role-Based Access Control (RBAC) to securely manage access within trusted networks.",
    "rationale": "Disabling public network access improves security by ensuring that a Recovery Services vault is not exposed on the public internet. Impact: Disabling public network access on Recovery Services vaults restricts access to the vault. This enhances security but may require the configuration of private endpoints for any services or users needing access within trusted networks.",
    "audit": "Audit from Azure Portal 1. Go to Recovery Services vaults. 2. Click the name of a vault. 3. Under Settings, click Networking. 4. Under Public access, ensure that Public network access is set to Deny. 5. Repeat steps 1-4 for each Recovery Services vault. Audit from Azure CLI Run the following command to list Recovery Services vaults: az backup vault list For each Recovery Services vault, run the following command: az backup vault show --resource-group <resource-group> --name <recovery- services-vault> Ensure that under properties, publicNetworkAccess is set to Disabled.  Audit from PowerShell Run the following command to list Recovery Services vaults: Get-AzRecoveryServicesVault Run the following command to get the vault in a resource group with a given name: $vault = Get-AzRecoveryServicesVault -ResourceGroupName <resource-group> - Name <recovery-services-vault> Run the following command to get the public network access setting for the vault: $vault.Properties.PublicNetworkAccess Ensure that the command returns Disabled. Repeat for each Recovery Services vault.",
    "remediation": "Remediate from Azure Portal 1. Go to Recovery Services vaults. 2. Click the name of a vault. 3. Under Settings, click Networking. 4. Under Public access, click the radio button next to Deny. 5. Click Apply. 6. Repeat steps 1-5 for each Recovery Services vault requiring remediation. Remediate from Azure CLI For each Recovery Services vault requiring remediation, run the following command to disable public network access: az backup vault update --resource-group <resource-group> --name <recovery- services-vault> --public-network-access Disable Remediate from PowerShell For each Recovery Services vault requiring remediation, run the following command to disable public network access: Update-AzRecoveryServicesVault -ResourceGroupName <resource-group> -Name <recovery-services-vault> -PublicNetworkAccess \"Disabled\" Default Value: Public network access is enabled by default on Recovery Services vaults. References: 1. https://learn.microsoft.com/en-us/azure/backup/private-endpoints#deny-public- network-access-to-the-vault 2. https://learn.microsoft.com/en-us/cli/azure/backup/vault?view=azure-cli-latest#az- backup-vault-list 3. https://learn.microsoft.com/en-us/cli/azure/backup/vault?view=azure-cli-latest#az- backup-vault-show 4. https://learn.microsoft.com/en-us/cli/azure/backup/vault?view=azure-cli-latest#az- backup-vault-update 5. https://learn.microsoft.com/en-us/powershell/module/az.recoveryservices/get- azrecoveryservicesvault?view=azps-12.4.0 6. https://learn.microsoft.com/en-us/powershell/module/az.recoveryservices/update- azrecoveryservicesvault?view=azps-12.4.0 Additional Information: Private endpoints for Backup can be only created for Recovery Services vaults that don't have any items protected to it. Azure recommends creating a new vault, and outlines a recommended workflow for disabling public network access and creating private endpoints in the following guides: • Create and use private endpoints (v1 experience) for Azure Backup • Create and use private endpoints (v2 experience) for Azure Backup",
    "profile_applicability": "•  Level 1",
    "impact": "Disabling public network access on Recovery Services vaults restricts access to the vault. This enhances security but may require the configuration of private endpoints for any services or users needing access within trusted networks.",
    "references": "1. https://learn.microsoft.com/en-us/azure/backup/private-endpoints#deny-public- network-access-to-the-vault 2. https://learn.microsoft.com/en-us/cli/azure/backup/vault?view=azure-cli-latest#az- backup-vault-list 3. https://learn.microsoft.com/en-us/cli/azure/backup/vault?view=azure-cli-latest#az- backup-vault-show 4. https://learn.microsoft.com/en-us/cli/azure/backup/vault?view=azure-cli-latest#az- backup-vault-update 5. https://learn.microsoft.com/en-us/powershell/module/az.recoveryservices/get- azrecoveryservicesvault?view=azps-12.4.0 6. https://learn.microsoft.com/en-us/powershell/module/az.recoveryservices/update- azrecoveryservicesvault?view=azps-12.4.0 Additional Information: Private endpoints for Backup can be only created for Recovery Services vaults that don't have any items protected to it. Azure recommends creating a new vault, and outlines a recommended workflow for disabling public network access and creating private endpoints in the following guides: • Create and use private endpoints (v1 experience) for Azure Backup • Create and use private endpoints (v2 experience) for Azure Backup",
    "function_names": [
      "recovery_services_vault_public_network_access_disabled",
      "recovery_services_vault_private_endpoint_enabled",
      "recovery_services_vault_network_access_restricted",
      "recovery_services_vault_public_access_blocked",
      "recovery_services_vault_private_network_only"
    ]
  },
  {
    "id": "5.2.6",
    "title": "Ensure 'Cross Region Restore' is set to 'Enabled' on Recovery Services vaults",
    "assessment": "Automated",
    "description": "Cross region restore enables data restoration in a secondary Azure paired region, even when the primary region is fully operational. This allows organizations to conduct drills and validate regional resiliency, thereby ensuring preparedness for potential outages.",
    "rationale": "Enabling cross region restore facilitates proactive resilience testing and disaster recovery planning by allowing data restoration drills in a secondary region without needing a primary region outage. This capability helps organizations validate recovery processes, identify gaps in regional failover, and ensures critical data can be accessed and restored during real disruptions. Impact: Enabling cross region restore on a Recovery Services vault incurs additional costs, and once it is enabled, it cannot be disabled. • Cross region restore can only be enabled on Recovery Services vaults using the GRS replication type. • Cross region restore is available for Azure Virtual Machines, SQL/SAP HANA databases running inside Azure VMs, and Recovery Services Agent (Preview) in the vault. There is no support for classic VMs. • Cross region restore is currently an irreversible storage property. • When cross region restore is enabled, Azure upgrades backup storage from GRS to read-access geo-redundant storage (RA-GRS). Pricing is updated accordingly.",
    "audit": "Audit from Azure Portal 1. Go to Recovery Services vaults. 2. Click the name of a Recovery Services vault. 3. Under Settings, click Properties. 4. Under Backup Configuration, click Update. 5. Next to Cross Region Restore, ensure the radio button next to Enabled is selected. 6. Repeat steps 1-5 for each Recovery Services vault. Audit from Azure CLI Run the following command to list Recovery Services vaults: az backup vault list For each Recovery Services vault, run the following command: az backup vault show --resource-group <resource-group> --name <recovery- services-vault> Ensure that under properties > redundancySettings, crossRegionRestore is set to Enabled. Audit from PowerShell Run the following command to list Recovery Services vaults: Get-AzRecoveryServicesVault Run the following command to get the Recovery Services vault in a resource group with a given name: $vault = Get-AzRecoveryServicesVault -ResourceGroupName <resource-group> - Name <recovery-services-vault> Run the following command to get the cross region restore setting for the Recovery Services vault: $vault.Properties.RedundancySettings.CrossRegionRestore Ensure that the command returns Enabled. Repeat for each Recovery Services vault.",
    "remediation": "Remediate from Azure Portal 1. Go to Recovery Services vaults. 2. Click the name of a Recovery Services vault. 3. Under Settings, click Properties. 4. Under Backup Configuration, click Update. 5. Next to Cross Region Restore, select the radio button next to Enabled. 6. Click Apply. 7. Repeat steps 1-6 for each Recovery Services vault requiring remediation. Remediate from Azure CLI For each Recovery Services vault requiring remediation, run the following command to enable cross region restore: az backup vault update --resource-group <resource-group> --name <recovery- services-vault> --cross-region-restore-flag Enabled  Remediate from PowerShell Run the following command to get the Recovery Services vault in a resource group with a given name: $vault = Get-AzRecoveryServicesVault -ResourceGroupName <resource-group> - Name <recovery-services-vault> Run the following command to enable cross region restore: Set-AzRecoveryServicesBackupProperty -Vault $vault -EnableCrossRegionRestore Repeat for each Recovery Services vault requiring remediation. Default Value: Cross region restore is disabled by default on Recovery Services vaults. References: 1. https://learn.microsoft.com/en-us/azure/backup/backup-create-recovery-services- vault#set-cross-region-restore 2. https://learn.microsoft.com/en-us/cli/azure/backup/vault 3. https://learn.microsoft.com/en-us/powershell/module/az.recoveryservices/get- azrecoveryservicesvault 4. https://learn.microsoft.com/en-us/powershell/module/az.recoveryservices/set- azrecoveryservicesbackupproperty",
    "profile_applicability": "•  Level 2",
    "impact": "Enabling cross region restore on a Recovery Services vault incurs additional costs, and once it is enabled, it cannot be disabled. • Cross region restore can only be enabled on Recovery Services vaults using the GRS replication type. • Cross region restore is available for Azure Virtual Machines, SQL/SAP HANA databases running inside Azure VMs, and Recovery Services Agent (Preview) in the vault. There is no support for classic VMs. • Cross region restore is currently an irreversible storage property. • When cross region restore is enabled, Azure upgrades backup storage from GRS to read-access geo-redundant storage (RA-GRS). Pricing is updated accordingly.",
    "references": "1. https://learn.microsoft.com/en-us/azure/backup/backup-create-recovery-services- vault#set-cross-region-restore 2. https://learn.microsoft.com/en-us/cli/azure/backup/vault 3. https://learn.microsoft.com/en-us/powershell/module/az.recoveryservices/get- azrecoveryservicesvault 4. https://learn.microsoft.com/en-us/powershell/module/az.recoveryservices/set- azrecoveryservicesbackupproperty",
    "function_names": [
      "recovery_services_vault_cross_region_restore_enabled",
      "recovery_services_vault_restore_secondary_region_enabled",
      "recovery_services_vault_regional_resiliency_enabled",
      "recovery_services_vault_secondary_region_restore_enabled",
      "recovery_services_vault_cross_region_recovery_enabled"
    ]
  },
  {
    "id": "5.2.7",
    "title": "Ensure 'Cross Subscription Restore' is set to 'Disabled' or 'Permanently Disabled' on Recovery Services vaults",
    "assessment": "Automated",
    "description": "Disable cross subscription restore for Recovery Services vaults to ensure that backup data can only be restored within the same subscription as the Recovery Services vault, preventing restoration to targets in other subscriptions.",
    "rationale": "Cross subscription restores increases security risks by widening access to sensitive backup data, potentially leading to accidental or intentional exposure, unauthorized access, or data exfiltration across environments. Impact: Organizations may need to consider alternatives for disaster recovery scenarios, and if utilizing multiple subscriptions, may need to make adjustments or consider alternatives for data access. Costs could be incurred if alternative or additional backup infrastructure is required to account for the disabling of cross subscription restore.",
    "audit": "Audit from Azure Portal 1. Go to Recovery Services vaults. 2. Click the name of a Recovery Services vault. 3. Under Settings, click Properties. 4. Under Cross Subscription Restore, click Update. 5. Ensure that Disable Cross Subscription Restore or Permanently disable Cross Subscription Restore on this vault is selected. 6. Repeat steps 1-5 for each Recovery Services vault. Audit from Azure CLI Run the following command to list Recovery Services vaults: az backup vault list For each Recovery Services vault, run the following command: az backup vault show --resource-group <resource-group> --name <recovery- services-vault> Ensure that under properties > restoreSettings > crossSubscriptionRestoreSettings, crossSubscriptionRestoreState is set to Disabled or PermanentlyDisabled. Audit from PowerShell Run the following command to list Recovery Services vaults: Get-AzRecoveryServicesVault Run the following command to get the Recovery Services vault in a resource group with a given name: $vault = Get-AzRecoveryServicesVault -ResourceGroupName <resource-group> - Name <recovery-services-vault> Run the following command to get the cross subscription restore setting for the Recovery Services vault: $vault.Properties.RestoreSettings.CrossSubscriptionRestoreSettings.CrossSubsc riptionRestoreState Ensure that the command returns Disabled or PermanentlyDisabled. Repeat for each Recovery Services vault. Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: f19b0c83-716f-4b81-85e3-2dbf057c35d6 • Name: '[Preview]: Disable Cross Subscription Restore for Azure Recovery Services vaults'",
    "remediation": "Remediate from Azure Portal 1. Go to Recovery Services vaults. 2. Click the name of a Recovery Services vault. 3. Under Settings, click Properties. 4. Under Cross Subscription Restore, click Update. 5. Select the radio button next to Disable Cross Subscription Restore or Permanently disable Cross Subscription Restore on this vault. 6. If selecting to permanently disable cross subscription restore, check the box next to Are you sure you want to permanently disable Cross Subscription Restore? Once disabled, it cannot be re-enabled. 7. Click Update. 8. Repeat steps 1-7 for each Recovery Services vault requiring remediation. Remediate from Azure CLI For each Recovery Services vault requiring remediation, run the following command to disable cross subscription restore: az backup vault update --resource-group <resource-group> --name <recovery- services-vault> --cross-subscription-restore-state Disable Note: Use --cross-subscription-restore-state PermanentlyDisable with the above command to permanently disable cross subscription restore. Remediate from PowerShell For each Recovery Services vault requiring remediation, run the following command to disable cross subscription restore: Update-AzRecoveryServicesVault -ResourceGroupName <resource-group> -Name <rescovery-services-vault> -CrossSubscriptionRestoreState Disabled Note: Use -CrossSubscriptionRestoreState PermanentlyDisabled with the above command to permanently disable cross subscription restore. Default Value: Cross subscription restore is enabled by default on Recovery Services vaults. References: 1. https://learn.microsoft.com/en-us/cli/azure/backup/vault 2. https://learn.microsoft.com/en-us/powershell/module/az.recoveryservices/get- azrecoveryservicesvault 3. https://learn.microsoft.com/en-us/powershell/module/az.recoveryservices/update- azrecoveryservicesvault 4. https://learn.microsoft.com/en-us/azure/backup/backup-azure-arm-restore- vms#cross-subscription-restore-for-azure-vm Additional Information: If cross subscription restore is permanently disabled on a vault, it cannot be re-enabled.",
    "profile_applicability": "•  Level 1",
    "impact": "Organizations may need to consider alternatives for disaster recovery scenarios, and if utilizing multiple subscriptions, may need to make adjustments or consider alternatives for data access. Costs could be incurred if alternative or additional backup infrastructure is required to account for the disabling of cross subscription restore.",
    "references": "1. https://learn.microsoft.com/en-us/cli/azure/backup/vault 2. https://learn.microsoft.com/en-us/powershell/module/az.recoveryservices/get- azrecoveryservicesvault 3. https://learn.microsoft.com/en-us/powershell/module/az.recoveryservices/update- azrecoveryservicesvault 4. https://learn.microsoft.com/en-us/azure/backup/backup-azure-arm-restore- vms#cross-subscription-restore-for-azure-vm Additional Information: If cross subscription restore is permanently disabled on a vault, it cannot be re-enabled.",
    "function_names": [
      "recovery_services_vault_cross_subscription_restore_disabled",
      "recovery_services_vault_cross_subscription_restore_permanently_disabled",
      "recovery_services_vault_restore_scope_same_subscription",
      "recovery_services_vault_backup_restore_subscription_locked"
    ]
  },
  {
    "id": "8.1",
    "title": "Ensure soft delete for Azure File Shares is Enabled",
    "assessment": "Automated",
    "description": "Azure Files offers soft delete for file shares, allowing you to easily recover your data when it is mistakenly deleted by an application or another storage account user.",
    "rationale": "Important data could be accidentally deleted or removed by a malicious actor. With soft delete enabled, the data is retained for the defined retention period before permanent deletion, allowing for recovery of the data. Impact: When a file share is soft-deleted, the used portion of the storage is charged for the indicated soft-deleted period. All other meters are not charged unless the share is restored.",
    "audit": "Audit from Azure Portal 1. Go to Storage Accounts. 2. For each storage account with file shares, under Data storage, click on File shares. 3. Under File share settings, ensure the value for Soft delete shows a number of days between 1 and 365, inclusive. Audit from Azure CLI Run the following command to list storage accounts: az storage account list Run the following command to determine if a storage account has file shares: az storage share list --account-name <storage-account> For each storage account with file shares, run the following command: az storage account file-service-properties show --resource-group <resource- group> --account-name <storage-account> Ensure that under shareDeleteRetentionPolicy, enabled is set to true, and days is set to an appropriate value between 1 and 365, inclusive. Audit from PowerShell Run the following command to list storage accounts: Get-AzStorageAccount -ResourceGroupName <resource-group> With a storage account context set, run the following command to determine if a storage account has file shares: Get-AzStorageShare For each storage account with file shares, run the following command: Get-AzStorageFileServiceProperty -ResourceGroupName <resource-group> - AccountName <storage-account> Ensure that ShareDeleteRetentionPolicy.Enabled is set to True and ShareDeleteRetentionPolicy.Days is set to an appropriate value between 1 and 365, inclusive.",
    "remediation": "Remediate from Azure Portal 1. Go to Storage Accounts. 2. For each storage account with file shares, under Data storage, click File shares. 3. Under File share settings, click the value next to Soft delete. 4. Under Soft delete for all file shares, click the toggle to set it to Enabled. 5. Under Retention policies, set an appropriate number of days to retain soft deleted data between 1 and 365, inclusive. 6. Click Save. Remediate from Azure CLI For each storage account requiring remediation, run the following command to enable soft delete for file shares and set an appropriate number of days for deleted data to be retained, between 1 and 365, inclusive: az storage account file-service-properties update --account-name <storage- account> --enable-delete-retention true --delete-retention-days <retention- days> Remediate from PowerShell For each storage account requiring remediation, run the following command to enable soft delete for file shares and set an appropriate number of days for deleted data to be retained, between 1 and 365, inclusive: Update-AzStorageFileServiceProperty -ResourceGroupName <resource-group> - AccountName <storage-account> -EnableShareDeleteRetentionPolicy $true - ShareRetentionDays <retention-days> Default Value: Soft delete is enabled by default at the storage account file share setting level. References: 1. https://learn.microsoft.com/en-us/azure/storage/files/storage-files-enable-soft- delete 2. https://learn.microsoft.com/en-us/cli/azure/storage/account/file-service-properties 3. https://learn.microsoft.com/en-us/powershell/module/az.storage/get- azstoragefileserviceproperty 4. https://learn.microsoft.com/en-us/powershell/module/az.storage/update- azstoragefileserviceproperty 5. https://learn.microsoft.com/en-us/azure/storage/files/storage-files-prevent-file- share-deletion",
    "profile_applicability": "•  Level 1",
    "impact": "When a file share is soft-deleted, the used portion of the storage is charged for the indicated soft-deleted period. All other meters are not charged unless the share is restored.",
    "references": "1. https://learn.microsoft.com/en-us/azure/storage/files/storage-files-enable-soft- delete 2. https://learn.microsoft.com/en-us/cli/azure/storage/account/file-service-properties 3. https://learn.microsoft.com/en-us/powershell/module/az.storage/get- azstoragefileserviceproperty 4. https://learn.microsoft.com/en-us/powershell/module/az.storage/update- azstoragefileserviceproperty 5. https://learn.microsoft.com/en-us/azure/storage/files/storage-files-prevent-file- share-deletion",
    "function_names": [
      "storage_file_share_soft_delete_enabled",
      "storage_file_share_recovery_retention_enabled",
      "storage_file_share_protection_enabled",
      "storage_file_share_deletion_recovery_enabled",
      "storage_file_share_soft_delete_retention_configured"
    ]
  },
  {
    "id": "8.2",
    "title": "Ensure root squash for NFS file shares is configured",
    "assessment": "Automated",
    "description": "Permissions for NFS file shares are enforced by the client OS rather than by the Azure Files service. Root squash is an administrative security feature in NFS that prevents unauthorized root-level access to the NFS server by client machines. This functionality is an important part of protecting user data and system settings from manipulation by untrusted or compromised clients.",
    "rationale": "Administrators should enable root squash in environments where multiple users or systems access the NFS share, especially in scenarios where client machines are not fully trusted. By converting root users to anonymous users, root squash ensures that even if a client machine is compromised, the attacker cannot exploit root privileges to access or modify critical files on the NFS server. Impact: There is no additional cost associated with enabling root squash; however, there may be some minor administrative overhead involved in configuring and managing permissions with root squash enabled.",
    "audit": "Audit from Azure Portal 1. Go to Storage accounts. 2. For each storage account with NFS file shares, under Data storage, click File shares. 3. Click the name of an NFS file share. 4. Click Properties. 5. Under ROOT SQUASH, ensure that Root Squash is selected. 6. Repeat steps 1-5 for each NFS file share in each storage account. Audit from Azure CLI Run the following command to list storage accounts: az storage account list For each storage account, run the following command to list file shares: az storage share list --account-name <storage-account> For each file share with \"protocols\": [ \"NFS\" ], ensure that rootSquash is set to RootSquash. Audit from PowerShell Run the following command to list storage accounts: Get-AzStorageAccount -ResourceGroupName <resource-group> For each storage account, run the following command to list file shares: Get-AzRmStorageShare -ResourceGroupName <resource-group> -StorageAccountName <storage-account> For each NFS file share, run the following command to get the root squash configuration: Get-AzRmStorageShare -ResourceGroupName <resource-group> -StorageAccountName <storage-account> -Name <nfs-file-share> | fl -Property RootSquash Ensure that RootSquash is set to RootSquash.",
    "remediation": "Remediate from Azure Portal 1. Go to Storage accounts. 2. For each storage account with NFS file shares, under Data storage, click File shares. 3. Click the name of an NFS file share. 4. Click Properties. 5. Under ROOT SQUASH, select Root Squash from the drop-down menu. 6. Click Save. 7. Repeat steps 1-6 for each NFS file share requiring remediation in each storage account. Remediate from Azure CLI For each NFS file share requiring remediation, run the following command to enable root squash: az storage share-rm update --resource-group <resource-group> --storage- account <storage-account> --name <nfs-file-share> --root-squash RootSquash Remediate from PowerShell For each NFS file share requiring remediation, run the following command to enable root squash: Update-AzRmStorageShare -ResourceGroupName <resource-group> - StorageAccountName <storage-account> -Name <nfs-file-share> -RootSquash RootSquash Default Value: Root squash is disabled by default on NFS Azure file shares. References: 1. https://learn.microsoft.com/en-us/azure/storage/files/nfs-root-squash 2. https://learn.microsoft.com/en-us/cli/azure/storage/account 3. https://learn.microsoft.com/en-us/cli/azure/storage/share 4. https://learn.microsoft.com/en-us/cli/azure/storage/share-rm 5. https://learn.microsoft.com/en-us/powershell/module/az.storage/get- azstorageaccount 6. https://learn.microsoft.com/en-us/powershell/module/az.storage/get- azrmstorageshare 7. https://learn.microsoft.com/en-us/powershell/module/az.storage/update- azrmstorageshare Additional Information: There are three root squash settings: • No root squash: Turn off root squashing. This option is mainly useful for diskless clients or workloads as specified by workload documentation. This is the default setting when creating a new NFS Azure file share. • All squash: Map all UIDs and GIDs to the anonymous user. This is useful for shares that require read-only access by all clients. • Root squash: Map requests from UID/GID 0 (root) to the anonymous UID/GID. This does not apply to any other UIDs or GIDs that might be equally sensitive, such as the user bin or group staff. All squash may be appropriate for highly restricted environments where no client-side user (including root) should have specific privileges on the NFS file share.",
    "profile_applicability": "•  Level 1",
    "impact": "There is no additional cost associated with enabling root squash; however, there may be some minor administrative overhead involved in configuring and managing permissions with root squash enabled.",
    "references": "1. https://learn.microsoft.com/en-us/azure/storage/files/nfs-root-squash 2. https://learn.microsoft.com/en-us/cli/azure/storage/account 3. https://learn.microsoft.com/en-us/cli/azure/storage/share 4. https://learn.microsoft.com/en-us/cli/azure/storage/share-rm 5. https://learn.microsoft.com/en-us/powershell/module/az.storage/get- azstorageaccount 6. https://learn.microsoft.com/en-us/powershell/module/az.storage/get- azrmstorageshare 7. https://learn.microsoft.com/en-us/powershell/module/az.storage/update- azrmstorageshare Additional Information: There are three root squash settings: • No root squash: Turn off root squashing. This option is mainly useful for diskless clients or workloads as specified by workload documentation. This is the default setting when creating a new NFS Azure file share. • All squash: Map all UIDs and GIDs to the anonymous user. This is useful for shares that require read-only access by all clients. • Root squash: Map requests from UID/GID 0 (root) to the anonymous UID/GID. This does not apply to any other UIDs or GIDs that might be equally sensitive, such as the user bin or group staff. All squash may be appropriate for highly restricted environments where no client-side user (including root) should have specific privileges on the NFS file share.",
    "function_names": [
      "storage_file_share_root_squash_enabled",
      "nfs_share_root_squash_configured",
      "file_share_root_squash_enforced",
      "nfs_export_root_squash_required",
      "storage_nfs_root_squash_secure"
    ]
  },
  {
    "id": "8.3",
    "title": "Ensure 'SMB protocol version' is set to 'SMB 3.1.1' or higher for SMB file shares",
    "assessment": "Automated",
    "description": "Ensure that SMB file shares are configured to use the latest supported SMB protocol version. Keeping the SMB protocol updated helps mitigate risks associated with older SMB versions, which may contain vulnerabilities and lack essential security controls.",
    "rationale": "Using the latest supported SMB protocol version enhances the security of SMB file shares by preventing the exploitation of known vulnerabilities in outdated SMB versions. Impact: Using the latest SMB protocol version may impact client compatibility.",
    "audit": "Audit from Azure Portal 1. Go to Storage accounts. 2. Click the name of a storage account. 3. Under Data storage, click File shares. 4. Under File share settings, click the link next to Security. 5. Under SMB protocol versions, ensure that SMB3.1.1 is the only checked protocol version. 6. Repeat steps 1-5 for each storage account. Audit from Azure CLI Run the following command to list storage accounts: az storage account list For each storage account, run the following command: az storage account file-service-properties show --resource-group <resource- group> --account-name <storage-account> Ensure that under protocolSettings > smb, versions is set to SMB3.1.1; only.  Audit from PowerShell Run the following command to list storage accounts: Get-AzStorageAccount Run the following command to get the file service properties for a storage account in a resource group with a given name: $storageaccountfileservice = Get-AzStorageFileServiceProperty - ResourceGroupName <resource-group> -AccountName <storage-account> Run the following command to get the SMB protocol version setting: $storageaccountfileservice.ProtocolSettings.Smb.Versions Ensure that the command returns SMB3.1.1 only. Repeat for each storage account.",
    "remediation": "Remediate from Azure Portal 1. Go to Storage accounts. 2. Click the name of a storage account. 3. Under Data storage, click File shares. 4. Under File share settings, click the link next to Security. 5. If Profile is set to Maximum compatibility, click the drop-down menu and select Maximum security or Custom. 6. If selecting Custom, under SMB protocol versions, uncheck the boxes next to SMB 2.1 and SMB 3.0. 7. Click Save. 8. Repeat steps 1-7 for each storage account requiring remediation. Remediate from Azure CLI For each storage account requiring remediation, run the following command to set the SMB protocol version: az storage account file-service-properties update --resource-group <resource- group> --account-name <storage-account> --versions SMB3.1.1 Remediate from PowerShell For each storage account requiring remediation, run the following command to set the SMB protocol version: Update-AzStorageFileServiceProperty -ResourceGroupName <resource-group> - StorageAccountName <storage-account> -SmbProtocolVersion SMB3.1.1 Default Value: By default, all SMB versions are allowed. References: 1. https://learn.microsoft.com/en-us/azure/well-architected/service-guides/azure- files#recommendations-for-smb-file-shares 2. https://learn.microsoft.com/en-us/azure/storage/files/files-smb-protocol#smb- security-settings 3. https://learn.microsoft.com/en-us/cli/azure/storage/account/file-service-properties 4. https://learn.microsoft.com/en-us/powershell/module/az.storage/get- azstoragefileserviceproperty 5. https://learn.microsoft.com/en-us/powershell/module/az.storage/update- azstoragefileserviceproperty",
    "profile_applicability": "•  Level 1",
    "impact": "Using the latest SMB protocol version may impact client compatibility.",
    "references": "1. https://learn.microsoft.com/en-us/azure/well-architected/service-guides/azure- files#recommendations-for-smb-file-shares 2. https://learn.microsoft.com/en-us/azure/storage/files/files-smb-protocol#smb- security-settings 3. https://learn.microsoft.com/en-us/cli/azure/storage/account/file-service-properties 4. https://learn.microsoft.com/en-us/powershell/module/az.storage/get- azstoragefileserviceproperty 5. https://learn.microsoft.com/en-us/powershell/module/az.storage/update- azstoragefileserviceproperty",
    "function_names": [
      "storage_file_share_smb_protocol_version_min_3_1_1",
      "storage_file_share_smb_protocol_version_up_to_date",
      "storage_file_share_smb_protocol_version_secure",
      "storage_file_share_smb_protocol_version_compliant",
      "storage_file_share_smb_protocol_version_latest"
    ]
  },
  {
    "id": "8.4",
    "title": "Ensure 'SMB channel encryption' is set to 'AES-256-GCM' or higher for SMB file shares",
    "assessment": "Automated",
    "description": "Implement SMB channel encryption with AES-256-GCM for SMB file shares to ensure data confidentiality and integrity in transit. This method offers strong protection against eavesdropping and man-in-the-middle attacks, safeguarding sensitive information.",
    "rationale": "AES-256-GCM encryption enhances the security of data transmitted over SMB channels by safeguarding it from unauthorized interception and tampering. Impact: Using the AES-256-GCM SMB channel encryption may impact client compatibility.",
    "audit": "Audit from Azure Portal 1. Go to Storage accounts. 2. Click the name of a storage account. 3. Under Data storage, click File shares. 4. Under File share settings, click the link next to Security. 5. Under SMB channel encryption, ensure that AES-256-GCM, or higher, is the only checked SMB channel encryption setting. 6. Repeat steps 1-5 for each storage account. Audit from Azure CLI Run the following command to list storage accounts: az storage account list For each storage account, run the following command: az storage account file-service-properties show --resource-group <resource- group> --account-name <storage-account> Ensure that under protocolSettings > smb, channelEncryption is set to AES-256- GCM;, or higher, only.  Audit from PowerShell Run the following command to list storage accounts: Get-AzStorageAccount Run the following command to get the file service properties for a storage account in a resource group with a given name: $storageaccountfileservice = Get-AzStorageFileServiceProperty - ResourceGroupName <resource-group> -AccountName <storage-account> Run the following command to get the SMB channel encryption setting: $storageaccountfileservice.ProtocolSettings.Smb.ChannelEncryption Ensure that the command returns AES-256-GCM, or higher, only. Repeat for each storage account.",
    "remediation": "Remediate from Azure Portal 1. Go to Storage accounts. 2. Click the name of a storage account. 3. Under Data storage, click File shares. 4. Under File share settings, click the link next to Security. 5. If Profile is set to Maximum compatibility, click the drop-down menu and select Maximum security or Custom. 6. If selecting Custom, under SMB channel encryption, uncheck the boxes next to AES-128-CCM and AES-128-GCM. 7. Click Save. 8. Repeat steps 1-7 for each storage account requiring remediation. Remediate from Azure CLI For each storage account requiring remediation, run the following command to set the SMB channel encryption: az storage account file-service-properties update --resource-group <resource- group> --account-name <storage-account> --channel-encryption AES-256-GCM Remediate from PowerShell For each storage account requiring remediation, run the following command to set the SMB channel encryption: Update-AzStorageFileServiceProperty -ResourceGroupName <resource-group> - StorageAccountName <storage-account> -SmbChannelEncryption AES-256-GCM Default Value: By default, the following SMB channel encryption algorithms are allowed: • AES-128-CCM • AES-128-GCM • AES-256-GCM References: 1. https://learn.microsoft.com/en-us/azure/well-architected/service-guides/azure- files#recommendations-for-smb-file-shares 2. https://learn.microsoft.com/en-us/azure/storage/files/files-smb- protocol?tabs=azure-portal#smb-security-settings 3. https://learn.microsoft.com/en-us/cli/azure/storage/account/file-service-properties 4. https://learn.microsoft.com/en-us/powershell/module/az.storage/get- azstoragefileserviceproperty 5. https://learn.microsoft.com/en-us/powershell/module/az.storage/update- azstoragefileserviceproperty",
    "profile_applicability": "•  Level 1",
    "impact": "Using the AES-256-GCM SMB channel encryption may impact client compatibility.",
    "references": "1. https://learn.microsoft.com/en-us/azure/well-architected/service-guides/azure- files#recommendations-for-smb-file-shares 2. https://learn.microsoft.com/en-us/azure/storage/files/files-smb- protocol?tabs=azure-portal#smb-security-settings 3. https://learn.microsoft.com/en-us/cli/azure/storage/account/file-service-properties 4. https://learn.microsoft.com/en-us/powershell/module/az.storage/get- azstoragefileserviceproperty 5. https://learn.microsoft.com/en-us/powershell/module/az.storage/update- azstoragefileserviceproperty",
    "function_names": [
      "smb_file_share_channel_encryption_aes_256_gcm",
      "smb_file_share_channel_encryption_min_aes_256_gcm",
      "smb_file_share_encryption_aes_256_gcm_or_higher",
      "smb_share_channel_encryption_aes_256_gcm",
      "smb_share_channel_encryption_min_aes_256_gcm"
    ]
  },
  {
    "id": "10.1",
    "title": "Ensure 'Encryption key source' is set to 'Customer Managed Key' for Azure NetApp Files accounts",
    "assessment": "Automated",
    "description": "Customer-managed keys (CMK) for Azure NetApp Files volume encryption enable organizations to use their own keys instead of platform-managed ones, providing full control over encryption.",
    "rationale": "Using customer-managed keys (CMKs) to encrypt Azure NetApp Files volumes enhances security by granting organizations complete control over their encryption keys. Impact: There are costs and configuration overhead associated with setting up and managing customer-managed keys.",
    "audit": "Audit from Azure Portal 1. Go to Azure NetApp Files. 2. Click the name of a NetApp account. 3. Under Azure NetApp Files, click Encryption. 4. Ensure that Encryption key source is set to Customer Managed Key. 5. Repeat steps 1-4 for each NetApp Files account. Audit from Azure CLI Run the following command to list NetApp Files accounts: az netappfiles account list For each NetApp Files account, run the following command: az netappfiles account show --resource-group <resource-group> --account-name <netapp-files-account> Ensure that under encryption, keySource is set to Microsoft.KeyVault.  Audit from PowerShell Run the following command to install the Az.NetAppFiles module: Install-Module Az.NetAppFiles Enter Y when prompted. Run the following command to list NetApp Files accounts: Get-AzResource | ? {$_.ResourceType -like 'Microsoft.NetApp/netAppAccounts'} | Format-Table Run the following command to get the NetApp Files account in a resource group with a given name: $netapp = Get-AzNetAppFilesAccount -ResourceGroupName <resource-group> -Name <netapp-files-account> Run the following command to get the encryption key source for the NetApp Files account: $netapp.Encryption.KeySource Ensure that the command returns Microsoft.KeyVault. Repeat for each NetApp Files account.",
    "remediation": "Remediate from Azure Portal 1. Go to Azure NetApp Files. 2. Click the name of a NetApp account. 3. Under Azure NetApp Files, click Encryption. 4. Next to Encryption key source, click the radio button next to Customer Managed Key. 5. Next to Encryption key, click the radio button next to Enter key URI to provide a known key URI, or click the radio button next to Select from key vault to select a key from a key vault. 6. If entering a key URI, provide the key URI in the text box next to Key URI. 7. If selecting a key from a key vault, click Select a key vault and key. 1. From the drop-down menu next to Key vault, select a key vault. 2. From the drop-down menu next to Key, select a key. 3. Click Select. 8. Next to Identity type, click the radio button next to System-assigned to use a system-assigned managed identity, or click the radio button next to User- assigned to use a user-assigned managed identity. 9. If selecting a user-assigned managed identity, next to User-assigned identity, click Select an identity. 1. In the filter box, type to filter by identity name and/or resource group name. 2. Check the box next to a managed identity. 3. Click Add. 10. Click Save. 11. Repeat steps 1-10 for each NetApp Files account. Remediate from Azure CLI For each NetApp Files account requiring remediation, run the following command to assign a customer-managed encryption key: az netappfiles account update --resource-group <resource-group> --account- name <netapp-files-account> --key-source Microsoft.KeyVault --key-name <key- name> --key-vault-uri <key-vault-uri> --keyvault-resource-id <key-vault- resource-id> --identity-type SystemAssigned Note: Use --identity-type UserAssigned --user-assigned-identity <user- assigned-identity-id> with the above command to provide a UserAssigned Identity Id. Default Value: By default, data in the NetApp Files account is encrypted using Microsoft-managed keys. References: 1. https://learn.microsoft.com/en-us/azure/azure-netapp-files/configure-customer- managed-keys 2. https://learn.microsoft.com/en-us/cli/azure/netappfiles 3. https://learn.microsoft.com/en-us/powershell/module/az.netappfiles/get- aznetappfilesaccount",
    "profile_applicability": "•  Level 2",
    "impact": "There are costs and configuration overhead associated with setting up and managing customer-managed keys.",
    "references": "1. https://learn.microsoft.com/en-us/azure/azure-netapp-files/configure-customer- managed-keys 2. https://learn.microsoft.com/en-us/cli/azure/netappfiles 3. https://learn.microsoft.com/en-us/powershell/module/az.netappfiles/get- aznetappfilesaccount",
    "function_names": [
      "netapp_files_account_encryption_key_customer_managed",
      "netapp_files_volume_encryption_key_customer_managed",
      "netapp_files_account_encryption_key_source_valid",
      "netapp_files_volume_encryption_key_source_valid"
    ]
  },
  {
    "id": "11.1",
    "title": "Ensure 'Allowed Protocols' for shared access signature (SAS) tokens is set to 'HTTPS Only'",
    "assessment": "Manual",
    "description": "Shared access signatures (SAS) can be used to grant limited access to Azure Storage resources. When generating a SAS, it is possible to specify the allowed protocols for a request made with the SAS. It is recommended to allow requests over HTTPS only.",
    "rationale": "If a SAS is passed over HTTP and intercepted, an attacker performing a man-in-the- middle attack can read the SAS. Then, they can use that SAS just as the intended user could have. This can potentially compromise sensitive data or allow for data corruption by the malicious user. Impact: SAS can pose security risks if they are not managed carefully.",
    "audit": "It is not possible to audit generated SAS.",
    "remediation": "Remediate from Azure Portal If SAS have been created to allow HTTP and were created with a stored access policy (SAP), the SAS can be revoked by deleting the SAP or updating the SAP expiration time to a time in the past: 1. Go to Storage accounts. 2. Click on a storage account. 3. Under Data storage, click Containers. 4. Click the three dots next to a container. 5. Click Access policy. 6. Click the three dots next to an access policy. 7. Click Delete. 8. Click Save. 9. Repeat steps 1-8 as needed to revoke SAS created with SAP.  If SAS have been created to allow HTTP and were not created with a SAP, the SAS can be revoked by regenerating the storage account access keys: Note: Regenerating access keys can affect any applications or Azure services that are dependent on the storage account key. 1. Go to Storage accounts. 2. Click on a storage account. 3. Under Security + networking, click Access keys. 4. Next to each key, click Rotate key. 5. Click Yes to confirm. 6. Repeat steps 1-5 as needed to revoke SAS. Default Value: When generating a SAS, the default selection for Allowed protocols is HTTPS only. References: 1. https://learn.microsoft.com/en-us/azure/storage/common/storage-sas-overview 2. https://learn.microsoft.com/en-us/azure/storage/common/storage-account-keys- manage Additional Information: This recommendation is based on the recommendation Ensure 'Allowed Protocols' for shared access signature (SAS) tokens is set to 'HTTPS Only', from the Common Reference Recommendations > Secrets and Keys > Shared Access Signatures section.",
    "profile_applicability": "•  Level 1",
    "impact": "SAS can pose security risks if they are not managed carefully.",
    "references": "1. https://learn.microsoft.com/en-us/azure/storage/common/storage-sas-overview 2. https://learn.microsoft.com/en-us/azure/storage/common/storage-account-keys- manage Additional Information: This recommendation is based on the recommendation Ensure 'Allowed Protocols' for shared access signature (SAS) tokens is set to 'HTTPS Only', from the Common Reference Recommendations > Secrets and Keys > Shared Access Signatures section.",
    "function_names": [
      "storage_account_sas_https_only",
      "storage_sas_token_protocol_https",
      "storage_shared_access_signature_https_required",
      "storage_sas_allowed_protocols_https",
      "storage_account_sas_restrict_protocol_https"
    ]
  },
  {
    "id": "11.2",
    "title": "Ensure that shared access signature (SAS) tokens expire within an hour",
    "assessment": "Manual",
    "description": "Shared access signature (SAS) tokens provide restricted access to Azure Storage resources (such as blobs, files, queues, or tables) for a defined time period with specific permissions. It enables users to interact with the resources without exposing account keys, offering precise control over the permitted actions (e.g., read, write) and the duration of access. To minimize security risks, SAS tokens should be configured with the shortest possible lifespan, ideally lasting no longer than an hour.",
    "rationale": "A short lifespan for SAS tokens is recommended to minimize the risk of unauthorized access. SAS tokens grant time-limited access to resources, and a longer duration increases the opportunity for misuse if the token is compromised. By setting a shorter lifespan, the potential for security breaches is reduced. Impact: SAS can pose security risks if they are not managed carefully.",
    "audit": "Currently, SAS token expiration times cannot be audited. Until Microsoft makes the token expiration time a setting rather than a token creation parameter, this recommendation will require manual verification.",
    "remediation": "Remediate from Azure Portal If SAS have been created without a short lifespan and were created with a stored access policy (SAP), the SAS can be revoked by deleting the SAP or updating the SAP expiration time to a time in the past: 1. Go to Storage accounts. 2. Click on a storage account. 3. Under Data storage, click Containers. 4. Click the three dots next to a listed item. 5. Click Access policy. 6. Click the three dots next to an access policy. 7. Click Delete. 8. Click Save. 9. Repeat steps 1-8 as needed to revoke SAS created with SAP. If SAS have been created without a short lifespan and were not created with a SAP, the SAS can be revoked by regenerating the storage account access keys: Note: Regenerating access keys can affect any applications or Azure services that are dependent on the storage account key. 1. Go to Storage accounts. 2. Click on a storage account. 3. Under Security + networking, click Access keys. 4. Next to each key, click Rotate key. 5. Click Yes to confirm. 6. Repeat steps 1-5 as needed to revoke SAS. Default Value: By default, expiration for shared access signature is set to 8 hours. References: 1. https://docs.microsoft.com/en-us/azure/storage/common/storage-sas-overview 2. https://docs.microsoft.com/en-us/rest/api/storageservices/delegating-access- with-a-shared-access-signature Additional Information: This recommendation is based on the recommendation Ensure that shared access signature (SAS) tokens expire within an hour, from the Common Reference Recommendations > Secrets and Keys > Shared Access Signatures section.",
    "profile_applicability": "•  Level 1",
    "impact": "SAS can pose security risks if they are not managed carefully.",
    "references": "1. https://docs.microsoft.com/en-us/azure/storage/common/storage-sas-overview 2. https://docs.microsoft.com/en-us/rest/api/storageservices/delegating-access- with-a-shared-access-signature Additional Information: This recommendation is based on the recommendation Ensure that shared access signature (SAS) tokens expire within an hour, from the Common Reference Recommendations > Secrets and Keys > Shared Access Signatures section.",
    "function_names": [
      "storage_account_sas_token_expiry_within_1h",
      "storage_container_sas_token_expiry_within_1h",
      "storage_blob_sas_token_expiry_within_1h",
      "storage_file_sas_token_expiry_within_1h",
      "storage_queue_sas_token_expiry_within_1h",
      "storage_table_sas_token_expiry_within_1h",
      "storage_sas_token_max_expiry_1h",
      "storage_sas_token_short_lived"
    ]
  },
  {
    "id": "11.3",
    "title": "Ensure that soft delete for blobs on Azure Blob Storage storage accounts is Enabled",
    "assessment": "Automated",
    "description": "Blobs in Azure storage accounts may contain sensitive or personal data, such as ePHI or financial information. Data that is erroneously modified or deleted by an application or a user can lead to data loss or unavailability. It is recommended that soft delete be enabled on Azure storage accounts with blob storage to allow for the preservation and recovery of data when blobs or blob snapshots are deleted.",
    "rationale": "Blobs can be deleted incorrectly. An attacker or malicious user may do this deliberately in order to cause disruption. Deleting an Azure storage blob results in immediate data loss. Enabling this configuration for Azure storage accounts ensures that even if blobs are deleted from the storage account, the blobs are recoverable for a specific period of time, which is defined in the \"Retention policies,\" ranging from 7 to 365 days. Impact: All soft-deleted data is billed at the same rate as active data. Additional costs may be incurred for deleted blobs until the soft delete period ends and the data is permanently removed.",
    "audit": "Audit from Azure Portal 1. Go to Storage Accounts. 2. For each Storage Account with blob storage, under Data management, go to Data protection. 3. Ensure that Enable soft delete for blobs is checked. 4. Ensure that the retention period is a sufficient length for your organization. Audit from Azure CLI Run the following command to list storage accounts: az storage account list Run the following command to determine if a storage account has containers: az storage container list --account-name <storage-account> For each storage account with containers, ensure that the output of the below command contains \"enabled\": true and days is not null: az storage blob service-properties delete-policy show --account-name <storage-account>",
    "remediation": "Remediate from Azure Portal 1. Go to Storage Accounts. 2. For each Storage Account with blob storage, under Data management, go to Data protection. 3. Check the box next to Enable soft delete for blobs. 4. Set the retention period to a sufficient length for your organization. 5. Click Save. Remediate from Azure CLI For each storage account requiring remediation, run the following command to enable soft delete for blobs: az storage blob service-properties delete-policy update --days-retained <retention-days> --account-name <storage-account> --enable true Default Value: Soft delete for blob storage is enabled by default on storage accounts created via the Azure Portal, and disabled by default on storage accounts created via Azure CLI or PowerShell. References: 1. https://learn.microsoft.com/en-us/azure/storage/blobs/soft-delete-blob-overview",
    "profile_applicability": "•  Level 1",
    "impact": "All soft-deleted data is billed at the same rate as active data. Additional costs may be incurred for deleted blobs until the soft delete period ends and the data is permanently removed.",
    "references": "1. https://learn.microsoft.com/en-us/azure/storage/blobs/soft-delete-blob-overview",
    "function_names": [
      "storage_blob_soft_delete_enabled",
      "storage_account_blob_soft_delete_enabled",
      "storage_blob_recovery_enabled",
      "storage_account_blob_recovery_enabled",
      "storage_blob_deletion_protection_enabled",
      "storage_account_blob_deletion_protection_enabled"
    ]
  },
  {
    "id": "11.4",
    "title": "Ensure stored access policies (SAP) are used when generating shared access signature (SAS) tokens",
    "assessment": "Manual",
    "description": "Use stored access policies (SAP) when generating shared access signature (SAS) tokens in Azure to centrally manage permissions, expiration, and revocation settings for resource access. Stored access policies can be applied to blob containers, file shares, queues, and tables.",
    "rationale": "Stored access policies provide centralized control over SAS token access, allowing administrators to update permissions or revoke access. This approach strengthens security by reducing the risk of unauthorized access to storage resources. Impact: There is no cost for creating stored access policies, however there is some administrative overhead involved in managing these policies.",
    "audit": "It is not currently possible to retrieve a list of all generated SAS tokens to check if they were associated with a SAP during creation. An SAS token that has been created with a SAP will contain an si parameter that references the stored access policy identifier associated with the SAS, e.g. si=<stored-access-policy-identifier>. The si parameter will be absent from an SAS token created without a SAP.",
    "remediation": "Remediate from Azure Portal To create a SAP for a blob container: 1. Go to Storage accounts. 2. Click on a storage account. 3. Under Data storage, click Containers. 4. Click the name of a container. 5. Under Settings, click Access policy. 6. Under Stored access policies, click + Add policy. 7. Enter an Identifier. 8. From the Permissions drop-down, select appropriate permissions for the policy. 9. Set an appropriate Start time for the policy. 10. Set an appropriate Expiry time for the policy. 11. Click OK. 12. Click Save. 13. Repeat steps 1-12 as needed to create SAP. When generating SAS, select a SAP from the Stored access policy drop-down. If SAS have been created without a SAP, the SAS can be revoked by regenerating the storage account access keys: Note: Regenerating access keys can affect any applications or Azure services that are dependent on the storage account key. 1. Go to Storage accounts. 2. Click on a storage account. 3. Under Security + networking, click Access keys. 4. Next to each key, click Rotate key. 5. Click Yes to confirm. 6. Repeat steps 1-5 as needed to revoke SAS. Default Value: By default, stored access policies are not associated with SAS. To use a stored access policy, it must be explicitly created and linked to the SAS at the time of creation. References: 1. https://learn.microsoft.com/en-us/azure/storage/common/storage-sas- overview#best-practices-when-using-sas 2. https://learn.microsoft.com/en-us/rest/api/storageservices/define-stored-access- policy Additional Information: This recommendation is based on the recommendation Ensure stored access policies (SAP) are used when generating shared access signature (SAS) tokens, from the Common Reference Recommendations > Secrets and Keys > Shared Access Signatures section.",
    "profile_applicability": "•  Level 1",
    "impact": "There is no cost for creating stored access policies, however there is some administrative overhead involved in managing these policies.",
    "references": "1. https://learn.microsoft.com/en-us/azure/storage/common/storage-sas- overview#best-practices-when-using-sas 2. https://learn.microsoft.com/en-us/rest/api/storageservices/define-stored-access- policy Additional Information: This recommendation is based on the recommendation Ensure stored access policies (SAP) are used when generating shared access signature (SAS) tokens, from the Common Reference Recommendations > Secrets and Keys > Shared Access Signatures section.",
    "function_names": [
      "storage_container_sas_policy_required",
      "storage_file_share_sas_policy_required",
      "storage_queue_sas_policy_required",
      "storage_table_sas_policy_required",
      "storage_sas_token_policy_enforced",
      "storage_sas_policy_centralized_management",
      "storage_sas_policy_expiration_enforced",
      "storage_sas_policy_revocation_enabled"
    ]
  },
  {
    "id": "11.5",
    "title": "Ensure 'Versioning' is set to 'Enabled' on Azure Blob Storage storage accounts",
    "assessment": "Automated",
    "description": "Enabling blob versioning allows for the automatic retention of previous versions of objects. With blob versioning enabled, earlier versions of a blob are accessible for data recovery in the event of modifications or deletions.",
    "rationale": "Blob versioning safeguards data integrity and enables recovery by retaining previous versions of stored objects, facilitating quick restoration from accidental deletion, modification, or malicious activity. Impact: Enabling blob versioning for a storage account creates a new version with each write operation to a blob, which can increase storage costs. To control these costs, a lifecycle management policy can be applied to automatically delete older versions.",
    "audit": "Audit from Azure Portal 1. Go to Storage accounts. 2. Click the name of a storage account with blob storage. 3. In the Overview page, on the Properties tab, under Blob service, ensure Versioning is set to Enabled. 4. Repeat steps 1-3 for each storage account with blob storage. Audit from Azure CLI Run the following command to list storage accounts: az storage account list Run the following command to determine if a storage account has containers: az storage container list --account-name <storage-account> For each storage account with containers, ensure that the output of the below command contains \"isVersioningEnabled\": true: az storage account blob-service-properties show --account-name <storage- account>  Audit from PowerShell Run the following command to list storage accounts: Get-AzStorageAccount Run the following command to create an Azure Storage context for a storage account: $context = New-AzStorageContext -StorageAccountName <storage-account> Run the following command to list containers for the storage account: Get-AzStorageContainer -Context $context If the storage account has containers, run the following command to get the blob service properties of the storage account: $account = Get-AzStorageBlobServiceProperty -ResourceGroupName <resource- group> -AccountName <storage-account> Run the following command to get the blob versioning setting for the storage account: $account.IsVersioningEnabled Ensure that the command returns True. Repeat for each storage account.",
    "remediation": "Remediate from Azure Portal 1. Go to Storage accounts. 2. Click the name of a storage account with blob storage. 3. In the Overview page, on the Properties tab, under Blob service, click Disabled next to Versioning. 4. Under Tracking, check the box next to Enable versioning for blobs. 5. Select the radio button next to Keep all versions or Delete versions after (in days). 6. If selecting to delete versions, enter a number of in the box after which to delete blob versions. 7. Click Save. 8. Repeat steps 1-7 for each storage account with blob storage. Remediate from Azure CLI For each storage account requiring remediation, run the following command to enable blob versioning: az storage account blob-service-properties update --account-name <storage- account> --enable-versioning true Remediate from PowerShell For each storage account requiring remediation, run the following command to enable blob versioning: Update-AzStorageBlobServiceProperty -ResourceGroupName <resource-group> - StorageAccountName <storage-account> -IsVersioningEnabled $true Default Value: Blob versioning is disabled by default on storage accounts. References: 1. https://learn.microsoft.com/en-us/cli/azure/storage/account 2. https://learn.microsoft.com/en-us/cli/azure/storage/account/blob-service- properties 3. https://learn.microsoft.com/en-us/powershell/module/az.storage/get- azstorageaccount 4. https://learn.microsoft.com/en-us/powershell/module/az.storage/new- azstoragecontext 5. https://learn.microsoft.com/en-us/powershell/module/az.storage/get- azstoragecontainer 6. https://learn.microsoft.com/en-us/powershell/module/az.storage/get- azstorageblobserviceproperty 7. https://learn.microsoft.com/en-us/powershell/module/az.storage/update- azstorageblobserviceproperty 8. https://learn.microsoft.com/en-us/azure/storage/blobs/versioning-overview 9. https://learn.microsoft.com/en-us/azure/storage/blobs/lifecycle-management- overview",
    "profile_applicability": "•  Level 2",
    "impact": "Enabling blob versioning for a storage account creates a new version with each write operation to a blob, which can increase storage costs. To control these costs, a lifecycle management policy can be applied to automatically delete older versions.",
    "references": "1. https://learn.microsoft.com/en-us/cli/azure/storage/account 2. https://learn.microsoft.com/en-us/cli/azure/storage/account/blob-service- properties 3. https://learn.microsoft.com/en-us/powershell/module/az.storage/get- azstorageaccount 4. https://learn.microsoft.com/en-us/powershell/module/az.storage/new- azstoragecontext 5. https://learn.microsoft.com/en-us/powershell/module/az.storage/get- azstoragecontainer 6. https://learn.microsoft.com/en-us/powershell/module/az.storage/get- azstorageblobserviceproperty 7. https://learn.microsoft.com/en-us/powershell/module/az.storage/update- azstorageblobserviceproperty 8. https://learn.microsoft.com/en-us/azure/storage/blobs/versioning-overview 9. https://learn.microsoft.com/en-us/azure/storage/blobs/lifecycle-management- overview",
    "function_names": [
      "storage_blob_versioning_enabled",
      "storage_account_versioning_enabled",
      "blob_storage_versioning_enabled",
      "storage_blob_versioning_enabled_all_containers",
      "storage_account_versioning_enabled_all_regions"
    ]
  },
  {
    "id": "11.6",
    "title": "Ensure locked immutability policies are used for containers storing business-critical blob data",
    "assessment": "Automated",
    "description": "Require locked immutability policies for all containers that store business-critical blob data. This measure protects the data from modifications or deletions, ensuring that critical information remains intact and unaltered, regardless of user actions or access permissions.",
    "rationale": "Implementing a locked immutability policy creates a Write Once, Read Many (WORM) storage model that safeguards critical data from accidental or malicious changes and deletions. Enforcing immutability minimizes data loss and tampering risks, enhancing data security and supporting regulatory requirements for data retention and integrity. Impact: Enforcing locked immutability policies for blob storage may increase long-term retention costs and require additional administrative effort for policy management. Once the policy is locked, the container cannot be deleted or edited, and the storage account cannot be deleted until the retention period has elapsed.",
    "audit": "Audit from Azure Portal 1. Go to Storage accounts. 2. Click the name of a storage account. 3. Under Data storage, click Containers. 4. Click the three dots next to a container. 5. Click Access policy. 6. Ensure a locked policy is listed under Immutable blob storage. 7. Repeat steps 1-6 for each blob container with business-critical blob data.  Audit from Azure CLI Run the following command to list storage accounts: az storage account list Run the following command to determine if a storage account has containers: az storage container list --account-name <storage-account> For each container, run the following command to view immutability policies: az storage container immutability-policy show --account-name <storage- account> --container <blob-container> Ensure that an immutability policy is listed with \"state\": \"Locked\" for each blob container with business-critical blob data.",
    "remediation": "Remediate from Azure Portal 1. Go to Storage accounts. 2. Click the name of a storage account. 3. Under Data storage, click Containers. 4. Click the three dots next to a container. 5. Click Access policy. 6. Under Immutable blob storage, click + Add policy. 7. From the Policy type drop-down, select Legal hold or Time-based retention. 8. If selecting legal hold: 1. Provide at least one tag for the policy. 2. Under Allow protected append writes to, select None or Block and append blobs. 9. If selecting time-based retention: 1. Under Set retention period for, enter a number of days for retention. 2. Check the box next to Enable version-level immutability if appropriate. Versioning must be enabled for this option to be available. 3. Under Allow protected append writes to, select None, Append blobs, or Block and append blobs. 10. Click Save. 11. Click the three dots next to the policy. 12. Click Lock policy. 13. Enter yes to confirm. 14. Click OK. 15. Repeat steps 1-14 for each blob container requiring remediation.  Remediate from Azure CLI For each blob container requiring remediation, run the following command to create an immutability policy: az storage container immutability-policy create --account-name <storage- account> --container-name <blob-container> --period <retention-period-in- days> For each blob container requiring remediation, run the following command to lock an immutability policy: az storage container immutability-policy lock --account-name <storage- account> --container-name <blob-container> --if-match <immutability-policy- etag> Default Value: Blob immutability is disabled by default. References: 1. https://learn.microsoft.com/en-gb/azure/storage/blobs/immutable-storage- overview 2. https://learn.microsoft.com/en-us/azure/storage/blobs/immutable-policy- configure-container-scope 3. https://learn.microsoft.com/en-us/cli/azure/storage/container/immutability-policy",
    "profile_applicability": "•  Level 2",
    "impact": "Enforcing locked immutability policies for blob storage may increase long-term retention costs and require additional administrative effort for policy management. Once the policy is locked, the container cannot be deleted or edited, and the storage account cannot be deleted until the retention period has elapsed.",
    "references": "1. https://learn.microsoft.com/en-gb/azure/storage/blobs/immutable-storage- overview 2. https://learn.microsoft.com/en-us/azure/storage/blobs/immutable-policy- configure-container-scope 3. https://learn.microsoft.com/en-us/cli/azure/storage/container/immutability-policy",
    "function_names": [
      "storage_container_immutability_policy_locked",
      "storage_container_immutability_policy_locked_business_critical",
      "blob_container_immutability_policy_locked",
      "blob_container_immutability_policy_locked_critical_data",
      "storage_container_immutability_policy_enabled_locked",
      "storage_container_immutability_policy_locked_all_regions",
      "blob_container_immutability_policy_locked_all",
      "storage_container_immutability_policy_locked_business_data"
    ]
  },
  {
    "id": "12.1",
    "title": "Ensure double encryption is used for Azure Data Box in high-security environments",
    "assessment": "Manual",
    "description": "Enabling double encryption on Azure Data Box applies an additional layer of encryption to safeguard data during physical transfer. This approach enhances confidentiality and integrity, ensuring that sensitive information remains secure against unauthorized access if the device is lost, stolen, or intercepted.",
    "rationale": "Double encryption ensures strong security for high-risk or regulated environments where data protection is critical. It enhances defense-in-depth and minimizes the risk of exposure, even during physical compromise in transit. Impact: Double encryption with Azure Data Box is available at no additional cost; however, enabling it may increase order processing and data copy times.",
    "audit": "Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: c349d81b-9985-44ae-a8da-ff98d108ede8 • Name: 'Azure Data Box jobs should enable double encryption for data at rest on the device'",
    "remediation": "Remediate from Azure Portal When creating a new Azure Data Box order, on the Security page, under Double encryption, check the box next to Enable double encryption for the order. Default Value: Double encryption is disabled by default on Azure Data Box orders. References: 1. https://learn.microsoft.com/en-us/azure/security/fundamentals/double-encryption 2. https://learn.microsoft.com/en-us/azure/databox/data-box-security 3. https://learn.microsoft.com/en-us/azure/databox/data-box-deploy-ordered 4. https://learn.microsoft.com/en-us/powershell/module/az.databox/update- azdataboxjob",
    "profile_applicability": "•  Level 2",
    "impact": "Double encryption with Azure Data Box is available at no additional cost; however, enabling it may increase order processing and data copy times.",
    "references": "1. https://learn.microsoft.com/en-us/azure/security/fundamentals/double-encryption 2. https://learn.microsoft.com/en-us/azure/databox/data-box-security 3. https://learn.microsoft.com/en-us/azure/databox/data-box-deploy-ordered 4. https://learn.microsoft.com/en-us/powershell/module/az.databox/update- azdataboxjob",
    "function_names": [
      "data_box_device_double_encryption_enabled",
      "data_box_device_high_security_encryption_enabled",
      "data_box_device_dual_layer_encryption_enabled",
      "data_box_device_physical_transfer_encryption_enabled",
      "data_box_device_secondary_encryption_enabled"
    ]
  },
  {
    "id": "15.1",
    "title": "Ensure 'Public network access' is set to 'Disabled' on Azure Elastic SAN",
    "assessment": "Automated",
    "description": "Azure Elastic SAN is a scalable, high-performance cloud-based storage solution. Disabling public network access at the SAN level ensures that Elastic SAN resources are accessible only through private networks.",
    "rationale": "Disabling public network access for Azure Elastic SAN at the SAN level enhances security by preventing unauthorized external access to sensitive storage resources. Impact: Disabling public network access at the SAN level incurs no direct cost. However, there may be costs and configuration overhead associated with setting up and managing private network access to securely connect to Azure Elastic SAN resources.",
    "audit": "Audit from Azure Portal 1. Go to Elastic SANs. 2. Click the name of an Elastic SAN. 3. Under Settings, click Networking. 4. Ensure that Public network access is set to Disabled. 5. Repeat steps 1-4 for each Elastic SAN. Audit from Azure CLI Run the following command to list Elastic SANs: az elastic-san list For each Elastic SAN, run the following command: az elastic-san show --resource-group <resource-group> --name <elastic-san> Ensure that publicNetworkAccess is set to Disabled.  Audit from PowerShell Run the following command to list Elastic SANs: Get-AzElasticSan Run the following command to get the Elastic SAN in a resource group with a given name: $elasticsan = Get-AzElasticSan -ResourceGroupName <resource-group> -Name <elastic-san> Run the following command to get the public network access setting for the Elastic SAN: $elasticsan.PublicNetworkAccess Ensure that the command returns Disabled.",
    "remediation": "Remediate from Azure Portal 1. Go to Elastic SANs. 2. Click the name of an Elastic SAN. 3. Under Settings, click Networking. 4. Under Public network access, click the radio button next to Disabled. 5. Click Apply. 6. Repeat steps 1-5 for each Elastic SAN. Remediate from Azure CLI For each Elastic SAN requiring remediation, run the following command to disable public network access: az elastic-san update --resource-group <resource-group> --name <elastic-san> --public-network-access Disabled Remediate from PowerShell For each Elastic SAN requiring remediation, run the following command to disable public network access: Update-AzElasticSan -ResourceGroupName <resource-group> -Name <elastic-san> - PublicNetworkAccess Disabled Default Value: Public network access at the SAN level is enabled by default, but access to individual volume groups is denied unless explicitly configured.  References: 1. https://learn.microsoft.com/en-us/azure/storage/elastic-san/elastic-san- networking 2. https://learn.microsoft.com/en-us/cli/azure/elastic-san 3. https://learn.microsoft.com/en-us/powershell/module/az.elasticsan/get- azelasticsan 4. https://learn.microsoft.com/en-us/powershell/module/az.elasticsan/update- azelasticsan",
    "profile_applicability": "•  Level 2",
    "impact": "Disabling public network access at the SAN level incurs no direct cost. However, there may be costs and configuration overhead associated with setting up and managing private network access to securely connect to Azure Elastic SAN resources.",
    "references": "1. https://learn.microsoft.com/en-us/azure/storage/elastic-san/elastic-san- networking 2. https://learn.microsoft.com/en-us/cli/azure/elastic-san 3. https://learn.microsoft.com/en-us/powershell/module/az.elasticsan/get- azelasticsan 4. https://learn.microsoft.com/en-us/powershell/module/az.elasticsan/update- azelasticsan",
    "function_names": [
      "elastic_san_public_network_access_disabled",
      "elastic_san_network_access_private_only",
      "elastic_san_public_access_restricted",
      "elastic_san_private_endpoint_enabled",
      "elastic_san_public_network_disabled"
    ]
  },
  {
    "id": "15.2",
    "title": "Ensure customer-managed keys (CMK) are used to encrypt data at rest on Azure Elastic SAN volume groups",
    "assessment": "Automated",
    "description": "Azure Elastic SAN volume groups offer two encryption options: Microsoft-managed keys, which provide automatic encryption without user intervention, and customer- managed keys (CMK), which allow organizations to retain full control over their encryption keys for enhanced security and compliance.",
    "rationale": "Using customer-managed keys (CMKs) to encrypt Azure Elastic SAN volume groups enhances security by granting organizations complete control over their encryption keys. Impact: There are costs and configuration overhead associated with setting up and managing customer-managed keys.",
    "audit": "Audit from Azure Portal 1. Go to Elastic SANs. 2. Click the name of an Elastic SAN. 3. Under SAN Management, click Volume groups. 4. For each volume group, ensure that the value in the Encryption type column is not Platform-managed key. Audit from Azure CLI Run the following command to list Elastic SANs: az elastic-san list For each Elastic SAN with a volumeGroupCount greater than 0, run the following command to list volume groups: az elastic-san volume-group list --resource-group <resource-group> --elastic- san <elastic-san> Ensure that for each volume group, encryption is set to EncryptionAtRestWithCustomerManagedKey.  Audit from PowerShell Run the following command to list Elastic SANs: Get-AzElasticSan For each Elastic SAN with a VolumeGroupCount greater than 0, run the following command to list volume groups: Get-AzElasticSanVolumeGroup -ResourceGroupName <resource-group> - ElasticSanName <elastic-san> Ensure that for each volume group, Encryption is set to EncryptionAtRestWithCustomerManagedKey. Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: 7698f4ed-80ce-4e13-b408-ee135fa400a5 • Name: 'ElasticSan Volume Group should use customer-managed keys to encrypt data at rest'",
    "remediation": "Remediate from Azure Portal It is not currently possible to remediate from Azure Portal. Refer to the Remediate from Azure CLI and Remediate from PowerShell sections for remediation options. Remediate from Azure CLI For each volume group requiring remediation, run the following command to assign an identity: az elastic-san volume-group update --resource-group <resource-group> -- elastic-san <elastic-san> --volume-group <volume-group> --identity \"{type:SystemAssigned}\" Note: Use --identity '{type:UserAssigned,user-assigned-identity:\"<user- assigned-identity-id>\"}' with the above command to provide a UserAssigned Identity Id. For each volume group requiring remediation, run the following command to assign a customer-managed encryption key: az elastic-san volume-group update --resource-group <resource-group> -- elastic-san <elastic-san> --volume-group <volume-group> --encryption EncryptionAtRestWithCustomerManagedKey --encryption-properties \"{key-vault- properties:{key-name:'<key>',key-vault-uri:'<key-vault-uri>'}}\"  Remediate from PowerShell For each volume group requiring remediation, run the following command to assign an identity: Update-AzElasticSanVolumeGroup -ResourceGroupName <resource-group> - ElasticSanName <elastic-san> -VolumeGroupName <volume-group> -IdentityType SystemAssigned Note: Use -IdentityType UserAssigned -IdentityUserAssignedIdentityId <user-assigned-identity-id> with the above command to provide a UserAssigned Identity Id. For each volume group requiring remediation, run the following command to assign a customer-managed encryption key: Update-AzElasticSanVolumeGroup -ResourceGroupName <resource-group> - ElasticSanName <elastic-san> -VolumeGroupName <volume-group> -Encryption EncryptionAtRestWithCustomerManagedKey -KeyName <key> -KeyVaultUri <key- vault-uri> Default Value: By default, Azure Elastic SAN volume groups are encrypted using Microsoft-managed keys. References: 1. https://learn.microsoft.com/en-us/azure/storage/elastic-san/elastic-san-configure- customer-managed-keys 2. https://learn.microsoft.com/en-us/cli/azure/elastic-san/volume-group 3. https://learn.microsoft.com/en-us/powershell/module/az.elasticsan/get- azelasticsanvolumegroup 4. https://learn.microsoft.com/en-us/powershell/module/az.elasticsan/update- azelasticsanvolumegroup 5. https://learn.microsoft.com/en-us/entra/identity/managed-identities-azure- resources/how-manage-user-assigned-managed-identities Additional Information: • To enable encryption, it is necessary to grant the volume group the appropriate permissions to access the encryption key in the key vault. The key can be modified as needed. Refer to the following guide for details: https://learn.microsoft.com/en-us/azure/storage/elastic-san/elastic-san-configure- customer-managed-keys?#configure-the-key-vault. • Azure Elastic SAN uses system-assigned managed identities and user-assigned managed identities to authenticate the volume groups to access encryption keys stored in Azure Key Vault. Refer to the following guide for details: https://learn.microsoft.com/en-us/azure/storage/elastic-san/elastic-san-configure- customer-managed-keys#choose-a-managed-identity-to-authorize-access-to-the- key-vault.",
    "profile_applicability": "•  Level 2",
    "impact": "There are costs and configuration overhead associated with setting up and managing customer-managed keys.",
    "references": "1. https://learn.microsoft.com/en-us/azure/storage/elastic-san/elastic-san-configure- customer-managed-keys 2. https://learn.microsoft.com/en-us/cli/azure/elastic-san/volume-group 3. https://learn.microsoft.com/en-us/powershell/module/az.elasticsan/get- azelasticsanvolumegroup 4. https://learn.microsoft.com/en-us/powershell/module/az.elasticsan/update- azelasticsanvolumegroup 5. https://learn.microsoft.com/en-us/entra/identity/managed-identities-azure- resources/how-manage-user-assigned-managed-identities Additional Information: • To enable encryption, it is necessary to grant the volume group the appropriate permissions to access the encryption key in the key vault. The key can be modified as needed. Refer to the following guide for details: https://learn.microsoft.com/en-us/azure/storage/elastic-san/elastic-san-configure- customer-managed-keys?#configure-the-key-vault. • Azure Elastic SAN uses system-assigned managed identities and user-assigned managed identities to authenticate the volume groups to access encryption keys stored in Azure Key Vault. Refer to the following guide for details: https://learn.microsoft.com/en-us/azure/storage/elastic-san/elastic-san-configure- customer-managed-keys#choose-a-managed-identity-to-authorize-access-to-the- key-vault.",
    "function_names": [
      "elastic_san_volume_group_cmk_encryption_enabled",
      "elastic_san_volume_group_microsoft_managed_key_disabled",
      "elastic_san_volume_group_customer_managed_key_required",
      "elastic_san_volume_group_encryption_at_rest_cmk",
      "elastic_san_volume_group_default_encryption_disabled"
    ]
  },
  {
    "id": "16.1",
    "title": "Ensure 'Allowed Protocols' for shared access signature (SAS) tokens is set to 'HTTPS Only'",
    "assessment": "Manual",
    "description": "Shared access signatures (SAS) can be used to grant limited access to Azure Storage resources. When generating a SAS, it is possible to specify the allowed protocols for a request made with the SAS. It is recommended to allow requests over HTTPS only.",
    "rationale": "If a SAS is passed over HTTP and intercepted, an attacker performing a man-in-the- middle attack can read the SAS. Then, they can use that SAS just as the intended user could have. This can potentially compromise sensitive data or allow for data corruption by the malicious user. Impact: SAS can pose security risks if they are not managed carefully.",
    "audit": "It is not possible to audit generated SAS.",
    "remediation": "Remediate from Azure Portal If SAS have been created to allow HTTP and were created with a stored access policy (SAP), the SAS can be revoked by deleting the SAP or updating the SAP expiration time to a time in the past: 1. Go to Storage accounts. 2. Click on a storage account. 3. Under Data storage, click Queues. 4. Click the three dots next to a queue. 5. Click Access policy. 6. Click the three dots next to an access policy. 7. Click Delete. 8. Click Save. 9. Repeat steps 1-8 as needed to revoke SAS created with SAP.  If SAS have been created to allow HTTP and were not created with a SAP, the SAS can be revoked by regenerating the storage account access keys: Note: Regenerating access keys can affect any applications or Azure services that are dependent on the storage account key. 1. Go to Storage accounts. 2. Click on a storage account. 3. Under Security + networking, click Access keys. 4. Next to each key, click Rotate key. 5. Click Yes to confirm. 6. Repeat steps 1-5 as needed to revoke SAS. Default Value: When generating a SAS, the default selection for Allowed protocols is HTTPS only. References: 1. https://learn.microsoft.com/en-us/azure/storage/common/storage-sas-overview 2. https://learn.microsoft.com/en-us/azure/storage/common/storage-account-keys- manage Additional Information: This recommendation is based on the recommendation Ensure 'Allowed Protocols' for shared access signature (SAS) tokens is set to 'HTTPS Only', from the Common Reference Recommendations > Secrets and Keys > Shared Access Signatures section.",
    "profile_applicability": "•  Level 1",
    "impact": "SAS can pose security risks if they are not managed carefully.",
    "references": "1. https://learn.microsoft.com/en-us/azure/storage/common/storage-sas-overview 2. https://learn.microsoft.com/en-us/azure/storage/common/storage-account-keys- manage Additional Information: This recommendation is based on the recommendation Ensure 'Allowed Protocols' for shared access signature (SAS) tokens is set to 'HTTPS Only', from the Common Reference Recommendations > Secrets and Keys > Shared Access Signatures section.",
    "function_names": [
      "storage_account_sas_https_only",
      "storage_sas_token_protocol_https",
      "storage_shared_access_signature_https_required",
      "storage_sas_allowed_protocols_https_only",
      "storage_account_sas_protocol_restricted_https"
    ]
  },
  {
    "id": "16.2",
    "title": "Ensure that shared access signature (SAS) tokens expire within an hour",
    "assessment": "Manual",
    "description": "Shared access signature (SAS) tokens provide restricted access to Azure Storage resources (such as blobs, files, queues, or tables) for a defined time period with specific permissions. It enables users to interact with the resources without exposing account keys, offering precise control over the permitted actions (e.g., read, write) and the duration of access. To minimize security risks, SAS tokens should be configured with the shortest possible lifespan, ideally lasting no longer than an hour.",
    "rationale": "A short lifespan for SAS tokens is recommended to minimize the risk of unauthorized access. SAS tokens grant time-limited access to resources, and a longer duration increases the opportunity for misuse if the token is compromised. By setting a shorter lifespan, the potential for security breaches is reduced. Impact: SAS can pose security risks if they are not managed carefully.",
    "audit": "Currently, SAS token expiration times cannot be audited. Until Microsoft makes the token expiration time a setting rather than a token creation parameter, this recommendation will require manual verification.",
    "remediation": "Remediate from Azure Portal If SAS have been created without a short lifespan and were created with a stored access policy (SAP), the SAS can be revoked by deleting the SAP or updating the SAP expiration time to a time in the past: 1. Go to Storage accounts. 2. Click on a storage account. 3. Under Data storage, click Queues. 4. Click the three dots next to a listed item. 5. Click Access policy. 6. Click the three dots next to an access policy. 7. Click Delete. 8. Click Save. 9. Repeat steps 1-8 as needed to revoke SAS created with SAP. If SAS have been created without a short lifespan and were not created with a SAP, the SAS can be revoked by regenerating the storage account access keys: Note: Regenerating access keys can affect any applications or Azure services that are dependent on the storage account key. 1. Go to Storage accounts. 2. Click on a storage account. 3. Under Security + networking, click Access keys. 4. Next to each key, click Rotate key. 5. Click Yes to confirm. 6. Repeat steps 1-5 as needed to revoke SAS. Default Value: By default, expiration for shared access signature is set to 8 hours. References: 1. https://docs.microsoft.com/en-us/azure/storage/common/storage-sas-overview 2. https://docs.microsoft.com/en-us/rest/api/storageservices/delegating-access- with-a-shared-access-signature Additional Information: This recommendation is based on the recommendation Ensure that shared access signature (SAS) tokens expire within an hour, from the Common Reference Recommendations > Secrets and Keys > Shared Access Signatures section.",
    "profile_applicability": "•  Level 1",
    "impact": "SAS can pose security risks if they are not managed carefully.",
    "references": "1. https://docs.microsoft.com/en-us/azure/storage/common/storage-sas-overview 2. https://docs.microsoft.com/en-us/rest/api/storageservices/delegating-access- with-a-shared-access-signature Additional Information: This recommendation is based on the recommendation Ensure that shared access signature (SAS) tokens expire within an hour, from the Common Reference Recommendations > Secrets and Keys > Shared Access Signatures section.",
    "function_names": [
      "storage_account_sas_token_expiry_within_1h",
      "storage_blob_sas_token_expiry_within_1h",
      "storage_file_sas_token_expiry_within_1h",
      "storage_queue_sas_token_expiry_within_1h",
      "storage_table_sas_token_expiry_within_1h",
      "storage_sas_token_short_lived",
      "storage_sas_token_max_duration_1h"
    ]
  },
  {
    "id": "16.3",
    "title": "Ensure stored access policies (SAP) are used when generating shared access signature (SAS) tokens",
    "assessment": "Manual",
    "description": "Use stored access policies (SAP) when generating shared access signature (SAS) tokens in Azure to centrally manage permissions, expiration, and revocation settings for resource access. Stored access policies can be applied to blob containers, file shares, queues, and tables.",
    "rationale": "Stored access policies provide centralized control over SAS token access, allowing administrators to update permissions or revoke access. This approach strengthens security by reducing the risk of unauthorized access to storage resources. Impact: There is no cost for creating stored access policies, however there is some administrative overhead involved in managing these policies.",
    "audit": "It is not currently possible to retrieve a list of all generated SAS tokens to check if they were associated with a SAP during creation. An SAS token that has been created with a SAP will contain an si parameter that references the stored access policy identifier associated with the SAS, e.g. si=<stored-access-policy-identifier>. The si parameter will be absent from an SAS token created without a SAP.",
    "remediation": "Remediate from Azure Portal To create a SAP for a queue: 1. Go to Storage accounts. 2. Click on a storage account. 3. Under Data storage, click Queues. 4. Click the name of a queue. 5. Under Settings, click Access policy. 6. Under Stored access policies, click + Add policy. 7. Enter an Identifier. 8. From the Permissions drop-down, select appropriate permissions for the policy. 9. Set an appropriate Start time for the policy. 10. Set an appropriate Expiry time for the policy. 11. Click OK. 12. Click Save. 13. Repeat steps 1-12 as needed to create SAP. When generating SAS, select a SAP from the Stored access policy drop-down. If SAS have been created without a SAP, the SAS can be revoked by regenerating the storage account access keys: Note: Regenerating access keys can affect any applications or Azure services that are dependent on the storage account key. 1. Go to Storage accounts. 2. Click on a storage account. 3. Under Security + networking, click Access keys. 4. Next to each key, click Rotate key. 5. Click Yes to confirm. 6. Repeat steps 1-5 as needed to revoke SAS. Default Value: By default, stored access policies are not associated with SAS. To use a stored access policy, it must be explicitly created and linked to the SAS at the time of creation. References: 1. https://learn.microsoft.com/en-us/azure/storage/common/storage-sas- overview#best-practices-when-using-sas 2. https://learn.microsoft.com/en-us/rest/api/storageservices/define-stored-access- policy Additional Information: This recommendation is based on the recommendation Ensure stored access policies (SAP) are used when generating shared access signature (SAS) tokens, from the Common Reference Recommendations > Secrets and Keys > Shared Access Signatures section.",
    "profile_applicability": "•  Level 1",
    "impact": "There is no cost for creating stored access policies, however there is some administrative overhead involved in managing these policies.",
    "references": "1. https://learn.microsoft.com/en-us/azure/storage/common/storage-sas- overview#best-practices-when-using-sas 2. https://learn.microsoft.com/en-us/rest/api/storageservices/define-stored-access- policy Additional Information: This recommendation is based on the recommendation Ensure stored access policies (SAP) are used when generating shared access signature (SAS) tokens, from the Common Reference Recommendations > Secrets and Keys > Shared Access Signatures section.",
    "function_names": [
      "storage_account_sas_token_stored_policy_required",
      "storage_container_sas_token_stored_policy_required",
      "storage_file_share_sas_token_stored_policy_required",
      "storage_queue_sas_token_stored_policy_required",
      "storage_table_sas_token_stored_policy_required",
      "storage_sas_token_centralized_permissions_required",
      "storage_sas_token_expiration_managed_by_policy",
      "storage_sas_token_revocation_managed_by_policy"
    ]
  },
  {
    "id": "17.1.1",
    "title": "Ensure that 'Enable key rotation reminders' is enabled for each Storage Account",
    "assessment": "Manual",
    "description": "Access Keys authenticate application access requests to data contained in Storage Accounts. A periodic rotation of these keys is recommended to ensure that potentially compromised keys cannot result in a long-term exploitable credential. The \"Rotation Reminder\" is an automatic reminder feature for a manual procedure.",
    "rationale": "Reminders such as those generated by this recommendation will help maintain a regular and healthy cadence for activities which improve the overall efficacy of a security program. Cryptographic key rotation periods will vary depending on your organization's security requirements and the type of data which is being stored in the Storage Account. For example, PCI DSS mandates that cryptographic keys be replaced or rotated 'regularly,' and advises that keys for static data stores be rotated every 'few months.' For the purposes of this recommendation, 90 days will prescribed for the reminder. Review and adjustment of the 90 day period is recommended, and may even be necessary. Your organization's security requirements should dictate the appropriate setting. Impact: This recommendation only creates a periodic reminder to regenerate access keys. Regenerating access keys can affect services in Azure as well as the organization's applications that are dependent on the storage account. All clients that use the access key to access the storage account must be updated to use the new key.",
    "audit": "Audit from Azure Portal 1. Go to Storage Accounts 2. For each Storage Account, under Security + networking, go to Access keys 3. If the button Edit rotation reminder is displayed, the Storage Account is compliant. Click Edit rotation reminder and review the Remind me every field for a desirable periodic setting that fits your security program's needs. If the button Set rotation reminder is displayed, the Storage Account is not compliant. Audit from Powershell $rgName = <resource group name for the storage> $accountName = <storage account name> $account = Get-AzStorageAccount -ResourceGroupName $rgName -Name $accountName Write-Output $accountName -> Write-Output \"Expiration Reminder set to: $($account.KeyPolicy.KeyExpirationPeriodInDays) Days\" Write-Output \"Key1 Last Rotated: $($account.KeyCreationTime.Key1.ToShortDateString())\" Write-Output \"Key2 Last Rotated: $($account.KeyCreationTime.Key2.ToShortDateString())\" Key rotation is recommended if the creation date for any key is empty. If the reminder is set, the period in days will be returned. The recommended period is 90 days.",
    "remediation": "Remediate from Azure Portal 1. Go to Storage Accounts 2. For each Storage Account that is not compliant, under Security + networking, go to Access keys 3. Click Set rotation reminder 4. Check Enable key rotation reminders 5. In the Send reminders field select Custom, then set the Remind me every field to 90 and the period drop down to Days 6. Click Save Remediate from Powershell $rgName = <resource group name for the storage> $accountName = <storage account name> $account = Get-AzStorageAccount -ResourceGroupName $rgName -Name $accountName if ($account.KeyCreationTime.Key1 -eq $null -or $account.KeyCreationTime.Key2 -eq $null){ Write-output (\"You must regenerate both keys at least once before setting expiration policy\") } else { $account = Set-AzStorageAccount -ResourceGroupName $rgName -Name $accountName -KeyExpirationPeriodInDay 90 } $account.KeyPolicy.KeyExpirationPeriodInDays Default Value: By default, Key rotation reminders is not configured.  References: 1. https://docs.microsoft.com/en-us/azure/storage/common/storage-create-storage- account#regenerate-storage-access-keys 2. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-privileged- access#pa-1-separate-and-limit-highly-privilegedadministrative-users 3. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-identity- management#im-3-manage-application-identities-securely-and-automatically 4. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-governance- strategy#gs-6-define-and-implement-identity-and-privileged-access-strategy 5. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-identity- management#im-8-restrict-the-exposure-of-credentials-and-secrets 6. https://www.pcidssguide.com/pci-dss-key-rotation-requirements/ 7. https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-57pt1r5.pdf",
    "profile_applicability": "•  Level 1",
    "impact": "This recommendation only creates a periodic reminder to regenerate access keys. Regenerating access keys can affect services in Azure as well as the organization's applications that are dependent on the storage account. All clients that use the access key to access the storage account must be updated to use the new key.",
    "references": "1. https://docs.microsoft.com/en-us/azure/storage/common/storage-create-storage- account#regenerate-storage-access-keys 2. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-privileged- access#pa-1-separate-and-limit-highly-privilegedadministrative-users 3. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-identity- management#im-3-manage-application-identities-securely-and-automatically 4. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-governance- strategy#gs-6-define-and-implement-identity-and-privileged-access-strategy 5. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-identity- management#im-8-restrict-the-exposure-of-credentials-and-secrets 6. https://www.pcidssguide.com/pci-dss-key-rotation-requirements/ 7. https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-57pt1r5.pdf",
    "function_names": [
      "storage_account_access_key_rotation_reminders_enabled",
      "storage_account_key_rotation_reminders_enabled",
      "storage_key_rotation_reminders_enabled",
      "storage_access_key_rotation_reminders_enabled",
      "storage_account_key_rotation_enabled"
    ]
  },
  {
    "id": "17.1.2",
    "title": "Ensure 'Allowed Protocols' for shared access signature (SAS) tokens is set to 'HTTPS Only'",
    "assessment": "Manual",
    "description": "Shared access signatures (SAS) can be used to grant limited access to Azure Storage resources. When generating a SAS, it is possible to specify the allowed protocols for a request made with the SAS. It is recommended to allow requests over HTTPS only.",
    "rationale": "If a SAS is passed over HTTP and intercepted, an attacker performing a man-in-the- middle attack can read the SAS. Then, they can use that SAS just as the intended user could have. This can potentially compromise sensitive data or allow for data corruption by the malicious user. Impact: SAS can pose security risks if they are not managed carefully.",
    "audit": "It is not possible to audit generated SAS tokens, but Azure Policy can be used to generally audit the existence of configured SAS policy. Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: bc1b984e-ddae-40cc-801a-050a030e4fbe • Name: 'Storage accounts should have shared access signature (SAS) policies configured'",
    "remediation": "Remediate from Azure Portal If SAS have been created to allow HTTP and were created with a stored access policy (SAP), the SAS can be revoked by deleting the SAP or updating the SAP expiration time to a time in the past: 1. Go to Storage accounts. 2. Click on a storage account. 3. Under Data storage, click Containers, File shares, Queues, or Tables. 4. Click the three dots next to a listed item. 5. Click Access policy. 6. Click the three dots next to an access policy. 7. Click Delete. 8. Click Save. 9. Repeat steps 1-8 as needed to revoke SAS created with SAP. If SAS have been created to allow HTTP and were not created with a SAP, the SAS can be revoked by regenerating the storage account access keys: Note: Regenerating access keys can affect any applications or Azure services that are dependent on the storage account key. 1. Go to Storage accounts. 2. Click on a storage account. 3. Under Security + networking, click Access keys. 4. Next to each key, click Rotate key. 5. Click Yes to confirm. 6. Repeat steps 1-5 as needed to revoke SAS. Default Value: When generating a SAS, the default selection for Allowed protocols is HTTPS only. References: 1. https://learn.microsoft.com/en-us/azure/storage/common/storage-sas-overview 2. https://learn.microsoft.com/en-us/azure/storage/common/storage-account-keys- manage Additional Information: This recommendation is based on the recommendation Ensure 'Allowed Protocols' for shared access signature (SAS) tokens is set to 'HTTPS Only', from the Common Reference Recommendations > Secrets and Keys > Shared Access Signatures section.",
    "profile_applicability": "•  Level 1",
    "impact": "SAS can pose security risks if they are not managed carefully.",
    "references": "1. https://learn.microsoft.com/en-us/azure/storage/common/storage-sas-overview 2. https://learn.microsoft.com/en-us/azure/storage/common/storage-account-keys- manage Additional Information: This recommendation is based on the recommendation Ensure 'Allowed Protocols' for shared access signature (SAS) tokens is set to 'HTTPS Only', from the Common Reference Recommendations > Secrets and Keys > Shared Access Signatures section.",
    "function_names": [
      "storage_account_sas_https_only",
      "storage_sas_token_protocol_https",
      "sas_allowed_protocols_https_restricted",
      "storage_shared_access_https_enforced",
      "sas_token_protocol_https_only"
    ]
  },
  {
    "id": "17.1.3",
    "title": "Ensure that Storage Account Access Keys are Periodically Regenerated",
    "assessment": "Manual",
    "description": "For increased security, regenerate storage account access keys periodically.",
    "rationale": "When a storage account is created, Azure generates two 512-bit storage access keys which are used for authentication when the storage account is accessed. Rotating these keys periodically ensures that any inadvertent access or exposure does not result from the compromise of these keys. Cryptographic key rotation periods will vary depending on your organization's security requirements and the type of data which is being stored in the Storage Account. For example, PCI DSS mandates that cryptographic keys be replaced or rotated 'regularly,' and advises that keys for static data stores be rotated every 'few months.' For the purposes of this recommendation, 90 days will prescribed for the reminder. Review and adjustment of the 90 day period is recommended, and may even be necessary. Your organization's security requirements should dictate the appropriate setting. Impact: Regenerating access keys can affect services in Azure as well as the organization's applications that are dependent on the storage account. All clients who use the access key to access the storage account must be updated to use the new key.",
    "audit": "Audit from Azure Portal 1. Go to Storage Accounts. 2. For each Storage Account, under Security + networking, go to Access keys. 3. Review the date and days in the Last rotated field for each key. If the Last rotated field indicates a number or days greater than 90 [or greater than your organization's period of validity], the key should be rotated. Audit from Azure CLI 1. Get a list of storage accounts az storage account list --subscription <subscription-id> Make a note of id, name and resourceGroup. 2. For every storage account make sure that key is regenerated in past 90 days. az monitor activity-log list --namespace Microsoft.Storage --offset 90d -- query \"[?contains(authorization.action, 'regenerateKey')]\" --resource-id <resource id> The output should contain \"authorization\"/\"scope\": <your_storage_account> AND \"authorization\"/\"action\": \"Microsoft.Storage/storageAccounts/regeneratekey/action\" AND \"status\"/\"localizedValue\": \"Succeeded\" \"status\"/\"Value\": \"Succeeded\"  Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: 044985bb-afe1-42cd-8a36-9d5d42424537 • Name: 'Storage account keys should not be expired'",
    "remediation": "Remediate from Azure Portal 1. Go to Storage Accounts. 2. For each Storage Account with outdated keys, under Security + networking, go to Access keys. 3. Click Rotate key next to the outdated key, then click Yes to the prompt confirming that you want to regenerate the access key. After Azure regenerates the Access Key, you can confirm that Access keys reflects a Last rotated date of (0 days ago). Default Value: By default, access keys are not regenerated periodically. References: 1. https://docs.microsoft.com/en-us/azure/storage/common/storage-create-storage- account#regenerate-storage-access-keys 2. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-privileged- access#pa-1-separate-and-limit-highly-privilegedadministrative-users 3. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-identity- management#im-2-protect-identity-and-authentication-systems 4. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-governance- strategy#gs-6-define-and-implement-identity-and-privileged-access-strategy 5. https://www.pcidssguide.com/pci-dss-key-rotation-requirements/ 6. https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-57pt1r5.pdf",
    "profile_applicability": "•  Level 1",
    "impact": "Regenerating access keys can affect services in Azure as well as the organization's applications that are dependent on the storage account. All clients who use the access key to access the storage account must be updated to use the new key.",
    "references": "1. https://docs.microsoft.com/en-us/azure/storage/common/storage-create-storage- account#regenerate-storage-access-keys 2. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-privileged- access#pa-1-separate-and-limit-highly-privilegedadministrative-users 3. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-identity- management#im-2-protect-identity-and-authentication-systems 4. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-governance- strategy#gs-6-define-and-implement-identity-and-privileged-access-strategy 5. https://www.pcidssguide.com/pci-dss-key-rotation-requirements/ 6. https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-57pt1r5.pdf",
    "function_names": [
      "storage_account_access_key_regenerated_periodically",
      "storage_account_access_key_rotation_enabled",
      "storage_account_access_key_rotation_over_90d",
      "storage_account_access_key_rotation_over_180d",
      "storage_account_access_key_no_long_term_static_keys"
    ]
  },
  {
    "id": "17.1.4",
    "title": "Ensure that shared access signature (SAS) tokens expire within an hour",
    "assessment": "Manual",
    "description": "Shared access signature (SAS) tokens provide restricted access to Azure Storage resources (such as blobs, files, queues, or tables) for a defined time period with specific permissions. It enables users to interact with the resources without exposing account keys, offering precise control over the permitted actions (e.g., read, write) and the duration of access. To minimize security risks, SAS tokens should be configured with the shortest possible lifespan, ideally lasting no longer than an hour.",
    "rationale": "A short lifespan for SAS tokens is recommended to minimize the risk of unauthorized access. SAS tokens grant time-limited access to resources, and a longer duration increases the opportunity for misuse if the token is compromised. By setting a shorter lifespan, the potential for security breaches is reduced. Impact: SAS can pose security risks if they are not managed carefully.",
    "audit": "Currently, SAS token expiration times cannot be audited. Until Microsoft makes the token expiration time a setting rather than a token creation parameter, this recommendation will require manual verification.",
    "remediation": "Remediate from Azure Portal If SAS have been created without a short lifespan and were created with a stored access policy (SAP), the SAS can be revoked by deleting the SAP or updating the SAP expiration time to a time in the past: 1. Go to Storage accounts. 2. Click on a storage account. 3. Under Data storage, click Containers, File shares, Queues, or Tables. 4. Click the three dots next to a listed item. 5. Click Access policy. 6. Click the three dots next to an access policy. 7. Click Delete. 8. Click Save. 9. Repeat steps 1-8 as needed to revoke SAS created with SAP. If SAS have been created without a short lifespan and were not created with a SAP, the SAS can be revoked by regenerating the storage account access keys: Note: Regenerating access keys can affect any applications or Azure services that are dependent on the storage account key. 1. Go to Storage accounts. 2. Click on a storage account. 3. Under Security + networking, click Access keys. 4. Next to each key, click Rotate key. 5. Click Yes to confirm. 6. Repeat steps 1-5 as needed to revoke SAS. Default Value: By default, expiration for shared access signature is set to 8 hours. References: 1. https://docs.microsoft.com/en-us/azure/storage/common/storage-sas-overview 2. https://docs.microsoft.com/en-us/rest/api/storageservices/delegating-access- with-a-shared-access-signature Additional Information: This recommendation is based on the recommendation Ensure that shared access signature (SAS) tokens expire within an hour, from the Common Reference Recommendations > Secrets and Keys > Shared Access Signatures section.",
    "profile_applicability": "•  Level 1",
    "impact": "SAS can pose security risks if they are not managed carefully.",
    "references": "1. https://docs.microsoft.com/en-us/azure/storage/common/storage-sas-overview 2. https://docs.microsoft.com/en-us/rest/api/storageservices/delegating-access- with-a-shared-access-signature Additional Information: This recommendation is based on the recommendation Ensure that shared access signature (SAS) tokens expire within an hour, from the Common Reference Recommendations > Secrets and Keys > Shared Access Signatures section.",
    "function_names": [
      "storage_account_sas_token_expiry_within_1h",
      "storage_blob_sas_token_expiry_within_1h",
      "storage_file_sas_token_expiry_within_1h",
      "storage_queue_sas_token_expiry_within_1h",
      "storage_table_sas_token_expiry_within_1h",
      "storage_container_sas_token_expiry_within_1h",
      "storage_service_sas_token_expiry_within_1h",
      "storage_resource_sas_token_expiry_within_1h"
    ]
  },
  {
    "id": "17.1.5",
    "title": "Ensure 'Allow storage account key access' for Azure Storage Accounts is 'Disabled'",
    "assessment": "Automated",
    "description": "Every secure request to an Azure Storage account must be authorized. By default, requests can be authorized with either Microsoft Entra credentials or by using the account access key for Shared Key authorization.",
    "rationale": "Microsoft Entra ID provides superior security and ease of use compared to Shared Key and is recommended by Microsoft. To require clients to use Microsoft Entra ID for authorizing requests, you can disallow requests to the storage account that are authorized with Shared Key. Impact: When you disallow Shared Key authorization for a storage account, any requests to the account that are authorized with Shared Key, including shared access signatures (SAS), will be denied. Client applications that currently access the storage account using the Shared Key will no longer function.",
    "audit": "Audit from Azure Portal 1. Go to Storage accounts. 2. Click on a storage account. 3. Under Settings, click Configuration. 4. Under Allow storage account key access, ensure that the radio button next to Disabled is selected. 5. Repeat steps 1-4 for each storage account. Audit from Azure CLI Run the following command to list storage accounts: az storage account list For each storage account, run the following command: az storage account show --resource-group <resource-group> --name <storage- account> Ensure that allowSharedKeyAccess is set to false. Audit from PowerShell Run the following command to list storage accounts: Get-AzStorageAccount Run the following command to get the storage account in a resource group with a given name: $storageAccount = Get-AzStorageAccount -ResourceGroupName <resource-group> - Name <storage-account> Run the following command to get the shared key access setting for the storage account: $storageAccount.allowSharedKeyAccess Ensure that the command returns False. Repeat for each storage account. Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: 8c6a50c6-9ffd-4ae7-986f-5fa6111f9a54 • Name: 'Storage accounts should prevent shared key access'",
    "remediation": "Remediate from Azure Portal 1. Go to Storage accounts. 2. Click on a storage account. 3. Under Settings, click Configuration. 4. Under Allow storage account key access, click the radio button next to Disabled. 5. Click Save. 6. Repeat steps 1-5 for each storage account requiring remediation. Remediate from Azure CLI For each storage account requiring remediation, run the following command to disallow shared key authorization: az storage account update --resource-group <resource-group> --name <storage- account> --allow-shared-key-access false Remediate from PowerShell For each storage account requiring remediation, run the following command to disallow shared key authorization: Set-AzStorageAccount -ResourceGroupName <resource-group> -Name <storage- account> -AllowSharedKeyAccess $false Default Value: The AllowSharedKeyAccess property of a storage account is not set by default and does not return a value until you explicitly set it. The storage account permits requests that are authorized with the Shared Key when the property value is null or when it is true . References: 1. https://learn.microsoft.com/en-us/azure/storage/common/shared-key- authorization-prevent 2. https://learn.microsoft.com/en-us/cli/azure/storage/account 3. https://learn.microsoft.com/en-us/powershell/module/az.storage/get- azstorageaccount 4. https://learn.microsoft.com/en-us/powershell/module/az.storage/set- azstorageaccount",
    "profile_applicability": "•  Level 1",
    "impact": "When you disallow Shared Key authorization for a storage account, any requests to the account that are authorized with Shared Key, including shared access signatures (SAS), will be denied. Client applications that currently access the storage account using the Shared Key will no longer function.",
    "references": "1. https://learn.microsoft.com/en-us/azure/storage/common/shared-key- authorization-prevent 2. https://learn.microsoft.com/en-us/cli/azure/storage/account 3. https://learn.microsoft.com/en-us/powershell/module/az.storage/get- azstorageaccount 4. https://learn.microsoft.com/en-us/powershell/module/az.storage/set- azstorageaccount",
    "function_names": [
      "storage_account_key_access_disabled",
      "storage_account_shared_key_auth_disabled",
      "storage_account_entra_auth_only",
      "storage_account_secure_auth_required",
      "storage_account_account_key_access_restricted"
    ]
  },
  {
    "id": "17.1.6",
    "title": "Ensure Storage for Critical Data are Encrypted with Customer Managed Keys (CMK)",
    "assessment": "Manual",
    "description": "Enable sensitive data encryption at rest using Customer Managed Keys (CMK) rather than Microsoft Managed keys.",
    "rationale": "By default, data in the storage account is encrypted using Microsoft Managed Keys at rest. All Azure Storage resources are encrypted, including blobs, disks, files, queues, and tables. All object metadata is also encrypted. If you want to control and manage this encryption key yourself, however, you can specify a customer-managed key. That key is used to protect and control access to the key that encrypts your data. You can also choose to automatically update the key version used for Azure Storage encryption whenever a new version is available in the associated Key Vault. While it is possible to automate the assessment of this recommendation, the assessment status for this recommendation remains 'Manual.' This is because the recommendation pertains to storage accounts that store critical data and is therefore not applicable to all storage accounts. Impact: If the key expires by setting the 'activation date' and 'expiration date', the user must rotate the key manually. Using Customer Managed Keys may also incur additional man-hour requirements to create, store, manage, and protect the keys as needed.",
    "audit": "Audit from Azure Portal 1. Go to Storage Accounts 2. For each storage account, under Security + networking, go to Encryption 3. Ensure that Encryption type is set to Customer-managed keys  Audit from PowerShell Connect-AzAccount Set-AzContext -Subscription <subscription id> Get-AzStorageAccount |Select-Object -ExpandProperty Encryption PowerShell Results - Non-Compliant ... KeySource                       : Microsoft.Storage ... PowerShell Results - Compliant ... KeySource                       : Microsoft.Keyvault ...  Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: 6fac406b-40ca-413b-bf8e-0bf964659c25 • Name: 'Storage accounts should use customer-managed key for encryption'",
    "remediation": "Remediate from Azure Portal 1. Go to Storage Accounts 2. For each storage account, under Security + networking, go to Encryption 3. Set Encryption type to Customer-managed keys 4. Select an encryption key or enter a key URI 5. Click Save Default Value: By default, Encryption type is set to Microsoft Managed Keys. References: 1. https://docs.microsoft.com/en-us/azure/storage/common/storage-service- encryption 2. https://docs.microsoft.com/en-us/azure/security/fundamentals/data-encryption- best-practices#protect-data-at-rest 3. https://docs.microsoft.com/en-us/azure/storage/common/storage-service- encryption#azure-storage-encryption-versus-disk-encryption 4. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-data- protection#dp-5-use-customer-managed-key-option-in-data-at-rest-encryption- when-required",
    "profile_applicability": "•  Level 2",
    "impact": "If the key expires by setting the 'activation date' and 'expiration date', the user must rotate the key manually. Using Customer Managed Keys may also incur additional man-hour requirements to create, store, manage, and protect the keys as needed.",
    "references": "1. https://docs.microsoft.com/en-us/azure/storage/common/storage-service- encryption 2. https://docs.microsoft.com/en-us/azure/security/fundamentals/data-encryption- best-practices#protect-data-at-rest 3. https://docs.microsoft.com/en-us/azure/storage/common/storage-service- encryption#azure-storage-encryption-versus-disk-encryption 4. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-data- protection#dp-5-use-customer-managed-key-option-in-data-at-rest-encryption- when-required",
    "function_names": [
      "storage_account_encryption_cmk_enabled",
      "storage_blob_encryption_cmk_enabled",
      "storage_file_share_encryption_cmk_enabled",
      "storage_table_encryption_cmk_enabled",
      "storage_queue_encryption_cmk_enabled",
      "storage_disk_encryption_cmk_enabled",
      "storage_container_encryption_cmk_enabled",
      "storage_data_lake_encryption_cmk_enabled",
      "storage_sensitive_data_encryption_cmk_enabled",
      "storage_critical_data_encryption_cmk_enabled"
    ]
  },
  {
    "id": "17.2.1",
    "title": "Ensure Private Endpoints are used to access Storage Accounts",
    "assessment": "Automated",
    "description": "Use private endpoints for your Azure Storage accounts to allow clients and services to securely access data located over a network via an encrypted Private Link. To do this, the private endpoint uses an IP address from the VNet for each service. Network traffic between disparate services securely traverses encrypted over the VNet. This VNet can also link addressing space, extending your network and accessing resources on it. Similarly, it can be a tunnel through public networks to connect remote infrastructures together. This creates further security through segmenting network traffic and preventing outside sources from accessing it.",
    "rationale": "Securing traffic between services through encryption protects the data from easy interception and reading. Impact: A Private Endpoint costs approximately US$7.30 per month. If an Azure Virtual Network is not implemented correctly, this may result in the loss of critical network traffic.",
    "audit": "Audit from Azure Portal 1. Open the Storage Accounts blade. 2. For each listed Storage Account, perform the following check: 3. Under the Security + networking heading, click on Networking. 4. Click on the Private endpoint connections tab at the top of the networking window. 5. Ensure that for each VNet that the Storage Account must be accessed from, a unique Private Endpoint is deployed and the Connection state for each Private Endpoint is Approved. Repeat the procedure for each Storage Account. Audit from PowerShell $storageAccount = Get-AzStorageAccount -ResourceGroup '<ResourceGroupName>' - Name '<storageaccountname>' Get-AzPrivateEndpoint -ResourceGroup '<ResourceGroupName>'|Where-Object {$_.PrivateLinkServiceConnectionsText -match $storageAccount.id} If the results of the second command returns information, the Storage Account is using a Private Endpoint and complies with this Benchmark, otherwise if the results of the second command are empty, the Storage Account generates a finding. Audit from Azure CLI az storage account show --name '<storage account name>' --query \"privateEndpointConnections[0].id\" If the above command returns data, the Storage Account complies with this Benchmark, otherwise if the results are empty, the Storage Account generates a finding. Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: 6edd7eda-6dd8-40f7-810d-67160c639cd9 • Name: 'Storage accounts should use private link'",
    "remediation": "Remediate from Azure Portal 1. Open the Storage Accounts blade 2. For each listed Storage Account, perform the following: 3. Under the Security + networking heading, click on Networking 4. Click on the Private endpoint connections tab at the top of the networking window 5. Click the + Private endpoint button 6. In the 1 - Basics tab/step: o Enter a name that will be easily recognizable as associated with the Storage Account ( Note : The \"Network Interface Name\" will be automatically completed, but you can customize it if needed.) o Ensure that the Region matches the region of the Storage Account o Click Next 7. In the 2 - Resource tab/step: o Select the target sub-resource based on what type of storage resource is being made available o Click Next 8. In the 3 - Virtual Network tab/step: o Select the Virtual network that your Storage Account will be connecting to o Select the Subnet that your Storage Account will be connecting to o (Optional) Select other network settings as appropriate for your environment o Click Next 9. In the 4 - DNS tab/step: o (Optional) Select other DNS settings as appropriate for your environment o Click Next 10. In the 5 - Tags tab/step: o (Optional) Set any tags that are relevant to your organization o Click Next 11. In the 6 - Review + create tab/step: o A validation attempt will be made and after a few moments it should indicate Validation Passed - if it does not pass, double-check your settings before beginning more in depth troubleshooting. o If validation has passed, click Create then wait for a few minutes for the scripted deployment to complete. Repeat the above procedure for each Private Endpoint required within every Storage Account. Remediate from PowerShell $storageAccount = Get-AzStorageAccount -ResourceGroupName '<ResourceGroupName>' -Name '<storageaccountname>' $privateEndpointConnection = @{ Name = 'connectionName' PrivateLinkServiceId = $storageAccount.Id GroupID = \"blob|blob_secondary|file|file_secondary|table|table_secondary|queue|queue_se condary|web|web_secondary|dfs|dfs_secondary\" } $privateLinkServiceConnection = New-AzPrivateLinkServiceConnection @privateEndpointConnection $virtualNetDetails = Get-AzVirtualNetwork -ResourceGroupName '<ResourceGroupName>' -Name '<name>' $privateEndpoint = @{ ResourceGroupName = '<ResourceGroupName>' Name = '<PrivateEndpointName>' Location = '<location>' Subnet = $virtualNetDetails.Subnets[0] PrivateLinkServiceConnection = $privateLinkServiceConnection } New-AzPrivateEndpoint @privateEndpoint  Remediate from Azure CLI az network private-endpoint create --resource-group <ResourceGroupName -- location <location> --name <private endpoint name> --vnet-name <VNET Name> -- subnet <subnet name> --private-connection-resource-id <storage account ID> -- connection-name <private link service connection name> --group-id <blob|blob_secondary|file|file_secondary|table|table_secondary|queue|queue_se condary|web|web_secondary|dfs|dfs_secondary> Default Value: By default, Private Endpoints are not created for Storage Accounts. References: 1. https://docs.microsoft.com/en-us/azure/storage/common/storage-private- endpoints 2. https://docs.microsoft.com/en-us/azure/virtual-network/virtual-networks-overview 3. https://docs.microsoft.com/en-us/azure/private-link/create-private-endpoint-portal 4. https://docs.microsoft.com/en-us/azure/private-link/create-private-endpoint- cli?tabs=dynamic-ip 5. https://docs.microsoft.com/en-us/azure/private-link/create-private-endpoint- powershell?tabs=dynamic-ip 6. https://docs.microsoft.com/en-us/azure/private-link/tutorial-private-endpoint- storage-portal 7. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-network- security#ns-2-secure-cloud-native-services-with-network-controls Additional Information: A NAT gateway is the recommended solution for outbound internet access.",
    "profile_applicability": "•  Level 2",
    "impact": "A Private Endpoint costs approximately US$7.30 per month. If an Azure Virtual Network is not implemented correctly, this may result in the loss of critical network traffic.",
    "references": "1. https://docs.microsoft.com/en-us/azure/storage/common/storage-private- endpoints 2. https://docs.microsoft.com/en-us/azure/virtual-network/virtual-networks-overview 3. https://docs.microsoft.com/en-us/azure/private-link/create-private-endpoint-portal 4. https://docs.microsoft.com/en-us/azure/private-link/create-private-endpoint- cli?tabs=dynamic-ip 5. https://docs.microsoft.com/en-us/azure/private-link/create-private-endpoint- powershell?tabs=dynamic-ip 6. https://docs.microsoft.com/en-us/azure/private-link/tutorial-private-endpoint- storage-portal 7. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-network- security#ns-2-secure-cloud-native-services-with-network-controls Additional Information: A NAT gateway is the recommended solution for outbound internet access.",
    "function_names": [
      "storage_account_private_endpoint_enabled",
      "storage_account_private_link_configured",
      "storage_account_vnet_integration_enabled",
      "storage_account_public_access_disabled",
      "storage_account_network_traffic_encrypted",
      "storage_account_private_endpoint_network_isolated",
      "storage_account_private_endpoint_vnet_peered",
      "storage_account_private_endpoint_remote_infrastructure_connected"
    ]
  },
  {
    "id": "17.2.2",
    "title": "Ensure that 'Public Network Access' is 'Disabled' for storage accounts",
    "assessment": "Automated",
    "description": "Disallowing public network access for a storage account overrides the public access settings for individual containers in that storage account for Azure Resource Manager Deployment Model storage accounts. Azure Storage accounts that use the classic deployment model will be retired on August 31, 2024.",
    "rationale": "The default network configuration for a storage account permits a user with appropriate permissions to configure public network access to containers and blobs in a storage account. Keep in mind that public access to a container is always turned off by default and must be explicitly configured to permit anonymous requests. It grants read-only access to these resources without sharing the account key, and without requiring a shared access signature. It is recommended not to provide public network access to storage accounts until, and unless, it is strongly desired. A shared access signature token or Azure AD RBAC should be used for providing controlled and timed access to blob containers. Impact: Access will have to be managed using shared access signatures or via Azure AD RBAC. For classic storage accounts (to be retired on August 31, 2024), each container in the account must be configured to block anonymous access. Either configure all containers or to configure at the storage account level, migrate to the Azure Resource Manager deployment model.",
    "audit": "Audit from Azure Portal 1. Go to Storage Accounts. 2. For each storage account, under the Security + networking section, click Networking. 3. Ensure the Public network access setting is set to Disabled. Audit from Azure CLI Ensure publicNetworkAccess is Disabled az storage account show --name <storage-account> --resource-group <resource- group> --query \"{publicNetworkAccess:publicNetworkAccess}\"  Audit from PowerShell For each Storage Account, ensure PublicNetworkAccess is Disabled Get-AzStorageAccount -Name <storage account name> -ResourceGroupName <resource group name> |select PublicNetworkAccess Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: b2982f36-99f2-4db5-8eff-283140c09693 • Name: 'Storage accounts should disable public network access'",
    "remediation": "Remediate from Azure Portal First, follow Microsoft documentation and create shared access signature tokens for your blob containers. Then, 1. Go to Storage Accounts. 2. For each storage account, under the Security + networking section, click Networking. 3. Set Public network access to Disabled. 4. Click Save. Remediate from Azure CLI Set 'Public Network Access' to Disabled on the storage account az storage account update --name <storage-account> --resource-group <resource-group> --public-network-access Disabled Remediate from PowerShell For each Storage Account, run the following to set the PublicNetworkAccess setting to Disabled Set-AzStorageAccount -ResourceGroupName <resource group name> -Name <storage account name> -PublicNetworkAccess Disabled Default Value: By default, Public Network Access is set to Enabled from all networks for the Storage Account. References: 1. https://docs.microsoft.com/en-us/azure/storage/blobs/storage-manage-access-to- resources 2. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-governance- strategy#gs-2-define-and-implement-enterprise-segmentationseparation-of- duties-strategy 3. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-network- security#ns-2-secure-cloud-native-services-with-network-controls 4. https://docs.microsoft.com/en-us/azure/storage/blobs/assign-azure-role-data- access 5. https://learn.microsoft.com/en-us/azure/storage/common/storage-network- security?tabs=azure-portal Additional Information: This recommendation is based on the Common Reference Recommendation Ensure public network access is Disabled, from the Common Reference Recommendations > Networking > Virtual Networks (VNets) section.",
    "profile_applicability": "•  Level 1",
    "impact": "Access will have to be managed using shared access signatures or via Azure AD RBAC. For classic storage accounts (to be retired on August 31, 2024), each container in the account must be configured to block anonymous access. Either configure all containers or to configure at the storage account level, migrate to the Azure Resource Manager deployment model.",
    "references": "1. https://docs.microsoft.com/en-us/azure/storage/blobs/storage-manage-access-to- resources 2. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-governance- strategy#gs-2-define-and-implement-enterprise-segmentationseparation-of- duties-strategy 3. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-network- security#ns-2-secure-cloud-native-services-with-network-controls 4. https://docs.microsoft.com/en-us/azure/storage/blobs/assign-azure-role-data- access 5. https://learn.microsoft.com/en-us/azure/storage/common/storage-network- security?tabs=azure-portal Additional Information: This recommendation is based on the Common Reference Recommendation Ensure public network access is Disabled, from the Common Reference Recommendations > Networking > Virtual Networks (VNets) section.",
    "function_names": [
      "storage_account_public_network_access_disabled",
      "storage_account_network_access_restricted",
      "storage_account_public_access_disabled",
      "storage_account_network_policy_disabled",
      "storage_account_public_endpoint_disabled",
      "storage_account_firewall_enabled",
      "storage_account_private_endpoint_only",
      "storage_account_public_access_override_disabled"
    ]
  },
  {
    "id": "17.2.3",
    "title": "Ensure Default Network Access Rule for Storage Accounts is Set to Deny",
    "assessment": "Automated",
    "description": "Restricting default network access helps to provide a new layer of security, since storage accounts accept connections from clients on any network. To limit access to selected networks, the default action must be changed.",
    "rationale": "Storage accounts should be configured to deny access to traffic from all networks (including internet traffic). Access can be granted to traffic from specific Azure Virtual networks, allowing a secure network boundary for specific applications to be built. Access can also be granted to public internet IP address ranges to enable connections from specific internet or on-premises clients. When network rules are configured, only applications from allowed networks can access a storage account. When calling from an allowed network, applications continue to require proper authorization (a valid access key or SAS token) to access the storage account. Impact: All allowed networks will need to be whitelisted on each specific network, creating administrative overhead. This may result in loss of network connectivity, so do not turn on for critical resources during business hours.",
    "audit": "Audit from Azure Portal 1. Go to Storage Accounts. 2. For each storage account, under Security + networking, click Networking. 3. Click the Firewalls and virtual networks heading. 4. Ensure that Public network access is not set to Enabled from all networks. Audit from Azure CLI Ensure defaultAction is not set to Allow. az storage account list --query '[*].networkRuleSet' Audit from PowerShell Connect-AzAccount Set-AzContext -Subscription <subscription ID> Get-AzStorageAccountNetworkRuleset -ResourceGroupName <resource group> -Name <storage account name> |Select-Object DefaultAction PowerShell Result - Non-Compliant DefaultAction       : Allow PowerShell Result - Compliant DefaultAction       : Deny Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: 34c877ad-507e-4c82-993e-3452a6e0ad3c - Name: 'Storage accounts should restrict network access' • Policy ID: 2a1a9cdf-e04d-429a-8416-3bfb72a1b26f - Name: 'Storage accounts should restrict network access using virtual network rules'",
    "remediation": "Remediate from Azure Portal 1. Go to Storage Accounts. 2. For each storage account, under Security + networking, click Networking. 3. Click the Firewalls and virtual networks heading. 4. Set Public network access to Enabled from selected virtual networks and IP addresses. 5. Add rules to allow traffic from specific networks and IP addresses. 6. Click Save. Remediate from Azure CLI Use the below command to update default-action to Deny. az storage account update --name <StorageAccountName> --resource-group <resourceGroupName> --default-action Deny Default Value: By default, Storage Accounts will accept connections from clients on any network. References: 1. https://docs.microsoft.com/en-us/azure/storage/common/storage-network- security 2. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-governance- strategy#gs-2-define-and-implement-enterprise-segmentationseparation-of- duties-strategy 3. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-network- security#ns-2-secure-cloud-native-services-with-network-controls Additional Information: This recommendation is based on the Common Reference Recommendation Ensure Network Access Rules are set to Deny-by-default, from the Common Reference Recommendations > Networking > Virtual Networks (VNets) section.",
    "profile_applicability": "•  Level 1",
    "impact": "All allowed networks will need to be whitelisted on each specific network, creating administrative overhead. This may result in loss of network connectivity, so do not turn on for critical resources during business hours.",
    "references": "1. https://docs.microsoft.com/en-us/azure/storage/common/storage-network- security 2. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-governance- strategy#gs-2-define-and-implement-enterprise-segmentationseparation-of- duties-strategy 3. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-network- security#ns-2-secure-cloud-native-services-with-network-controls Additional Information: This recommendation is based on the Common Reference Recommendation Ensure Network Access Rules are set to Deny-by-default, from the Common Reference Recommendations > Networking > Virtual Networks (VNets) section.",
    "function_names": [
      "storage_account_network_access_deny_default",
      "storage_account_network_restrict_default",
      "storage_account_default_network_deny",
      "storage_account_network_access_deny_all",
      "storage_account_default_access_deny",
      "storage_account_network_rule_deny_default",
      "storage_account_network_deny_default_rule",
      "storage_account_default_network_rule_deny"
    ]
  },
  {
    "id": "17.4",
    "title": "Ensure that 'Secure transfer required' is set to 'Enabled'",
    "assessment": "Automated",
    "description": "Enable data encryption in transit.",
    "rationale": "The secure transfer option enhances the security of a storage account by only allowing requests to the storage account by a secure connection. For example, when calling REST APIs to access storage accounts, the connection must use HTTPS. Any requests using HTTP will be rejected when 'secure transfer required' is enabled. When using the Azure files service, connection without encryption will fail, including scenarios using SMB 2.1, SMB 3.0 without encryption, and some flavors of the Linux SMB client. Because Azure storage doesn’t support HTTPS for custom domain names, this option is not applied when using a custom domain name.",
    "audit": "Audit from Azure Portal 1. Go to Storage Accounts. 2. For each storage account, under Settings, click Configuration. 3. Ensure that Secure transfer required is set to Enabled. Audit from Azure CLI Use the below command to ensure the Secure transfer required is enabled for all the Storage Accounts by ensuring the output contains true for each of the Storage Accounts. az storage account list --query \"[*].[name,enableHttpsTrafficOnly]\"  Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: 404c3081-a854-4457-ae30-26a93ef643f9 - Name: 'Secure transfer to storage accounts should be enabled'",
    "remediation": "Remediate from Azure Portal 1. Go to Storage Accounts. 2. For each storage account, under Settings, click Configuration. 3. Set Secure transfer required to Enabled. 4. Click Save. Remediate from Azure CLI Use the below command to enable Secure transfer required for a Storage Account az storage account update --name <storageAccountName> --resource-group <resourceGroupName> --https-only true Default Value: By default, Secure transfer required is set to Disabled. References: 1. https://docs.microsoft.com/en-us/azure/storage/blobs/security- recommendations#encryption-in-transit 2. https://docs.microsoft.com/en-us/cli/azure/storage/account?view=azure-cli- latest#az_storage_account_list 3. https://docs.microsoft.com/en-us/cli/azure/storage/account?view=azure-cli- latest#az_storage_account_update 4. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-data- protection#dp-3-encrypt-sensitive-data-in-transit",
    "profile_applicability": "•  Level 1",
    "references": "1. https://docs.microsoft.com/en-us/azure/storage/blobs/security- recommendations#encryption-in-transit 2. https://docs.microsoft.com/en-us/cli/azure/storage/account?view=azure-cli- latest#az_storage_account_list 3. https://docs.microsoft.com/en-us/cli/azure/storage/account?view=azure-cli- latest#az_storage_account_update 4. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-data- protection#dp-3-encrypt-sensitive-data-in-transit",
    "function_names": [
      "s3_bucket_secure_transfer_required",
      "s3_bucket_encryption_in_transit_enabled",
      "s3_bucket_transfer_requirement_secure",
      "s3_bucket_secure_transfer_enabled",
      "s3_bucket_tls_required_for_transfer"
    ]
  },
  {
    "id": "17.5",
    "title": "Ensure that ‘Enable Infrastructure Encryption’ for Each Storage Account in Azure Storage is Set to ‘enabled’",
    "assessment": "Automated",
    "description": "Enabling encryption at the hardware level on top of the default software encryption for Storage Accounts accessing Azure storage solutions.",
    "rationale": "Azure Storage automatically encrypts all data in a storage account at the network level using 256-bit AES encryption, which is one of the strongest, FIPS 140-2-compliant block ciphers available. Customers who require higher levels of assurance that their data is secure can also enable 256-bit AES encryption at the Azure Storage infrastructure level for double encryption. Double encryption of Azure Storage data protects against a scenario where one of the encryption algorithms or keys may be compromised. Similarly, data is encrypted even before network transmission and in all backups. In this scenario, the additional layer of encryption continues to protect your data. For the most secure implementation of key based encryption, it is recommended to use a Customer Managed asymmetric RSA 2048 Key in Azure Key Vault. Impact: The read and write speeds to the storage will be impacted if both default encryption and Infrastructure Encryption are checked, as a secondary form of encryption requires more resource overhead for the cryptography of information. This performance impact should be considered in an analysis for justifying use of the feature in your environment. Customer-managed keys are recommended for the most secure implementation, leading to overhead of key management. The key will also need to be backed up in a secure location, as loss of the key will mean loss of the information in the storage.",
    "audit": "Audit from Azure Portal 1. From Azure Portal select the portal menu in the top left. 2. Select Storage Accounts. 3. Click on each storage account within each resource group you wish to audit. 4. In the overview, under Security, ensure Infrastructure encryption is set to Enabled.  Audit from Azure CLI az storage blob show \\ --account-name <storage-account> \\ --container-name <container> \\ --name <blob> \\ --query \"properties.serverEncrypted\" Audit from PowerShell $account = Get-AzStorageAccount -ResourceGroupName <resource-group> ` -Name <storage-account> $blob = Get-AzStorageBlob -Context $account.Context ` -Container <container> ` -Blob <blob> $blob.ICloudBlob.Properties.IsServerEncrypted Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: 4733ea7b-a883-42fe-8cac-97454c2a9e4a - Name: 'Storage accounts should have infrastructure encryption'",
    "remediation": "Remediate from Azure Portal 1. During Storage Account creation, in the Encryption tab, check the box next to Enable infrastructure encryption. Remediate from Azure CLI Replace the information within <> with appropriate values: az storage account create \\ --name <storage-account> \\ --resource-group <resource-group> \\ --location <location> \\ --sku Standard_RAGRS \\ --kind StorageV2 \\ --require-infrastructure-encryption Remediate from PowerShell Replace the information within <> with appropriate values: New-AzStorageAccount -ResourceGroupName <resource_group> ` -AccountName <storage-account> ` -Location <location> ` -SkuName \"Standard_RAGRS\" ` -Kind StorageV2 ` -RequireInfrastructureEncryption Enabling Infrastructure Encryption after Storage Account Creation If infrastructure encryption was not enabled on blob storage creation, there is no official way to enable it. Please see the additional information section. Default Value: By default, Infrastructure Encryption is disabled in blob creation. References: 1. https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-encryption- status 2. https://docs.microsoft.com/en-us/azure/storage/common/storage-service- encryption 3. https://docs.microsoft.com/en-us/azure/storage/common/infrastructure- encryption-enable 4. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-data- protection#dp-4-enable-data-at-rest-encryption-by-default Additional Information: The default service side encryption for Azure Storage is enabled on every block blob, append blob, or page blob that was written to Azure Storage after October 20, 2017. Hardware encryption, however, cannot be enabled on a blob storage after its creation. There are ways to copy all data from a blob storage into another or download and reupload into another blob storage. This could result in data loss and is not recommended.",
    "profile_applicability": "•  Level 2",
    "impact": "The read and write speeds to the storage will be impacted if both default encryption and Infrastructure Encryption are checked, as a secondary form of encryption requires more resource overhead for the cryptography of information. This performance impact should be considered in an analysis for justifying use of the feature in your environment. Customer-managed keys are recommended for the most secure implementation, leading to overhead of key management. The key will also need to be backed up in a secure location, as loss of the key will mean loss of the information in the storage.",
    "references": "1. https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-encryption- status 2. https://docs.microsoft.com/en-us/azure/storage/common/storage-service- encryption 3. https://docs.microsoft.com/en-us/azure/storage/common/infrastructure- encryption-enable 4. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-data- protection#dp-4-enable-data-at-rest-encryption-by-default Additional Information: The default service side encryption for Azure Storage is enabled on every block blob, append blob, or page blob that was written to Azure Storage after October 20, 2017. Hardware encryption, however, cannot be enabled on a blob storage after its creation. There are ways to copy all data from a blob storage into another or download and reupload into another blob storage. This could result in data loss and is not recommended.",
    "function_names": [
      "storage_account_infrastructure_encryption_enabled",
      "storage_account_encryption_hardware_enabled",
      "storage_account_double_encryption_enabled",
      "storage_account_infra_encryption_enabled",
      "storage_account_encryption_infra_enabled"
    ]
  },
  {
    "id": "17.6",
    "title": "Ensure 'Allow Azure services on the trusted services list to access this storage account' is Enabled for Storage Account Access",
    "assessment": "Automated",
    "description": "NOTE: This recommendation assumes that the Public network access parameter is set to Enabled from selected virtual networks and IP addresses. Please ensure the prerequisite recommendation has been implemented before proceeding: • Ensure Default Network Access Rule for Storage Accounts is Set to Deny Some Azure services that interact with storage accounts operate from networks that can't be granted access through network rules. To help this type of service work as intended, allow the set of trusted Azure services to bypass the network rules. These services will then use strong authentication to access the storage account. If the Allow Azure services on the trusted services list to access this storage account exception is enabled, the following services are granted access to the storage account: Azure Backup, Azure Data Box, Azure DevTest Labs, Azure Event Grid, Azure Event Hubs, Azure File Sync, Azure HDInsight, Azure Import/Export, Azure Monitor, Azure Networking Services, and Azure Site Recovery (when registered in the subscription).",
    "rationale": "Turning on firewall rules for a storage account will block access to incoming requests for data, including from other Azure services. We can re-enable this functionality by allowing access to trusted Azure services through networking exceptions. Impact: This creates authentication credentials for services that need access to storage resources so that services will no longer need to communicate via network request. There may be a temporary loss of communication as you set each Storage Account. It is recommended to not do this on mission-critical resources during business hours.",
    "audit": "Audit from Azure Portal 1. Go to Storage Accounts. 2. For each storage account, under Security + networking, click Networking. 3. Click on the Firewalls and virtual networks heading. 4. Under Exceptions, ensure that Allow Azure services on the trusted services list to access this storage account is checked. Audit from Azure CLI Ensure bypass contains AzureServices az storage account list --query '[*].networkRuleSet' Audit from PowerShell Connect-AzAccount Set-AzContext -Subscription <subscription ID> Get-AzStorageAccountNetworkRuleset -ResourceGroupName <resource group> -Name <storage account name> |Select-Object Bypass If the response from the above command is None, the storage account configuration is out of compliance with this check. If the response is AzureServices, the storage account configuration is in compliance with this check. Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: c9d007d0-c057-4772-b18c-01e546713bcd - Name: 'Storage accounts should allow access from trusted Microsoft services'",
    "remediation": "Remediate from Azure Portal 1. Go to Storage Accounts. 2. For each storage account, under Security + networking, click Networking. 3. Click on the Firewalls and virtual networks heading. 4. Under Exceptions, check the box next to Allow Azure services on the trusted services list to access this storage account. 5. Click Save. Remediate from Azure CLI Use the below command to update bypass to Azure services. az storage account update --name <StorageAccountName> --resource-group <resourceGroupName> --bypass AzureServices Default Value: By default, Storage Accounts will accept connections from clients on any network. References: 1. https://docs.microsoft.com/en-us/azure/storage/common/storage-network- security 2. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-network- security#ns-2-secure-cloud-native-services-with-network-controls",
    "profile_applicability": "•  Level 2",
    "impact": "This creates authentication credentials for services that need access to storage resources so that services will no longer need to communicate via network request. There may be a temporary loss of communication as you set each Storage Account. It is recommended to not do this on mission-critical resources during business hours.",
    "references": "1. https://docs.microsoft.com/en-us/azure/storage/common/storage-network- security 2. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-network- security#ns-2-secure-cloud-native-services-with-network-controls",
    "function_names": [
      "storage_account_network_trusted_services_access_enabled",
      "storage_account_network_azure_services_access_allowed",
      "storage_account_network_bypass_trusted_services_enabled",
      "storage_account_network_allow_azure_services_access",
      "storage_account_network_trusted_services_exception_enabled",
      "storage_account_network_azure_services_bypass_enabled",
      "storage_account_network_allow_trusted_services_access",
      "storage_account_network_azure_services_access_granted"
    ]
  },
  {
    "id": "17.7",
    "title": "Ensure Soft Delete is Enabled for Azure Containers and Blob Storage",
    "assessment": "Automated",
    "description": "The Azure Storage blobs contain data like ePHI or Financial, which can be secret or personal. Data that is erroneously modified or deleted by an application or other storage account user will cause data loss or unavailability. It is recommended that both Azure Containers with attached Blob Storage and standalone containers with Blob Storage be made recoverable by enabling the soft delete configuration. This is to save and recover data when blobs or blob snapshots are deleted.",
    "rationale": "Containers and Blob Storage data can be incorrectly deleted. An attacker/malicious user may do this deliberately in order to cause disruption. Deleting an Azure Storage blob causes immediate data loss. Enabling this configuration for Azure storage ensures that even if blobs/data were deleted from the storage account, Blobs/data objects are recoverable for a particular time which is set in the \"Retention policies,\" ranging from 7 days to 365 days. Impact: Additional storage costs may be incurred as snapshots are retained.",
    "audit": "Audit from Azure Portal 1. Go to Storage Accounts. 2. For each Storage Account, under Data management, go to Data protection. 3. Ensure that Enable soft delete for blobs is checked. 4. Ensure that Enable soft delete for containers is checked. 5. Ensure that the retention period for both is a sufficient length for your organization.  Audit from Azure CLI Blob Storage: Ensure that the output of the below command contains enabled status as true and days is not empty or null az storage blob service-properties delete-policy show --account-name <storageAccount> --account-key <accountkey> Azure Containers: Ensure that within containerDeleteRetentionPolicy, the enabled property is set to true. az storage account blob-service-properties show --account-name <storageAccount> --resource-group <resourceGroup>",
    "remediation": "Remediate from Azure Portal 1. Go to Storage Accounts. 2. For each Storage Account, under Data management, go to Data protection. 3. Check the box next to Enable soft delete for blobs. 4. Check the box next to Enable soft delete for containers. 5. Set the retention period for both to a sufficient length for your organization. 6. Click Save. Remediate from Azure CLI Update blob storage retention days in below command az storage blob service-properties delete-policy update --days-retained <RetentionDaysValue> --account-name <StorageAccountName> --account-key <AccountKey> --enable true Update container retention with the below command az storage account blob-service-properties update --enable-container-delete-retention true --container-delete-retention-days <days> --account-name <storageAccount> --resource-group <resourceGroup> Default Value: Soft delete for containers and blob storage is enabled by default on storage accounts created via the Azure Portal, and disabled by default on storage accounts created via Azure CLI or PowerShell. References: 1. https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-soft-delete 2. https://docs.microsoft.com/en-us/azure/storage/blobs/soft-delete-container- overview 3. https://docs.microsoft.com/en-us/azure/storage/blobs/soft-delete-container- enable?tabs=azure-portal",
    "profile_applicability": "•  Level 1",
    "impact": "Additional storage costs may be incurred as snapshots are retained.",
    "references": "1. https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-soft-delete 2. https://docs.microsoft.com/en-us/azure/storage/blobs/soft-delete-container- overview 3. https://docs.microsoft.com/en-us/azure/storage/blobs/soft-delete-container- enable?tabs=azure-portal",
    "function_names": [
      "storage_container_soft_delete_enabled",
      "storage_blob_soft_delete_enabled",
      "storage_container_recoverable_deletion_enabled",
      "storage_blob_recoverable_deletion_enabled",
      "storage_container_blob_soft_delete_enabled",
      "storage_blob_snapshot_soft_delete_enabled",
      "storage_container_data_protection_enabled",
      "storage_blob_data_protection_enabled"
    ]
  },
  {
    "id": "17.8",
    "title": "Ensure Storage Logging is Enabled for Queue Service for 'Read', 'Write', and 'Delete' requests",
    "assessment": "Automated",
    "description": "The Storage Queue service stores messages that may be read by any client who has access to the storage account. A queue can contain an unlimited number of messages, each of which can be up to 64KB in size using version 2011-08-18 or newer. Storage Logging happens server-side and allows details for both successful and failed requests to be recorded in the storage account. These logs allow users to see the details of read, write, and delete operations against the queues. Storage Logging log entries contain the following information about individual requests: Timing information such as start time, end-to-end latency, and server latency, authentication details, concurrency information, and the sizes of the request and response messages.",
    "rationale": "Storage Analytics logs contain detailed information about successful and failed requests to a storage service. This information can be used to monitor individual requests and to diagnose issues with a storage service. Requests are logged on a best-effort basis. Storage Analytics logging is not enabled by default for your storage account. Impact: Enabling this setting can have a high impact on the cost of the log analytics service and data storage used by logging more data per each request. Do not enable this without determining your need for this level of logging, and do not forget to check in on data usage and projected cost. Some users have seen their logging costs increase from $10 per month to $10,000 per month.",
    "audit": "Audit from Azure Portal 1. Go to Storage Accounts. 2. For each storage account, under Monitoring, click Diagnostics settings. 3. Select the queue tab indented below the storage account. 4. Ensure that at least one diagnostic setting is listed. 5. Click Edit setting on a diagnostic setting. 6. Ensure that at least one diagnostic setting has StorageRead, StorageWrite, and StorageDelete options selected under the Logs section and that they are sent to an appropriate destination. Audit from Azure CLI Ensure the below command's output contains properties delete, read and write set to true. az storage logging show --services q --account-name <storageAccountName> Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: 7bd000e3-37c7-4928-9f31-86c4b77c5c45 - Name: 'Configure diagnostic settings for Queue Services to Log Analytics workspace'",
    "remediation": "Remediate from Azure Portal 1. Go to Storage Accounts. 2. For each storage account, under Monitoring, click Diagnostics settings. 3. Select the queue tab indented below the storage account. 4. To create a new diagnostic setting, click + Add diagnostic setting. To update an existing diagnostic setting, click Edit setting on the diagnostic setting. 5. Check the boxes next to StorageRead, StorageWrite, and StorageDelete. 6. Select an appropriate destination. 7. Click Save. Remediate from Azure CLI Use the below command to enable the Storage Logging for Queue service. az storage logging update --account-name <storageAccountName> --account-key <storageAccountKey> --services q --log rwd --retention 90 Default Value: By default storage account queue services are not logged. References: 1. https://docs.microsoft.com/en-us/rest/api/storageservices/about-storage- analytics-logging 2. https://docs.microsoft.com/en-us/cli/azure/storage/logging?view=azure-cli-latest 3. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-logging-threat- detection#lt-4-enable-network-logging-for-security-investigation 4. https://docs.microsoft.com/en-us/azure/storage/queues/monitor-queue- storage?tabs=azure-portal Additional Information: We cannot practically generalize detailed audit log requirements for every queue due to their nature and intent. This recommendation may be applicable to storage account queue services where the security is paramount.",
    "profile_applicability": "•  Level 2",
    "impact": "Enabling this setting can have a high impact on the cost of the log analytics service and data storage used by logging more data per each request. Do not enable this without determining your need for this level of logging, and do not forget to check in on data usage and projected cost. Some users have seen their logging costs increase from $10 per month to $10,000 per month.",
    "references": "1. https://docs.microsoft.com/en-us/rest/api/storageservices/about-storage- analytics-logging 2. https://docs.microsoft.com/en-us/cli/azure/storage/logging?view=azure-cli-latest 3. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-logging-threat- detection#lt-4-enable-network-logging-for-security-investigation 4. https://docs.microsoft.com/en-us/azure/storage/queues/monitor-queue- storage?tabs=azure-portal Additional Information: We cannot practically generalize detailed audit log requirements for every queue due to their nature and intent. This recommendation may be applicable to storage account queue services where the security is paramount.",
    "function_names": [
      "storage_queue_logging_enabled",
      "storage_queue_read_logging_enabled",
      "storage_queue_write_logging_enabled",
      "storage_queue_delete_logging_enabled",
      "storage_queue_server_side_logging_enabled",
      "storage_queue_request_logging_enabled",
      "storage_queue_authentication_logging_enabled",
      "storage_queue_latency_logging_enabled",
      "storage_queue_concurrency_logging_enabled",
      "storage_queue_message_size_logging_enabled"
    ]
  },
  {
    "id": "17.9",
    "title": "Ensure Storage logging is Enabled for Blob Service for 'Read', 'Write', and 'Delete' requests",
    "assessment": "Automated",
    "description": "The Storage Blob service provides scalable, cost-efficient object storage in the cloud. Storage Logging happens server-side and allows details for both successful and failed requests to be recorded in the storage account. These logs allow users to see the details of read, write, and delete operations against the blobs. Storage Logging log entries contain the following information about individual requests: timing information such as start time, end-to-end latency, and server latency; authentication details; concurrency information; and the sizes of the request and response messages.",
    "rationale": "Storage Analytics logs contain detailed information about successful and failed requests to a storage service. This information can be used to monitor each individual request to a storage service for increased security or diagnostics. Requests are logged on a best- effort basis. Storage Analytics logging is not enabled by default for your storage account. Impact: Being a level 2, enabling this setting can have a high impact on the cost of data storage used for logging more data per each request. Do not enable this without determining your need for this level of logging or forget to check in on data usage and projected cost.",
    "audit": "Audit from Azure Portal 1. Go to Storage Accounts. 2. For each storage account, under Monitoring, click Diagnostics settings. 3. Select the blob tab indented below the storage account. 4. Ensure that at least one diagnostic setting is listed. 5. Click Edit setting on a diagnostic setting. 6. Ensure that at least one diagnostic setting has StorageRead, StorageWrite, and StorageDelete options selected under the Logs section and that they are sent to an appropriate destination.  Audit from Azure CLI Ensure the below command's output contains properties delete, read and write set to true. az storage logging show --services b --account-name <storageAccountName>  Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: b4fe1a3b-0715-4c6c-a5ea-ffc33cf823cb - Name: 'Configure diagnostic settings for Blob Services to Log Analytics workspace'",
    "remediation": "Remediate from Azure Portal 1. Go to Storage Accounts. 2. For each storage account, under Monitoring, click Diagnostics settings. 3. Select the blob tab indented below the storage account. 4. To create a new diagnostic setting, click + Add diagnostic setting. To update an existing diagnostic setting, click Edit setting on the diagnostic setting. 5. Check the boxes next to StorageRead, StorageWrite, and StorageDelete. 6. Select an appropriate destination. 7. Click Save. Remediate from Azure CLI Use the below command to enable the Storage Logging for Blob service. az storage logging update --account-name <storageAccountName> --account-key <storageAccountKey> --services b --log rwd --retention 90 Default Value: By default, storage account blob service logging is disabled for read, write, and delete operations. References: 1. https://docs.microsoft.com/en-us/rest/api/storageservices/about-storage- analytics-logging 2. https://docs.microsoft.com/en-us/cli/azure/storage/logging?view=azure-cli-latest 3. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-logging-threat- detection#lt-3-enable-logging-for-security-investigation Additional Information: We cannot practically generalize detailed audit log requirements for every blob due to their nature and intent. This recommendation may be applicable to storage account blob service where the security is paramount.",
    "profile_applicability": "•  Level 2",
    "impact": "Being a level 2, enabling this setting can have a high impact on the cost of data storage used for logging more data per each request. Do not enable this without determining your need for this level of logging or forget to check in on data usage and projected cost.",
    "references": "1. https://docs.microsoft.com/en-us/rest/api/storageservices/about-storage- analytics-logging 2. https://docs.microsoft.com/en-us/cli/azure/storage/logging?view=azure-cli-latest 3. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-logging-threat- detection#lt-3-enable-logging-for-security-investigation Additional Information: We cannot practically generalize detailed audit log requirements for every blob due to their nature and intent. This recommendation may be applicable to storage account blob service where the security is paramount.",
    "function_names": [
      "storage_blob_logging_enabled",
      "storage_blob_read_logging_enabled",
      "storage_blob_write_logging_enabled",
      "storage_blob_delete_logging_enabled",
      "storage_blob_all_operations_logging_enabled",
      "storage_blob_server_side_logging_enabled",
      "storage_blob_request_logging_enabled",
      "storage_blob_audit_logging_enabled",
      "storage_blob_operations_logging_enabled",
      "storage_blob_access_logging_enabled"
    ]
  },
  {
    "id": "17.10",
    "title": "Ensure Storage Logging is Enabled for Table Service for 'Read', 'Write', and 'Delete' Requests",
    "assessment": "Automated",
    "description": "Azure Table storage is a service that stores structured NoSQL data in the cloud, providing a key/attribute store with a schema-less design. Storage Logging happens server-side and allows details for both successful and failed requests to be recorded in the storage account. These logs allow users to see the details of read, write, and delete operations against the tables. Storage Logging log entries contain the following information about individual requests: timing information such as start time, end-to-end latency, and server latency; authentication details; concurrency information; and the sizes of the request and response messages.",
    "rationale": "Storage Analytics logs contain detailed information about successful and failed requests to a storage service. This information can be used to monitor each individual request to a storage service for increased security or diagnostics. Requests are logged on a best- effort basis. Storage Analytics logging is not enabled by default for your storage account. Impact: Being a level 2, enabling this setting can have a high impact on the cost of data storage used for logging more data per each request. Do not enable this without determining your need for this level of logging or forget to check in on data usage and projected cost.",
    "audit": "Audit from Azure Portal 1. Go to Storage Accounts. 2. For each storage account, under Monitoring, click Diagnostics settings. 3. Select the table tab indented below the storage account. 4. Ensure that at least one diagnostic setting is listed. 5. Click Edit setting on a diagnostic setting. 6. Ensure that at least one diagnostic setting has StorageRead, StorageWrite, and StorageDelete options selected under the Logs section and that they are sent to an appropriate destination. Audit from Azure CLI Ensure the below command's output contains properties delete, read and write set to true. az storage logging show --services t --account-name <storageAccountName> Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: 2fb86bf3-d221-43d1-96d1-2434af34eaa0 - Name: 'Configure diagnostic settings for Table Services to Log Analytics workspace'",
    "remediation": "Remediate from Azure Portal 1. Go to Storage Accounts. 2. For each storage account, under Monitoring, click Diagnostics settings. 3. Select the table tab indented below the storage account. 4. To create a new diagnostic setting, click + Add diagnostic setting. To update an existing diagnostic setting, click Edit setting on the diagnostic setting. 5. Check the boxes next to StorageRead, StorageWrite, and StorageDelete. 6. Select an appropriate destination. 7. Click Save. Remediate from Azure CLI Use the below command to enable the Storage Logging for Table service. az storage logging update --account-name <storageAccountName> --account-key <storageAccountKey> --services t --log rwd --retention 90 Default Value: By default, storage account table service logging is disabled for read, write, an delete operations References: 1. https://docs.microsoft.com/en-us/rest/api/storageservices/about-storage- analytics-logging 2. https://docs.microsoft.com/en-us/cli/azure/storage/logging?view=azure-cli-latest 3. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-logging-threat- detection#lt-3-enable-logging-for-security-investigation Additional Information: We cannot practically generalize detailed audit log requirements for every table due to their nature and intent. This recommendation may be applicable to storage account table service where the security is paramount.",
    "profile_applicability": "•  Level 2",
    "impact": "Being a level 2, enabling this setting can have a high impact on the cost of data storage used for logging more data per each request. Do not enable this without determining your need for this level of logging or forget to check in on data usage and projected cost.",
    "references": "1. https://docs.microsoft.com/en-us/rest/api/storageservices/about-storage- analytics-logging 2. https://docs.microsoft.com/en-us/cli/azure/storage/logging?view=azure-cli-latest 3. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-logging-threat- detection#lt-3-enable-logging-for-security-investigation Additional Information: We cannot practically generalize detailed audit log requirements for every table due to their nature and intent. This recommendation may be applicable to storage account table service where the security is paramount.",
    "function_names": [
      "storage_table_logging_enabled",
      "storage_table_logging_read_enabled",
      "storage_table_logging_write_enabled",
      "storage_table_logging_delete_enabled",
      "storage_table_logging_all_operations_enabled",
      "storage_table_logging_request_details_captured",
      "storage_table_logging_authentication_details_captured",
      "storage_table_logging_latency_metrics_enabled",
      "storage_table_logging_request_response_sizes_captured",
      "storage_table_logging_server_side_enabled"
    ]
  },
  {
    "id": "17.11",
    "title": "Ensure the 'Minimum TLS version' for storage accounts is set to 'Version 1.2'",
    "assessment": "Automated",
    "description": "In some cases, Azure Storage sets the minimum TLS version to be version 1.0 by default. TLS 1.0 is a legacy version and has known vulnerabilities. This minimum TLS version can be configured to be later protocols such as TLS 1.2.",
    "rationale": "TLS 1.0 has known vulnerabilities and has been replaced by later versions of the TLS protocol. Continued use of this legacy protocol affects the security of data in transit. Impact: When set to TLS 1.2 all requests must leverage this version of the protocol. Applications leveraging legacy versions of the protocol will fail.",
    "audit": "Audit from Azure Portal 1. Go to Storage Accounts. 2. For each storage account, under Settings, click Configuration. 3. Ensure that the Minimum TLS version is set to Version 1.2. Audit from Azure CLI Get a list of all storage accounts and their resource groups az storage account list | jq '.[] | {name, resourceGroup}' Then query the minimumTLSVersion field az storage account show \\ --name <storage-account> \\ --resource-group <resource-group> \\ --query minimumTlsVersion \\ --output tsv Audit from PowerShell To get the minimum TLS version, run the following command: (Get-AzStorageAccount -Name <STORAGEACCOUNTNAME>  -ResourceGroupName <RESOURCEGROUPNAME>).MinimumTlsVersion Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: fe83a0eb-a853-422d-aac2-1bffd182c5d0 - Name: 'Storage accounts should have the specified minimum TLS version'",
    "remediation": "Remediate from Azure Portal 1. Go to Storage Accounts. 2. For each storage account, under Settings, click Configuration. 3. Set the Minimum TLS version to Version 1.2. 4. Click Save. Remediate from Azure CLI az storage account update \\ --name <storage-account> \\ --resource-group <resource-group> \\ --min-tls-version TLS1_2 Remediate from PowerShell To set the minimum TLS version, run the following command: Set-AzStorageAccount -AccountName <STORAGEACCOUNTNAME> ` -ResourceGroupName <RESOURCEGROUPNAME> ` -MinimumTlsVersion TLS1_2 Default Value: If a storage account is created through the portal, the MinimumTlsVersion property for that storage account will be set to TLS 1.2. If a storage account is created through PowerShell or CLI, the MinimumTlsVersion property for that storage account will not be set, and defaults to TLS 1.0. References: 1. https://docs.microsoft.com/en-us/azure/storage/common/transport-layer-security- configure-minimum-version?tabs=portal 2. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-data- protection#dp-3-encrypt-sensitive-data-in-transit",
    "profile_applicability": "•  Level 1",
    "impact": "When set to TLS 1.2 all requests must leverage this version of the protocol. Applications leveraging legacy versions of the protocol will fail.",
    "references": "1. https://docs.microsoft.com/en-us/azure/storage/common/transport-layer-security- configure-minimum-version?tabs=portal 2. https://learn.microsoft.com/en-us/security/benchmark/azure/mcsb-data- protection#dp-3-encrypt-sensitive-data-in-transit",
    "function_names": [
      "storage_account_min_tls_version",
      "storage_account_tls_min_version_1_2",
      "storage_account_tls_1_2_enabled",
      "storage_account_tls_version_compliance",
      "storage_account_tls_secure_version",
      "storage_account_tls_no_legacy_version",
      "storage_account_tls_1_2_or_higher",
      "storage_account_tls_version_configured",
      "storage_account_tls_legacy_disabled",
      "storage_account_tls_secure_min_version"
    ]
  },
  {
    "id": "17.12",
    "title": "Ensure 'Cross Tenant Replication' is not enabled",
    "assessment": "Automated",
    "description": "Cross Tenant Replication in Azure allows data to be replicated across multiple Azure tenants. While this feature can be beneficial for data sharing and availability, it also poses a significant security risk if not properly managed. Unauthorized data access, data leakage, and compliance violations are potential risks. Disabling Cross Tenant Replication ensures that data is not inadvertently replicated across different tenant boundaries without explicit authorization.",
    "rationale": "Disabling Cross Tenant Replication minimizes the risk of unauthorized data access and ensures that data governance policies are strictly adhered to. This control is especially critical for organizations with stringent data security and privacy requirements, as it prevents the accidental sharing of sensitive information. Impact: Disabling Cross Tenant Replication may affect data availability and sharing across different Azure tenants. Ensure that this change aligns with your organizational data sharing and availability requirements.",
    "audit": "Audit from Azure Portal 1. Go to Storage Accounts. 2. For each storage account, under Data management, click Object replication. 3. Click Advanced settings. 4. Ensure Allow cross-tenant replication is not checked. Audit from Azure CLI az storage account list --query \"[*].[name,allowCrossTenantReplication]\" The value of false should be returned for each storage account listed.  Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: 92a89a79-6c52-4a7e-a03f-61306fc49312 - Name: 'Storage accounts should prevent cross tenant object replication'",
    "remediation": "Remediate from Azure Portal 1. Go to Storage Accounts. 2. For each storage account, under Data management, click Object replication. 3. Click Advanced settings. 4. Uncheck Allow cross-tenant replication. 5. Click OK. Remediate from Azure CLI Replace the information within <> with appropriate values: az storage account update --name <storageAccountName> --resource-group <resourceGroupName> --allow-cross-tenant-replication false Default Value: For new storage accounts created after Dec 15, 2023 cross tenant replication is not enabled. References: 1. https://learn.microsoft.com/en-us/azure/storage/blobs/object-replication-prevent- cross-tenant-policies?tabs=portal",
    "profile_applicability": "•  Level 1",
    "impact": "Disabling Cross Tenant Replication may affect data availability and sharing across different Azure tenants. Ensure that this change aligns with your organizational data sharing and availability requirements.",
    "references": "1. https://learn.microsoft.com/en-us/azure/storage/blobs/object-replication-prevent- cross-tenant-policies?tabs=portal",
    "function_names": [
      "storage_account_cross_tenant_replication_disabled",
      "storage_account_replication_no_cross_tenant",
      "storage_account_replication_within_tenant_only",
      "storage_account_cross_tenant_replication_restricted",
      "storage_account_replication_same_tenant_enabled"
    ]
  },
  {
    "id": "17.13",
    "title": "Ensure that 'Allow Blob Anonymous Access' is set to 'Disabled'",
    "assessment": "Automated",
    "description": "The Azure Storage setting ‘Allow Blob Anonymous Access’ (aka \"allowBlobPublicAccess\") controls whether anonymous access is allowed for blob data in a storage account. When this property is set to True, it enables public read access to blob data, which can be convenient for sharing data but may carry security risks. When set to False, it disallows public access to blob data, providing a more secure storage environment.",
    "rationale": "If \"Allow Blob Anonymous Access\" is enabled, blobs can be accessed by adding the blob name to the URL to see the contents. An attacker can enumerate a blob using methods, such as brute force, and access them. Exfiltration of data by brute force enumeration of items from a storage account may occur if this setting is set to 'Enabled'. Impact: Additional consideration may be required for exceptional circumstances where elements of a storage account require public accessibility. In these circumstances, it is highly recommended that all data stored in the public facing storage account be reviewed for sensitive or potentially compromising data, and that sensitive or compromising data is never stored in these storage accounts.",
    "audit": "Audit from Azure Portal 1. Go to Storage Accounts. 2. For each storage account, under Settings, click Configuration. 3. Ensure Allow Blob Anonymous Access is set to Disabled. Audit from Azure CLI For every storage account in scope: az storage account show --name \"<yourStorageAccountName>\" --query allowBlobPublicAccess Ensure that every storage account in scope returns false for the \"allowBlobPublicAccess\" setting. Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: 4fa4b6c0-31ca-4c0d-b10d-24b96f62a751 - Name: '[Preview]: Storage account public access should be disallowed'",
    "remediation": "Remediate from Azure Portal 1. Go to Storage Accounts. 2. For each storage account, under Settings, click Configuration. 3. Set Allow Blob Anonymous Access to Disabled. 4. Click Save. Remediate from Powershell For every storage account in scope, run the following: $storageAccount = Get-AzStorageAccount -ResourceGroupName \"<yourResourceGroup>\" -Name \"<yourStorageAccountName>\" $storageAccount.AllowBlobPublicAccess = $false Set-AzStorageAccount -InputObject $storageAccount Default Value: Disabled References: 1. https://learn.microsoft.com/en-us/azure/storage/blobs/anonymous-read-access- prevent?tabs=portal 2. https://learn.microsoft.com/en-us/azure/storage/blobs/anonymous-read-access- prevent?source=recommendations&tabs=portal 3. Classic Storage Accounts: https://learn.microsoft.com/en- us/azure/storage/blobs/anonymous-read-access-prevent-classic?tabs=portal Additional Information: Azure Storage accounts that use the classic deployment model will be retired on August 31, 2024.",
    "profile_applicability": "•  Level 1",
    "impact": "Additional consideration may be required for exceptional circumstances where elements of a storage account require public accessibility. In these circumstances, it is highly recommended that all data stored in the public facing storage account be reviewed for sensitive or potentially compromising data, and that sensitive or compromising data is never stored in these storage accounts.",
    "references": "1. https://learn.microsoft.com/en-us/azure/storage/blobs/anonymous-read-access- prevent?tabs=portal 2. https://learn.microsoft.com/en-us/azure/storage/blobs/anonymous-read-access- prevent?source=recommendations&tabs=portal 3. Classic Storage Accounts: https://learn.microsoft.com/en- us/azure/storage/blobs/anonymous-read-access-prevent-classic?tabs=portal Additional Information: Azure Storage accounts that use the classic deployment model will be retired on August 31, 2024.",
    "function_names": [
      "storage_account_blob_anonymous_access_disabled",
      "storage_account_blob_public_access_disabled",
      "storage_account_allow_blob_public_access_disabled",
      "storage_account_anonymous_blob_access_disabled"
    ]
  },
  {
    "id": "17.14",
    "title": "Ensure Azure Resource Manager Delete locks are applied to Azure Storage Accounts",
    "assessment": "Manual",
    "description": "Azure Resource Manager CannotDelete (Delete) locks can prevent users from accidentally or maliciously deleting a storage account. This feature ensures that while the Storage account can still be modified or used, deletion of the Storage account resource requires removal of the lock by a user with appropriate permissions. This feature is a protective control for the availability of data. By ensuring that a storage account or its parent resource group cannot be deleted without first removing the lock, the risk of data loss is reduced.",
    "rationale": "Applying a Delete lock on storage accounts protects the availability of data by preventing the accidental or unauthorized deletion of the entire storage account. It is a fundamental protective control that can prevent data loss Impact: • Prevents the deletion of the Storage account Resource entirely. • Prevents the deletion of the parent Resource Group containing the locked Storage account resource. • Does not prevent other control plane operations, including modification of configurations, network settings, containers, and access. • Does not prevent deletion of containers or other objects within the storage account.",
    "audit": "Audit from Azure Portal 1. Navigate to the storage account in the Azure portal. 2. For each storage account, under Settings, click Locks. 3. Ensure that a Delete lock exists on the storage account. Audit from Azure CLI az lock list --resource-group <resource-group> \\ --resource-name <storage-account> \\ --resource-type \"Microsoft.Storage/storageAccounts\"  Audit from PowerShell Get-AzResourceLock -ResourceGroupName <RESOURCEGROUPNAME> ` -ResourceName <STORAGEACCOUNTNAME> ` -ResourceType \"Microsoft.Storage/storageAccounts\" Audit from Azure Policy There is currently no built-in Microsoft policy to audit resource locks on storage accounts. Custom and community policy definitions can check for the existence of a “Microsoft.Authorization/locks” resource with an AuditIfNotExists effect.",
    "remediation": "Remediate from Azure Portal 1. Navigate to the storage account in the Azure portal. 2. Under the Settings section, select Locks. 3. Select Add. 4. Provide a Name, and choose Delete for the type of lock. 5. Add a note about the lock if desired. Remediate from Azure CLI Replace the information within <> with appropriate values: az lock create --name <lock> \\ --resource-group <resource-group> \\ --resource <storage-account> \\ --lock-type CanNotDelete \\ --resource-type Microsoft.Storage/storageAccounts Remediate from PowerShell Replace the information within <> with appropriate values: New-AzResourceLock -LockLevel CanNotDelete ` -LockName <lock> ` -ResourceName <storage-account> ` -ResourceType Microsoft.Storage/storageAccounts ` -ResourceGroupName <resource-group> Default Value: By default, no locks are applied to Azure resources, including storage accounts. Locks must be manually configured after resource creation. References: 1. https://learn.microsoft.com/en-us/azure/storage/common/lock-account-resource 2. https://learn.microsoft.com/en-us/azure/azure-resource- manager/management/lock-resources",
    "profile_applicability": "•  Level 1",
    "impact": "• Prevents the deletion of the Storage account Resource entirely. • Prevents the deletion of the parent Resource Group containing the locked Storage account resource. • Does not prevent other control plane operations, including modification of configurations, network settings, containers, and access. • Does not prevent deletion of containers or other objects within the storage account.",
    "references": "1. https://learn.microsoft.com/en-us/azure/storage/common/lock-account-resource 2. https://learn.microsoft.com/en-us/azure/azure-resource- manager/management/lock-resources",
    "function_names": [
      "storage_account_delete_lock_enabled",
      "storage_account_delete_lock_configured",
      "storage_account_resource_lock_applied",
      "storage_account_cannot_delete_lock_enabled",
      "storage_account_protection_lock_enabled",
      "storage_account_availability_lock_enabled",
      "storage_account_resource_lock_configured",
      "storage_account_delete_protection_enabled"
    ]
  },
  {
    "id": "17.15",
    "title": "Ensure Azure Resource Manager ReadOnly locks are considered for Azure Storage Accounts",
    "assessment": "Manual",
    "description": "Adding an Azure Resource Manager ReadOnly lock can prevent users from accidentally or maliciously deleting a storage account, modifying its properties and containers, or creating access assignments. The lock must be removed before the storage account can be deleted or updated. It provides more protection than a CannotDelete-type of resource manager lock. This feature prevents POST operations on a storage account and containers to the Azure Resource Manager control plane, management.azure.com . Blocked operations include listKeys which prevents clients from obtaining the account shared access keys. Microsoft does not recommend ReadOnly locks for storage accounts with Azure Files and Table service containers. This Azure Resource Manager REST API documentation (spec) provides information about the control plane POST operations for Microsoft.Storage resources.",
    "rationale": "Applying a ReadOnly lock on storage accounts protects the confidentiality and availability of data by preventing the accidental or unauthorized deletion of the entire storage account and modification of the account, container properties, or access permissions. It can offer enhanced protection for blob and queue workloads with tradeoffs in usability and compatibility for clients using account shared access keys. Impact: • Prevents the deletion of the Storage account Resource entirely. • Prevents the deletion of the parent Resource Group containing the locked Storage account resource. • Prevents clients from obtaining the storage account shared access keys using a listKeys operation. • Requires Entra credentials to access blob and queue data in the Portal. • Data in Azure Files or the Table service may be inaccessible to clients using the account shared access keys. • Prevents modification of account properties, network settings, containers, and RBAC assignments. • Does not prevent access using existing account shared access keys issued to clients. • Does not prevent deletion of containers or other objects within the storage account.",
    "audit": "Audit from Azure Portal 1. Navigate to the storage account in the Azure portal. 2. For each storage account, under Settings, click Locks. 3. Ensure that a ReadOnly lock exists on the storage account. Audit from Azure CLI az lock list --resource-group <resource-group> \\ --resource-name <storage-account> \\ --resource-type \"Microsoft.Storage/storageAccounts\" Audit from PowerShell Get-AzResourceLock -ResourceGroupName <RESOURCEGROUPNAME> ` -ResourceName <STORAGEACCOUNTNAME> ` -ResourceType \"Microsoft.Storage/storageAccounts\" Audit from Azure Policy There is currently no built-in Microsoft policy to audit resource locks on storage accounts. Custom and community policy definitions can check for the existence of a “Microsoft.Authorization/locks” resource with an AuditIfNotExists effect.",
    "remediation": "Remediate from Azure Portal 1. Navigate to the storage account in the Azure portal. 2. Under the Settings section, select Locks. 3. Select Add. 4. Provide a Name, and choose ReadOnly for the type of lock. 5. Add a note about the lock if desired. Remediate from Azure CLI Replace the information within <> with appropriate values: az lock create --name <lock> \\ --resource-group <resource-group> \\ --resource <storage-account> \\ --lock-type ReadOnly \\ --resource-type Microsoft.Storage/storageAccounts Remediate from PowerShell Replace the information within <> with appropriate values: New-AzResourceLock -LockLevel ReadOnly ` -LockName <lock> ` -ResourceName <storage-account> ` -ResourceType Microsoft.Storage/storageAccounts ` -ResourceGroupName <resource-group> Default Value: By default, no locks are applied to Azure resources, including storage accounts. Locks must be manually configured after resource creation. References: 1. https://learn.microsoft.com/en-us/azure/storage/common/lock-account-resource 2. https://learn.microsoft.com/en-us/azure/azure-resource- manager/management/lock-resources 3. https://github.com/Azure/azure-rest-api-specs/tree/main/specification/storage",
    "profile_applicability": "•  Level 2",
    "impact": "• Prevents the deletion of the Storage account Resource entirely. • Prevents the deletion of the parent Resource Group containing the locked Storage account resource. • Prevents clients from obtaining the storage account shared access keys using a listKeys operation. • Requires Entra credentials to access blob and queue data in the Portal. • Data in Azure Files or the Table service may be inaccessible to clients using the account shared access keys. • Prevents modification of account properties, network settings, containers, and RBAC assignments. • Does not prevent access using existing account shared access keys issued to clients. • Does not prevent deletion of containers or other objects within the storage account.",
    "references": "1. https://learn.microsoft.com/en-us/azure/storage/common/lock-account-resource 2. https://learn.microsoft.com/en-us/azure/azure-resource- manager/management/lock-resources 3. https://github.com/Azure/azure-rest-api-specs/tree/main/specification/storage",
    "function_names": [
      "storage_account_readonly_lock_enabled",
      "storage_account_readonly_lock_configured",
      "storage_account_resource_lock_readonly",
      "storage_account_lock_readonly_required",
      "storage_account_protection_readonly_lock",
      "storage_account_management_lock_readonly",
      "storage_account_arm_lock_readonly",
      "storage_account_delete_protection_readonly_lock",
      "storage_account_modification_protection_readonly_lock",
      "storage_account_management_plane_readonly_lock"
    ]
  },
  {
    "id": "17.16",
    "title": "Ensure Redundancy is set to 'geo-redundant storage (GRS)' on critical Azure Storage Accounts",
    "assessment": "Automated",
    "description": "Geo-redundant storage (GRS) in Azure replicates data three times within the primary region using locally redundant storage (LRS) and asynchronously copies it to a secondary region hundreds of miles away. This setup ensures high availability and resilience by providing 16 nines (99.99999999999999%) durability over a year, safeguarding data against regional outages.",
    "rationale": "Enabling GRS protects critical data from regional failures by maintaining a copy in a geographically separate location. This significantly reduces the risk of data loss, supports business continuity, and meets high availability requirements for disaster recovery. Impact: Enabling geo-redundant storage on Azure storage accounts increases costs due to cross-region data replication.",
    "audit": "Audit from Azure Portal 1. Go to Storage accounts. 2. Click on a storage account. 3. Under Data management, click Redundancy. 4. Ensure that Redundancy is set to Geo-redundant storage (GRS). 5. Repeat steps 1-4 for each storage account. Audit from Azure CLI Run the following command to list storage accounts: az storage account list For each storage account, run the following command: az storage account show --resource-group <resource-group> --name <storage- account> Under sku, ensure that name is set to Standard_GRS.  Audit from PowerShell Run the following command to list storage accounts: Get-AzStorageAccount Run the following command to get the storage account in a resource group with a given name: $storageAccount = Get-AzStorageAccount -ResourceGroupName <resource-group> - Name <storage-account> Run the following command to get the redundancy setting for the storage account: $storageAccount.SKU.Name Ensure that the command returns Standard_GRS. Repeat for each storage account. Audit from Azure Policy If referencing a digital copy of this Benchmark, clicking a Policy ID will open a link to the associated Policy definition in Azure. If referencing a printed copy, you can search Policy IDs from this URL: https://portal.azure.com/#view/Microsoft_Azure_Policy/PolicyMenuBlade/~/Definitions • Policy ID: bf045164-79ba-4215-8f95-f8048dc1780b • Name: 'Geo-redundant storage should be enabled for Storage Accounts'",
    "remediation": "Remediate from Azure Portal 1. Go to Storage accounts. 2. Click on a storage account. 3. Under Data management, click Redundancy. 4. From the Redundancy drop-down menu, select Geo-redundant storage (GRS). 5. Click Save. 6. Repeat steps 1-5 for each storage account requiring remediation. Remediate from Azure CLI For each storage account requiring remediation, run the following command to enable geo-redundant storage: az storage account update --resource-group <resource-group> --name <storage- account> --sku Standard_GRS Remediate from PowerShell For each storage account requiring remediation, run the following command to enable geo-redundant storage: Set-AzStorageAccount -ResourceGroupName <resource-group> -Name <storage- account> -SkuName \"Standard_GRS\" Default Value: When creating a storage account in the Azure Portal, the default redundancy setting is geo-redundant storage (GRS). Using the Azure CLI, the default is read-access geo- redundant storage (RA-GRS). In PowerShell, a redundancy level must be explicitly specified during account creation. References: 1. https://learn.microsoft.com/en-us/azure/storage/common/storage-redundancy 2. https://learn.microsoft.com/en-us/azure/storage/common/redundancy-migration 3. https://learn.microsoft.com/en-us/cli/azure/storage/account?view=azure-cli- latest#az-storage-account-update 4. https://learn.microsoft.com/en-us/powershell/module/az.storage/set- azstorageaccount?view=azps-12.4.0 5. https://learn.microsoft.com/en-us/azure/storage/common/storage-disaster- recovery-guidance Additional Information: When choosing the best redundancy option, weigh the trade-offs between lower costs and higher availability. Key factors to consider include: • The method of data replication within the primary region. • The replication of data from a primary to a geographically distant secondary region for protection against regional disasters (geo-replication). • The necessity for read access to replicated data in the secondary region during an outage in the primary region (geo-replication with read access).",
    "profile_applicability": "•  Level 2",
    "impact": "Enabling geo-redundant storage on Azure storage accounts increases costs due to cross-region data replication.",
    "references": "1. https://learn.microsoft.com/en-us/azure/storage/common/storage-redundancy 2. https://learn.microsoft.com/en-us/azure/storage/common/redundancy-migration 3. https://learn.microsoft.com/en-us/cli/azure/storage/account?view=azure-cli- latest#az-storage-account-update 4. https://learn.microsoft.com/en-us/powershell/module/az.storage/set- azstorageaccount?view=azps-12.4.0 5. https://learn.microsoft.com/en-us/azure/storage/common/storage-disaster- recovery-guidance Additional Information: When choosing the best redundancy option, weigh the trade-offs between lower costs and higher availability. Key factors to consider include: • The method of data replication within the primary region. • The replication of data from a primary to a geographically distant secondary region for protection against regional disasters (geo-replication). • The necessity for read access to replicated data in the secondary region during an outage in the primary region (geo-replication with read access).",
    "function_names": [
      "storage_account_redundancy_geo_redundant",
      "storage_account_replication_geo_redundant_enabled",
      "storage_account_critical_geo_redundant_storage",
      "storage_account_availability_geo_redundant_set",
      "storage_account_resilience_geo_redundant_configured"
    ]
  },
  {
    "id": "18.1",
    "title": "Ensure that shared access signature (SAS) tokens expire within an hour",
    "assessment": "Manual",
    "description": "Shared access signature (SAS) tokens provide restricted access to Azure Storage resources (such as blobs, files, queues, or tables) for a defined time period with specific permissions. It enables users to interact with the resources without exposing account keys, offering precise control over the permitted actions (e.g., read, write) and the duration of access. To minimize security risks, SAS tokens should be configured with the shortest possible lifespan, ideally lasting no longer than an hour.",
    "rationale": "A short lifespan for SAS tokens is recommended to minimize the risk of unauthorized access. SAS tokens grant time-limited access to resources, and a longer duration increases the opportunity for misuse if the token is compromised. By setting a shorter lifespan, the potential for security breaches is reduced. Impact: SAS can pose security risks if they are not managed carefully.",
    "audit": "Currently, SAS token expiration times cannot be audited. Until Microsoft makes the token expiration time a setting rather than a token creation parameter, this recommendation will require manual verification.",
    "remediation": "Remediate from Storage Explorer If SAS have been created without a short lifespan and were created with a stored access policy (SAP), the SAS can be revoked by deleting the SAP or updating the SAP expiration time to a time in the past: 1. In Storage Explorer, expand Storage Accounts. 2. Expand a storage account. 3. Expand Blob Containers, File Shares, Queues, or Tables, and right-click a blob container, file share, queue, or table. 4. Click Manage Stored Access Policies.... 5. Click the trash icon next to a stored access policy. 6. Click Save. 7. Repeat steps 1-6 as needed to revoke SAS created with SAP. Remediate from Azure Portal If SAS have been created without a short lifespan and were not created with a SAP, the SAS can be revoked by regenerating the storage account access keys: Note: Regenerating access keys can affect any applications or Azure services that are dependent on the storage account key. 1. Go to Storage accounts. 2. Click on a storage account. 3. Under Security + networking, click Access keys. 4. Next to each key, click Rotate key. 5. Click Yes to confirm. 6. Repeat steps 1-5 as needed to revoke SAS. Default Value: By default, expiration for shared access signature created from Storage Explorer is set to 24 hours. References: 1. https://docs.microsoft.com/en-us/azure/storage/common/storage-sas-overview 2. https://docs.microsoft.com/en-us/rest/api/storageservices/delegating-access- with-a-shared-access-signature 3. https://learn.microsoft.com/en-us/azure/storage/storage-explorer/vs-azure-tools- storage-explorer-blobs#manage-access-policies-for-a-blob-container Additional Information: This recommendation is based on the recommendation Ensure that shared access signature (SAS) tokens expire within an hour, from the Common Reference Recommendations > Secrets and Keys > Shared Access Signatures section.",
    "profile_applicability": "•  Level 1",
    "impact": "SAS can pose security risks if they are not managed carefully.",
    "references": "1. https://docs.microsoft.com/en-us/azure/storage/common/storage-sas-overview 2. https://docs.microsoft.com/en-us/rest/api/storageservices/delegating-access- with-a-shared-access-signature 3. https://learn.microsoft.com/en-us/azure/storage/storage-explorer/vs-azure-tools- storage-explorer-blobs#manage-access-policies-for-a-blob-container Additional Information: This recommendation is based on the recommendation Ensure that shared access signature (SAS) tokens expire within an hour, from the Common Reference Recommendations > Secrets and Keys > Shared Access Signatures section.",
    "function_names": [
      "storage_account_sas_token_expiry_within_1h",
      "storage_sas_token_short_lived",
      "storage_container_sas_token_expiry_within_1h",
      "storage_blob_sas_token_expiry_within_1h",
      "storage_queue_sas_token_expiry_within_1h",
      "storage_table_sas_token_expiry_within_1h",
      "storage_file_sas_token_expiry_within_1h",
      "storage_sas_token_max_duration_1h"
    ]
  },
  {
    "id": "18.2",
    "title": "Ensure stored access policies (SAP) are used when generating shared access signature (SAS) tokens",
    "assessment": "Manual",
    "description": "Use stored access policies (SAP) when generating shared access signature (SAS) tokens in Azure to centrally manage permissions, expiration, and revocation settings for resource access. Stored access policies can be applied to blob containers, file shares, queues, and tables.",
    "rationale": "Stored access policies provide centralized control over SAS token access, allowing administrators to update permissions or revoke access. This approach strengthens security by reducing the risk of unauthorized access to storage resources. Impact: There is no cost for creating stored access policies, however there is some administrative overhead involved in managing these policies.",
    "audit": "It is not currently possible to retrieve a list of all generated SAS tokens to check if they were associated with a SAP during creation. An SAS token that has been created with a SAP will contain an si parameter that references the stored access policy identifier associated with the SAS, e.g. si=<stored-access-policy-identifier>. The si parameter will be absent from an SAS token created without a SAP.",
    "remediation": "Remediate from Storage Explorer To create a SAP: 1. In Storage Explorer, expand Storage Accounts. 2. Expand a storage account. 3. Expand Blob Containers, File Shares, Queues, or Tables, and right-click a blob container, file share, queue, or table. 4. Click Manage Stored Access Policies.... 5. Under Access Policies, click Add. 6. Modify the ID, Start time, Expiry time, and permissions appropriately. 7. Click Save. 8. Repeat steps 1-7 as needed to create SAP. When generating SAS, select a SAP from the Access policy drop-down. Remediate from Azure Portal If SAS have been created without a SAP, the SAS can be revoked by regenerating the storage account access keys: Note: Regenerating access keys can affect any applications or Azure services that are dependent on the storage account key. 1. Go to Storage accounts. 2. Click on a storage account. 3. Under Security + networking, click Access keys. 4. Next to each key, click Rotate key. 5. Click Yes to confirm. 6. Repeat steps 1-5 as needed to revoke SAS. Default Value: By default, stored access policies are not associated with SAS. To use a stored access policy, it must be explicitly created and linked to the SAS at the time of creation. References: 1. https://learn.microsoft.com/en-us/azure/storage/common/storage-sas- overview#best-practices-when-using-sas 2. https://learn.microsoft.com/en-us/rest/api/storageservices/define-stored-access- policy 3. https://learn.microsoft.com/en-us/azure/storage/storage-explorer/vs-azure-tools- storage-explorer-blobs#manage-access-policies-for-a-blob-container Additional Information: This recommendation is based on the recommendation Ensure stored access policies (SAP) are used when generating shared access signature (SAS) tokens, from the Common Reference Recommendations > Secrets and Keys > Shared Access Signatures section.",
    "profile_applicability": "•  Level 1",
    "impact": "There is no cost for creating stored access policies, however there is some administrative overhead involved in managing these policies.",
    "references": "1. https://learn.microsoft.com/en-us/azure/storage/common/storage-sas- overview#best-practices-when-using-sas 2. https://learn.microsoft.com/en-us/rest/api/storageservices/define-stored-access- policy 3. https://learn.microsoft.com/en-us/azure/storage/storage-explorer/vs-azure-tools- storage-explorer-blobs#manage-access-policies-for-a-blob-container Additional Information: This recommendation is based on the recommendation Ensure stored access policies (SAP) are used when generating shared access signature (SAS) tokens, from the Common Reference Recommendations > Secrets and Keys > Shared Access Signatures section.",
    "function_names": [
      "storage_account_sas_token_stored_access_policy_required",
      "storage_container_sas_token_stored_access_policy_required",
      "storage_file_share_sas_token_stored_access_policy_required",
      "storage_queue_sas_token_stored_access_policy_required",
      "storage_table_sas_token_stored_access_policy_required",
      "storage_sas_token_stored_access_policy_enabled",
      "storage_sas_token_stored_access_policy_centralized_management",
      "storage_sas_token_stored_access_policy_expiration_controlled"
    ]
  },
  {
    "id": "18.3",
    "title": "Ensure Storage Explorer is using the latest version",
    "assessment": "Manual",
    "description": "Ensure all users accessing Azure Storage resources with Storage Explorer are using the latest version of the software, applying updates promptly to safeguard against new vulnerabilities and benefit from the latest security enhancements.",
    "rationale": "Using the latest version of Storage Explorer is essential for safeguarding access to Azure Storage resources. Impact: Using the latest version of Storage Explorer is free and requires minimal administrative effort.",
    "audit": "Audit from Storage Explorer for MacOS 1. Go to Storage Explorer. 2. From the menu bar, click Microsoft Azure Storage Explorer. 3. Click About. 4. Check the Version listed. 5. Compare the installed version with the latest released version from https://github.com/microsoft/AzureStorageExplorer/releases. 6. Ensure that the installed Storage Explorer version matches the latest released version.",
    "remediation": "Remediate from Storage Explorer for MacOS 1. Go to Storage Explorer. 2. From the menu bar, click Microsoft Azure Storage Explorer. 3. Click Check for Updates. 4. Follow the instructions to install the latest version of Storage Explorer. Default Value: By default, new installations of Storage Explorer will utilize the latest released version. References: 1. https://azure.microsoft.com/en-us/products/storage/storage-explorer/#Overview 2. https://github.com/microsoft/AzureStorageExplorer/releases",
    "profile_applicability": "•  Level 1",
    "impact": "Using the latest version of Storage Explorer is free and requires minimal administrative effort.",
    "references": "1. https://azure.microsoft.com/en-us/products/storage/storage-explorer/#Overview 2. https://github.com/microsoft/AzureStorageExplorer/releases",
    "function_names": [
      "storage_explorer_version_latest",
      "storage_explorer_updates_promptly_applied",
      "storage_explorer_vulnerabilities_patched",
      "storage_explorer_security_enhancements_enabled"
    ]
  }
]