[
  {
    "id": "1.1.1",
    "title": "Ensure a separate partition for containers has been created",
    "assessment": "Manual",
    "description": "All Docker containers and their data and metadata is stored under /var/lib/docker directory. By default, /var/lib/docker should be mounted under either the / or /var partitions dependent on how the Linux operating system in use is configured.",
    "rationale": "Docker depends on /var/lib/docker as the default directory where all Docker related files, including the images, are stored. This directory could fill up quickly causing both Docker and the host to become unusable. For this reason, you should create a separate partition (logical volume) for storing Docker files. Impact: None.",
    "audit": "At the Docker host execute one of the below commands: grep '/var/lib/docker\\s' /proc/mounts This should return the partition details for the /var/lib/docker mountpoint. mountpoint -- \"$(docker info -f '{{ .DockerRootDir }}')\" This should return whether the configured root directory is a mount point.",
    "remediation": "For new installations, you should create a separate partition for the /var/lib/docker mount point. For systems which have already been installed, you should use the Logical Volume Manager (LVM) within Linux to create a new partition. Default Value: By default, /var/lib/docker is mounted under the / or /var partitions dependent on how the OS is configured. References: 1. https://www.projectatomic.io/docs/docker-storage-recommendation/ 2. https://docs.docker.com/storage/",
    "function_names": [
      "compute_container_partition_created",
      "compute_container_separate_partition",
      "compute_container_var_lib_docker_partitioned",
      "compute_container_docker_partition_exists",
      "compute_container_dedicated_partition",
      "compute_container_storage_partitioned",
      "compute_container_default_partition_configured",
      "compute_container_metadata_partitioned"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://www.projectatomic.io/docs/docker-storage-recommendation/ 2. https://docs.docker.com/storage/"
  },
  {
    "id": "1.1.2",
    "title": "Ensure only trusted users are allowed to control Docker daemon",
    "assessment": "Manual",
    "description": "The Docker daemon currently requires access to the Docker socket which is, by default, owned by the user root and the group docker.",
    "rationale": "Docker allows you to share a directory between the Docker host and a guest container without limiting the access rights of the container. This means that you can start a container and map the / directory on your host to the container. The container would then be able to modify your host file system without any restrictions. This means that you could gain elevated privileges simply by being a member of the docker group and subsequently start a container which maps the root / directory on the host. Impact: Provided the proceeding instructions are implemented, rights to build and execute containers as normal user would be restricted.",
    "audit": "Execute the following command on the docker host and ensure that only trusted users are members of the docker group. getent group docker",
    "remediation": "You should remove any untrusted users from the docker group. Additionally, you should not create a mapping of sensitive directories from the host to container volumes. Default Value: Not Applicable References: 1. https://docs.docker.com/engine/security/#docker-daemon-attack-surface 2. http://www.projectatomic.io/blog/2015/08/why-we-dont-let-non-root-users-run- docker-in-centos-fedora-or-rhel/",
    "function_names": [
      "docker_daemon_trusted_users_only",
      "docker_socket_restricted_access",
      "docker_daemon_control_restricted",
      "docker_socket_group_membership_restricted",
      "docker_daemon_root_access_restricted",
      "docker_socket_ownership_restricted",
      "docker_daemon_admin_users_restricted",
      "docker_socket_permissions_restricted"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "Provided the proceeding instructions are implemented, rights to build and execute containers as normal user would be restricted.",
    "references": "1. https://docs.docker.com/engine/security/#docker-daemon-attack-surface 2. http://www.projectatomic.io/blog/2015/08/why-we-dont-let-non-root-users-run- docker-in-centos-fedora-or-rhel/"
  },
  {
    "id": "1.1.3",
    "title": "Ensure auditing is configured for the Docker daemon",
    "assessment": "Automated",
    "description": "Audit all Docker daemon activities.",
    "rationale": "As well as auditing the normal Linux file system and system calls, you should also audit the Docker daemon. Because this daemon runs with root privileges. It is very important to audit its activities and usage. Impact: Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "audit": "Verify that there are audit rules for the Docker daemon. For example, you could execute the following command: auditctl -l | grep /usr/bin/dockerd This should show the rules associated with the Docker daemon.",
    "remediation": "You should add rules for the Docker daemon. For example: Add the line below to the /etc/audit/rules.d/audit.rules file: -w /usr/bin/dockerd -k docker Then, restart the audit daemon using the following command systemctl restart auditd Default Value: By default, the Docker daemon is not audited. References: 1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide",
    "function_names": [
      "docker_daemon_auditing_enabled",
      "docker_daemon_logging_enabled",
      "docker_daemon_audit_logs_enabled",
      "docker_daemon_activity_auditing_enabled",
      "docker_daemon_audit_configuration_valid"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "references": "1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide"
  },
  {
    "id": "1.1.4",
    "title": "Ensure auditing is configured for Docker files and directories - /run/containerd",
    "assessment": "Manual",
    "description": "Audit /run/containerd.",
    "rationale": "As well as auditing the normal Linux file system and system calls, you should also audit all Docker related files and directories. The Docker daemon runs with root privileges and its behaviour depends on some key files and directories. /run/containerd is one such directory. As it holds all the information about containers it should be audited. Impact: Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "audit": "You should verify that there is an audit rule applied to the /run/containerd directory. For example, you could execute the command below: auditctl -l | grep /run/containerd This should list a rule for the /run/containerd directory.",
    "remediation": "You should add a rule for the /run/containerd directory. For example, Add the line as below to the /etc/audit/rules.d/audit.rules file: -a exit,always -F path=/run/containerd -F perm=war -k docker Then, restart the audit daemon using the following command systemctl restart auditd Default Value: By default, Docker related files and directories are not audited. References: 1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide",
    "function_names": [
      "auditd_file_auditing_enabled",
      "auditd_containerd_directory_audited",
      "auditd_containerd_file_rules_configured",
      "auditd_containerd_access_monitoring_enabled",
      "auditd_containerd_audit_rules_present",
      "auditd_containerd_logging_enabled",
      "auditd_containerd_file_integrity_monitored",
      "auditd_containerd_audit_policy_configured"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "references": "1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide"
  },
  {
    "id": "1.1.5",
    "title": "Ensure auditing is configured for Docker files and directories - /var/lib/docker",
    "assessment": "Manual",
    "description": "Audit /var/lib/docker.",
    "rationale": "As well as auditing the normal Linux file system and system calls, you should also audit all Docker related files and directories. The Docker daemon runs with root privileges and its behaviour depends on some key files and directories. /var/lib/docker is one such directory. As it holds all the information about containers it should be audited. Impact: Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "audit": "You should verify that there is an audit rule applied to the /var/lib/docker directory. For example, you could execute the command below: auditctl -l | grep /var/lib/docker This should list a rule for the /var/lib/docker directory.",
    "remediation": "You should add a rule for the /var/lib/docker directory. Adding exclusions for /var/lib/docker/overlay2 & /var/lib/docker/volumes reduces the audit messages to a more manageable level. For example, Add the line as below to the /etc/audit/rules.d/audit.rules file: -a exit,always -F path=/var/lib/docker -F perm=war -k docker -a exit,never -F dir=/var/lib/docker/volumes -a exit,never -F dir=/var/lib/docker/overlay2 or for systems with namespace-remapping enabled -a exit,always -F path=/var/lib/docker -F perm=war -k docker -a exit,never -F dir=/var/lib/docker/165536.165536/volumes -a exit,never -F dir=/var/lib/docker/165536.165536/overlay2 Then, restart the audit daemon using the following command systemctl restart auditd Default Value: By default, Docker related files and directories are not audited. References: 1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide",
    "function_names": [
      "compute_docker_audit_logging_enabled",
      "compute_docker_directory_audit_enabled",
      "compute_docker_files_audit_enabled",
      "compute_docker_var_lib_audit_enabled",
      "compute_docker_audit_rules_configured"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "references": "1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide"
  },
  {
    "id": "1.1.6",
    "title": "Ensure auditing is configured for Docker files and directories - /etc/docker",
    "assessment": "Automated",
    "description": "Audit /etc/docker.",
    "rationale": "As well as auditing the normal Linux file system and system calls, you should also audit all Docker related files and directories. The Docker daemon runs with root privilege and its behavior depends on some key files and directories, one of these being /etc/docker. This holds various certificates and keys used for TLS communication between Docker daemon and Docker client and as such it should be audited. Impact: Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "audit": "You should verify that there is an audit rule applied to the /etc/docker directory. For example, you could execute the command below: auditctl -l | grep /etc/docker This should display a rule for the /etc/docker directory.",
    "remediation": "You should add a rule for the /etc/docker directory. For example: Add the line below to the /etc/audit/rules.d/audit.rules file: -w /etc/docker -k docker Then restart the audit daemon. For example: systemctl restart auditd Default Value: By default, Docker related files and directories are not audited. References: 1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide",
    "function_names": [
      "docker_file_audit_enabled",
      "docker_directory_audit_enabled",
      "docker_config_audit_enabled",
      "docker_etc_audit_enabled",
      "docker_file_monitoring_enabled",
      "docker_directory_monitoring_enabled",
      "docker_config_monitoring_enabled",
      "docker_etc_monitoring_enabled",
      "docker_file_audit_logging_enabled",
      "docker_directory_audit_logging_enabled"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "references": "1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide"
  },
  {
    "id": "1.1.7",
    "title": "Ensure auditing is configured for Docker files and directories - docker.service",
    "assessment": "Automated",
    "description": "Audit the docker.service if applicable.",
    "rationale": "As well as auditing the normal Linux file system and system calls, you should also audit all Docker related files and directories. The Docker daemon runs with root privileges and its behavior depends on some key files and directories with docker.service being one such file. The docker.service file might be present if the daemon parameters have been changed by an administrator. If so, it holds various parameters for the Docker daemon and should be audited. Impact: Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "audit": "Step 1 : Find out the file location: systemctl show -p FragmentPath docker.service Step 2 : If the file does not exist, this recommendation does not apply. If the file does exist, verify that there is an audit rule corresponding to the file: For example, you could execute the command below: auditctl -l | grep docker.service This should display a rule for docker.service.",
    "remediation": "If the file exists, a rule for it should be added. For example: Add the line as below in /etc/audit/rules.d/audit.rules file: -w /usr/lib/systemd/system/docker.service -k docker Then restart the audit daemon. For example: systemctl restart auditd Default Value: By default, Docker related files and directories are not audited. The file docker.service may not be present on the system. References: 1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide",
    "function_names": [
      "docker_service_audit_logging_enabled",
      "docker_service_file_auditing_enabled",
      "docker_service_directory_auditing_enabled",
      "docker_service_audit_rules_configured",
      "docker_service_audit_policy_enabled",
      "docker_service_audit_logs_retained",
      "docker_service_audit_logs_immutable",
      "docker_service_audit_logs_encrypted",
      "docker_service_audit_logs_centralized",
      "docker_service_audit_logs_monitoring_enabled"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "references": "1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide"
  },
  {
    "id": "1.1.8",
    "title": "Ensure auditing is configured for Docker files and directories - containerd.sock",
    "assessment": "Automated",
    "description": "Audit containerd.sock, if applicable.",
    "rationale": "As well as auditing the normal Linux file system and system calls, you should also audit the Docker daemon. Because this daemon runs with root privileges, it is very important to audit its activities and usage. Its behavior depends on some key files and directories with containerd.sock being one such file, and as this holds various parameters for the Docker daemon, it should be audited. Impact: Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "audit": "Step 1 : Find out the file location: grep 'containerd.sock' /etc/containerd/config.toml or by checking the Docker --containerd option. Step 2 : If the file does not exist, this recommendation is not applicable. If the file exists, you should verify that there is an audit rule corresponding to the file: For example, you could execute the command below: auditctl -l | grep containerd.sock This should display a rule for containerd.sock.",
    "remediation": "If the file exists, you should add a rule for it. For example: Add the line below to the /etc/audit/rules.d/audit.rules file: -w /run/containerd/containerd.sock -k docker Then restart the audit daemon. For example: systemctl restart auditd Default Value: By default, Docker related files and directories are not audited. The file containerd.sock may not be present, but if it is, it should be audited. References: 1. https://github.com/containerd/containerd/blob/master/docs/ops.md 2. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide 3. https://docs.docker.com/engine/reference/commandline/dockerd/#docker- runtime-execution-options",
    "function_names": [
      "container_runtime_auditd_configured",
      "container_runtime_socket_auditing_enabled",
      "containerd_socket_audit_rules_configured",
      "docker_socket_audit_logging_enabled",
      "container_runtime_file_auditing_active",
      "containerd_sock_audit_policy_configured",
      "docker_auditd_socket_monitoring_enabled",
      "container_runtime_audit_logging_active"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "references": "1. https://github.com/containerd/containerd/blob/master/docs/ops.md 2. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide 3. https://docs.docker.com/engine/reference/commandline/dockerd/#docker- runtime-execution-options"
  },
  {
    "id": "1.1.9",
    "title": "Ensure auditing is configured for Docker files and directories - docker.sock",
    "assessment": "Automated",
    "description": "Audit docker.sock, if applicable.",
    "rationale": "As well as auditing the normal Linux file system and system calls, you should also audit the Docker daemon. Because this daemon runs with root privileges, it is very important to audit its activities and usage. Its behavior depends on some key files and directories with docker.socket being one such file, and as this holds various parameters for the Docker daemon, it should be audited. Impact: Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "audit": "Step 1 : Find out the configuration file location: systemctl show -p FragmentPath docker.sock Step 2 : Locate the socket file location: grep ListenStream <FragmentPath from previous step> Step 3 : If the file does not exist, this recommendation is not applicable. If the file exists, you should verify that there is an audit rule corresponding to the file: For example, you could execute the command below: auditctl -l | grep docker.sock This should display a rule for docker.sock.",
    "remediation": "If the file exists, you should add a rule for it. For example: Add the line below to the /etc/audit/rules.d/audit.rules file: -w /var/run/docker.sock -k docker Then restart the audit daemon. For example: systemctl restart auditd Default Value: By default, Docker related files and directories are not audited. The file docker.sock may not be present, but if it is, it should be audited. References: 1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide",
    "function_names": [
      "docker_socket_auditing_enabled",
      "docker_socket_file_permissions_secure",
      "docker_socket_access_restricted",
      "docker_socket_logging_enabled",
      "docker_socket_monitoring_enabled",
      "docker_socket_ownership_correct",
      "docker_socket_unix_permissions_secure",
      "docker_socket_audit_rules_configured"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "references": "1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide"
  },
  {
    "id": "1.1.10",
    "title": "Ensure auditing is configured for Docker files and directories - /etc/default/docker",
    "assessment": "Automated",
    "description": "Audit /etc/default/docker, if applicable.",
    "rationale": "As well as auditing the normal Linux file system and system calls, you should audit all Docker related files and directories. The Docker daemon runs with root privileges and its behavior depends on some key files and directories. /etc/default/docker is one such file. It holds various parameters related to the Docker daemon and should therefore be audited. Impact: Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "audit": "You should verify that there is an audit rule associated with the /etc/default/docker file. For example, you could execute the command below: auditctl -l | grep /etc/default/docker This should display a rule for the /etc/default/docker file.",
    "remediation": "You should add a rule for the /etc/default/docker file. For example: Add the line below to the /etc/audit/audit.rules file: -w /etc/default/docker -k docker Then restart the audit daemon. For example: systemctl restart auditd Default Value: By default, Docker related files and directories are not audited so these defaults should be changed in line with organizational security policy. The file /etc/default/docker may not be present, and if so, this recommendation is not applicable. References: 1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide",
    "function_names": [
      "docker_file_auditing_enabled",
      "docker_directory_auditing_enabled",
      "docker_config_audit_logging_enabled",
      "docker_default_config_auditing_enabled",
      "docker_system_file_audit_rules_configured",
      "docker_config_file_monitoring_enabled",
      "docker_auditd_rules_configured",
      "docker_sensitive_file_auditing_enabled"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "references": "1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide"
  },
  {
    "id": "1.1.11",
    "title": "Ensure auditing is configured for Docker files and directories - /etc/docker/daemon.json",
    "assessment": "Automated",
    "description": "Audit /etc/docker/daemon.json, if applicable.",
    "rationale": "As well as auditing the normal Linux file system and system calls, you should also audit all Docker related files and directories. The Docker daemon runs with root privileges and its behavior depends on some key files and directories. /etc/docker/daemon.json is one such file. This holds various parameters for the Docker daemon, and as such it should be audited. Impact: Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "audit": "You should verify that there is an audit rule associated with the /etc/docker/daemon.json file. For example, you could execute the command below: auditctl -l | grep /etc/docker/daemon.json This should display a rule for the /etc/docker/daemon.json file.",
    "remediation": "You should add a rule for the /etc/docker/daemon.json file. For example: Add the line below to the /etc/audit/audit.rules file: -w /etc/docker/daemon.json -k docker Then restart the audit daemon. For example: systemctl restart auditd Default Value: By default, Docker related files and directories are not audited. The file /etc/docker/daemon.json may not exist on the system and in that case, this recommendation is not applicable. References: 1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide 2. https://docs.docker.com/engine/reference/commandline/dockerd/#daemon- configuration-file",
    "function_names": [
      "docker_daemon_audit_logging_enabled",
      "docker_daemon_config_file_monitoring_enabled",
      "docker_daemon_json_audit_rules_configured",
      "docker_daemon_file_integrity_monitoring_enabled",
      "docker_daemon_audit_policy_defined",
      "docker_daemon_config_audit_logging_active",
      "docker_daemon_json_file_audit_enabled",
      "docker_daemon_audit_logging_configured"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "references": "1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide 2. https://docs.docker.com/engine/reference/commandline/dockerd/#daemon- configuration-file"
  },
  {
    "id": "1.1.12",
    "title": "Ensure auditing is configured for Docker files and directories - /etc/containerd/config.toml",
    "assessment": "Automated",
    "description": "Audit /etc/containerd/config.toml if applicable",
    "rationale": "As well as auditing the normal Linux file system and system calls, you should also audit the Docker daemon. Because this daemon runs with root privileges it is very important to audit its activities and usage. Its behavior depends on some key files and directories and /etc/containerd/config.toml is one such file as it contains various parameters. If present, it is important that it is audited. Impact: Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "audit": "You should verify that there is an audit rule present relating to the /etc/containerd/config.toml file. For example, you could execute the command below: auditctl -l | grep /etc/containerd/config.toml This should display a rule for /etc/containerd/config.toml file.",
    "remediation": "You should add a rule for /etc/containerd/config.toml file. For example: Add the line below to the /etc/audit/audit.rules file: -w /etc/containerd/config.toml -k docker Then restart the audit daemon. For example: systemctl restart auditd Default Value: By default, Docker related files and directories are not audited. The file /etc/containerd/config.toml may not be present on the system and in that case, this recommendation is not applicable. References: 1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide",
    "function_names": [
      "container_runtime_config_audit_enabled",
      "containerd_config_file_auditing_enabled",
      "container_runtime_config_file_monitoring_enabled",
      "containerd_config_audit_logging_enabled",
      "container_runtime_config_file_integrity_monitored",
      "containerd_config_file_change_auditing_enabled",
      "container_runtime_config_audit_rules_configured",
      "containerd_config_file_access_audited"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "references": "1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide"
  },
  {
    "id": "1.1.13",
    "title": "Ensure auditing is configured for Docker files and directories - /etc/sysconfig/docker",
    "assessment": "Automated",
    "description": "Audit /etc/sysconfig/docker if applicable",
    "rationale": "As well as auditing the normal Linux file system and system calls, you should also audit the Docker daemon. Because this daemon runs with root privileges it is very important to audit its activities and usage. Its behavior depends on some key files and directories and /etc/sysconfig/docker is one such file as it contains various parameters related to the Docker daemon when run on CentOS and RHEL based distributions. If present, it is important that it is audited. Impact: Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "audit": "You should verify that there is an audit rule present relating to the /etc/sysconfig/docker file. For example, you could execute the command below: auditctl -l | grep /etc/sysconfig/docker This should display a rule for /etc/sysconfig/docker file.",
    "remediation": "You should add a rule for /etc/sysconfig/docker file. For example: Add the line below to the /etc/audit/audit.rules file: -w /etc/sysconfig/docker -k docker Then restart the audit daemon. For example: systemctl restart auditd Default Value: By default, Docker related files and directories are not audited. The file /etc/sysconfig/docker may not be presemt on the system and in that case, this recommendation is not applicable. References: 1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide",
    "function_names": [
      "auditd_file_auditing_enabled",
      "auditd_docker_config_audited",
      "auditd_docker_file_rules_configured",
      "auditd_sysconfig_docker_monitoring_enabled",
      "auditd_docker_directory_audit_rules_present",
      "auditd_docker_config_audit_rules_defined",
      "auditd_docker_file_access_monitored",
      "auditd_docker_config_changes_tracked"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "references": "1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide"
  },
  {
    "id": "1.1.14",
    "title": "Ensure auditing is configured for Docker files and directories - /usr/bin/containerd",
    "assessment": "Automated",
    "description": "Audit /usr/bin/containerd if applicable.",
    "rationale": "As well as auditing the normal Linux file system and system calls, you should audit all Docker related files and directories. The Docker daemon runs with root privileges and its behavior depends on some key files and directories. /usr/bin/containerd is one such file and as such should be audited. Impact: Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "audit": "You should verify that there is an audit rule corresponding to /usr/bin/containerd file. For example, you could execute the command below: auditctl -l | grep /usr/bin/containerd This should display a rule for /usr/bin/containerd file.",
    "remediation": "You should add a rule for the /usr/bin/containerd file. For example: Add the line below to the /etc/audit/audit.rules file: -w /usr/bin/containerd -k docker Then restart the audit daemon. For example: systemctl restart auditd Default Value: By default, Docker related files and directories are not audited. The file /usr/bin/containerd may not be present on the system and in that case, this recommendation is not applicable. References: 1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide 2. https://containerd.io/",
    "function_names": [
      "auditd_file_auditing_enabled",
      "auditd_containerd_auditing_enabled",
      "auditd_file_permissions_audited",
      "auditd_containerd_file_monitored",
      "auditd_file_access_logging_enabled",
      "auditd_containerd_file_audit_rules_configured",
      "auditd_file_integrity_monitoring_enabled",
      "auditd_containerd_file_change_tracking_enabled"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "references": "1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide 2. https://containerd.io/"
  },
  {
    "id": "1.1.15",
    "title": "Ensure auditing is configured for Docker files and directories - /usr/bin/containerd-shim",
    "assessment": "Automated",
    "description": "Audit /usr/bin/containerd-shim if applicable.",
    "rationale": "As well as auditing the normal Linux file system and system calls, you should audit all Docker related files and directories. The Docker daemon runs with root privileges and its behavior depends on some key files and directories. /usr/bin/containerd-shim is one such file and as such should be audited. Impact: Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "audit": "You should verify that there is an audit rule corresponding to /usr/bin/containerd- shim file. For example, you could execute the command below: auditctl -l | grep /usr/bin/containerd-shim This should display a rule for /usr/bin/containerd-shim file.",
    "remediation": "You should add a rule for the /usr/bin/containerd-shim file. For example: Add the line below to the /etc/audit/rules.d/audit.rules file: -w /usr/bin/containerd-shim -k docker Then restart the audit daemon. For example: systemctl restart auditd Default Value: By default, Docker related files and directories are not audited. The file /usr/bin/containerd-shim may not be present on the system and in that case, this recommendation is not applicable. References: 1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide 2. https://containerd.io/",
    "function_names": [
      "auditd_file_auditing_enabled",
      "auditd_containerd_shim_audited",
      "auditd_file_rules_configured",
      "auditd_containerd_shim_monitoring_enabled",
      "auditd_file_access_audited",
      "auditd_containerd_shim_rules_present",
      "auditd_file_integrity_monitored",
      "auditd_containerd_shim_audit_rules_configured"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "references": "1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide 2. https://containerd.io/"
  },
  {
    "id": "1.1.16",
    "title": "Ensure auditing is configured for Docker files and directories - /usr/bin/containerd-shim-runc-v1",
    "assessment": "Manual",
    "description": "Audit /usr/bin/containerd-shim-runc-v1 if applicable.",
    "rationale": "As well as auditing the normal Linux file system and system calls, you should audit all Docker related files and directories. The Docker daemon runs with root privileges and its behavior depends on some key files and directories. /usr/bin/containerd-shim- runc-v1 is one such file and as such should be audited. Impact: Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "audit": "You should verify that there is an audit rule corresponding to /usr/bin/containerd- shim-runc-v1 file. For example, you could execute the command below: auditctl -l | grep /usr/bin/containerd-shim-runc-v1 This should display a rule for /usr/bin/containerd-shim-runc-v1 file.",
    "remediation": "You should add a rule for the /usr/bin/containerd-shim-runc-v1 file. For example: Add the line below to the /etc/audit/audit.rules file: -w /usr/bin/containerd-shim-runc-v1 -k docker Then restart the audit daemon. For example: systemctl restart auditd Default Value: By default, Docker related files and directories are not audited. The file /usr/bin/containerd-shim-runc-v1 may not be present on the system and in that case, this recommendation is not applicable. References: 1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide 2. https://containerd.io/",
    "function_names": [
      "auditd_file_auditing_enabled",
      "auditd_containerd_shim_runc_v1_auditing_enabled",
      "auditd_binary_audit_rules_configured",
      "auditd_container_runtime_auditing_enabled",
      "auditd_docker_file_audit_rules_present",
      "auditd_runc_binary_auditing_enabled",
      "auditd_containerd_shim_audit_rules_configured",
      "auditd_runtime_binaries_auditing_enabled"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "references": "1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide 2. https://containerd.io/"
  },
  {
    "id": "1.1.17",
    "title": "Ensure auditing is configured for Docker files and directories - /usr/bin/containerd-shim-runc-v2",
    "assessment": "Automated",
    "description": "Audit /usr/bin/containerd-shim-runc-v2 if applicable.",
    "rationale": "As well as auditing the normal Linux file system and system calls, you should audit all Docker related files and directories. The Docker daemon runs with root privileges and its behavior depends on some key files and directories. /usr/bin/containerd-shim- runc-v2 is one such file and as such should be audited. Impact: Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "audit": "You should verify that there is an audit rule corresponding to /usr/bin/containerd- shim-runc-v2 file. For example, you could execute the command below: auditctl -l | grep /usr/bin/containerd-shim-runc-v2 This should display a rule for /usr/bin/containerd-shim-runc-v2 file.",
    "remediation": "You should add a rule for the /usr/bin/containerd-shim-runc-v2 file. For example: Add the line below to the /etc/audit/audit.rules file: -w /usr/bin/containerd-shim-runc-v2 -k docker Then restart the audit daemon. For example: systemctl restart auditd Default Value: By default, Docker related files and directories are not audited. The file /usr/bin/containerd-shim-runc-v2 may not be present on the system and in that case, this recommendation is not applicable. References: 1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide 2. https://containerd.io/",
    "function_names": [
      "auditd_file_auditing_enabled",
      "auditd_containerd_shim_runc_v2_audited",
      "auditd_docker_file_auditing_configured",
      "auditd_containerd_shim_runc_v2_monitored",
      "auditd_docker_directory_auditing_enabled"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "references": "1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide 2. https://containerd.io/"
  },
  {
    "id": "1.1.18",
    "title": "Ensure auditing is configured for Docker files and directories - /usr/bin/runc",
    "assessment": "Automated",
    "description": "Audit /usr/bin/runc if applicable",
    "rationale": "As well as auditing the normal Linux file system and system calls, you should also audit all Docker related files and directories. The Docker daemon runs with root privileges and its behavior depends on some key files and directories. /usr/bin/runc is one such file, and as such it should be audited. Impact: Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "audit": "You should verify that there is an audit rule corresponding to /usr/bin/runc file. For example, you could execute the command below: auditctl -l | grep /usr/bin/runc This should display a rule for the /usr/bin/runc file.",
    "remediation": "You should add a rule for /usr/bin/runc file. For example: Add the line below to the /etc/audit/audit.rules file: -w /usr/bin/runc -k docker Then restart the audit daemon. For example: systemctl restart auditd Default Value: By default, Docker related files and directories are not audited. The file /usr/bin/runc may not be present on the system and in that case this recommendation is not applicable. References: 1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide 2. https://containerd.io",
    "function_names": [
      "auditd_file_auditing_enabled",
      "auditd_runc_file_monitored",
      "auditd_docker_directory_audited",
      "auditd_runc_binary_audit_rule_configured",
      "auditd_docker_file_permissions_audited",
      "auditd_runc_executable_audit_enabled",
      "auditd_container_runtime_audit_configured",
      "auditd_docker_related_file_auditing_active"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "Auditing can generate large log files. You should ensure that these are rotated and archived periodically. A separate partition should also be created for audit logs to avoid filling up any other critical partition.",
    "references": "1. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux/8/html/system_design_guide/auditing-the- system_system-design-guide 2. https://containerd.io"
  },
  {
    "id": "1.2.1",
    "title": "Ensure the container host has been Hardened",
    "assessment": "Manual",
    "description": "A container host is able to run one or more containers. It is of utmost importance to harden the host to mitigate host security misconfiguration.",
    "rationale": "You should follow infrastructure security best practices and harden your host OS. Keeping the host system hardened will ensure that host vulnerabilities are mitigated. Not hardening the host system could lead to security exposures and breaches. Impact: None.",
    "audit": "Ensure that the host specific security guidelines are followed. Ask the system administrators which security benchmark the current host system should currently be compliant with and check that security standards associated with this standard are currently in place.",
    "remediation": "You may consider various CIS Security Benchmarks for your container host. If you have other security guidelines or regulatory requirements to adhere to, please follow them as suitable in your environment. Default Value: By default, the host has factory setting and is not hardened. References: 1. https://docs.docker.com/engine/security/ 2. https://www.cisecurity.org/cis-benchmarks/",
    "function_names": [
      "compute_container_host_hardened",
      "compute_container_host_os_updated",
      "compute_container_host_unnecessary_services_disabled",
      "compute_container_host_firewall_enabled",
      "compute_container_host_root_login_disabled",
      "compute_container_host_ssh_hardened",
      "compute_container_host_selinux_enabled",
      "compute_container_host_app_armor_enabled",
      "compute_container_host_kernel_hardened",
      "compute_container_host_minimal_packages_installed"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/engine/security/ 2. https://www.cisecurity.org/cis-benchmarks/"
  },
  {
    "id": "1.2.2",
    "title": "Ensure that the version of Docker is up to date",
    "assessment": "Manual",
    "description": "Frequent releases for Docker are issued which address security vulnerabilities, resolve product bugs and bring in new functionality. You should keep a tab on these product updates and upgrade as frequently as possible in line with the general IT security policy of your organization.",
    "rationale": "By staying up to date on Docker updates, vulnerabilities in the software can be mitigated. An experienced attacker may be able to exploit known vulnerabilities resulting in them being able to attain inappropriate access or to elevate their privileges. If you do not ensure that Docker is running at the most current release consistent with the requirements of of your application, you may introduce unwanted behaviour and it is therefore important to ensure that you monitor software versions and upgrade in a timely fashion. Impact: You should perform a risk assessment regarding Docker version updates and review how they may impact your operations. You should be aware that third-party products that use Docker may require older major versions of Docker to be supported, and this should be reviewed in line with the general IT security policy of your organization, particularly where security vulnerabilities in older versions have been publicly disclosed.",
    "audit": "You should execute the command below in order to verify that the Docker version is up to date in line with the requirements of the application you are running. It should be noted that it is not a security requirement to be at the most up to date version, provided the version you are using does not contain any critical or high security vulnerabilities. docker version",
    "remediation": "You should monitor versions of Docker releases and make sure your software is updated as required. Default Value: Not Applicable References: 1. https://docs.docker.com/engine/install/ 2. https://docs.docker.com/engine/release-notes/",
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "You should perform a risk assessment regarding Docker version updates and review how they may impact your operations. You should be aware that third-party products that use Docker may require older major versions of Docker to be supported, and this should be reviewed in line with the general IT security policy of your organization, particularly where security vulnerabilities in older versions have been publicly disclosed.",
    "references": "1. https://docs.docker.com/engine/install/ 2. https://docs.docker.com/engine/release-notes/"
  },
  {
    "id": "2.1",
    "title": "Run the Docker daemon as a non-root user, if possible",
    "assessment": "Manual",
    "description": "Rootless mode executes the Docker daemon and containers inside a user namespace, with both the daemon and the container are running without root privileges.",
    "rationale": "Rootless mode allows running the Docker daemon and containers as a non-root user to mitigate potential vulnerabilities in the daemon and the container runtime. Impact: There are multiple prerequisites depending on which distribution that is in use, and also known limitations regarding networking and resource limitation. Running in rootless mode also changes the location of any configuration files in use, including all containers using the daemon.",
    "audit": "Running the following command will show any running dockerd processes and which user that is managing the daemon. ps -fe | grep 'dockerd'",
    "remediation": "Follow the current Docker documentation on how to install the Docker daemon as a non-root user. Default Value: The Docker daemon is running as the root user by default. References: 1. https://docs.docker.com/engine/security/rootless/",
    "function_names": [
      "docker_daemon_non_root_user",
      "docker_daemon_rootless_mode_enabled",
      "docker_daemon_user_namespace_enabled",
      "docker_container_non_root_execution",
      "docker_daemon_privilege_escalation_prevented"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "There are multiple prerequisites depending on which distribution that is in use, and also known limitations regarding networking and resource limitation. Running in rootless mode also changes the location of any configuration files in use, including all containers using the daemon.",
    "references": "1. https://docs.docker.com/engine/security/rootless/"
  },
  {
    "id": "2.2",
    "title": "Ensure network traffic is restricted between containers on the default bridge",
    "assessment": "Manual",
    "description": "By default, all network traffic is allowed between containers on the same host on the default network bridge. If not desired, restrict all inter-container communication. Link specific containers together that require communication. Alternatively, you can create custom network and only join containers that need to communicate to that custom network.",
    "rationale": "By default, unrestricted network traffic is enabled between all containers on the same host on the default network bridge. Thus, each container has the potential of reading all packets across the container network on the same host. This might lead to an unintended and unwanted disclosure of information to other containers. Hence, restrict inter-container communication on the default network bridge. Impact: Inter-container communication would be disabled on the default network bridge. If any communication between containers on the same host is desired, then it needs to be explicitly defined using container linking or alternatively custom networks have to be defined.",
    "audit": "Run the below command and verify that the default network bridge has been configured to restrict inter-container communication. docker network ls --quiet | xargs docker network inspect --format '{{ .Name }}: {{ .Options }}' It should return com.docker.network.bridge.enable_icc:false for the default network bridge.",
    "remediation": "Edit the Docker daemon configuration file to ensure that icc is disabled. It should include the following setting \"icc\": false Alernatively, run the docker daemon directly and pass --icc=false as an argument. For Example, dockerd --icc=false Alternatively, you can follow the Docker documentation and create a custom network and only join containers that need to communicate to that custom network. The --icc parameter only applies to the default docker bridge, if custom networks are used then the approach of segmenting networks should be adopted instead. In order for this control to be fully effective, all containers connected to the docker0 bridge should drop the NET_RAW capability, otherwise a compromised container could use raw ethernet packets to communicate with other containers despite this restriction. Default Value: By default, all inter-container communication is allowed on the default network bridge. References: 1. https://docs.docker.com/network/ 2. https://github.com/docker/cli/blob/v20.10.1/man/dockerd.8.md",
    "function_names": [
      "compute_container_network_restricted",
      "compute_container_default_bridge_restricted",
      "compute_container_inter_container_traffic_restricted",
      "compute_container_custom_network_required",
      "compute_container_network_isolation_enabled",
      "compute_container_default_bridge_disabled",
      "compute_container_network_segmentation_enabled",
      "compute_container_traffic_restricted_by_default"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "Inter-container communication would be disabled on the default network bridge. If any communication between containers on the same host is desired, then it needs to be explicitly defined using container linking or alternatively custom networks have to be defined.",
    "references": "1. https://docs.docker.com/network/ 2. https://github.com/docker/cli/blob/v20.10.1/man/dockerd.8.md"
  },
  {
    "id": "2.3",
    "title": "Ensure the logging level is set to 'info'",
    "assessment": "Manual",
    "description": "Set Docker daemon log level to info.",
    "rationale": "Setting up an appropriate log level, configures the Docker daemon to log events that you would want to review later. A base log level of info and above would capture all logs except debug logs. Until and unless required, you should not run Docker daemon at debug log level. Impact: None.",
    "audit": "To confirm this setting a combination of reviewing the dockerd start-up options and a review of any settings in /etc/docker/daemon.json should be completed. To review the dockerd startup options, use: ps -ef | grep dockerd Ensure that either the --log-level parameter is not present or if present, then it is set to info. The contents of /etc/docker/daemon.json should also be reviewed for this setting.",
    "remediation": "Ensure that the Docker daemon configuration file has the following configuration included \"log-level\": \"info\" Alternatively, run the Docker daemon as below: dockerd --log-level=\"info\" Default Value: By default, Docker daemon is set to log level of info. References: 1. https://docs.docker.com/engine/reference/commandline/dockerd/",
    "function_names": [
      "docker_daemon_log_level_info",
      "docker_logging_level_info",
      "container_log_level_info",
      "docker_service_log_level_info",
      "docker_engine_log_level_info"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/engine/reference/commandline/dockerd/"
  },
  {
    "id": "2.4",
    "title": "Ensure Docker is allowed to make changes to iptables",
    "assessment": "Manual",
    "description": "The iptables firewall is used to set up, maintain, and inspect the tables of IP packet filter rules within the Linux kernel. The Docker daemon should be allowed to make changes to the iptables ruleset.",
    "rationale": "Docker will never make changes to your system iptables rules unless you allow it to do so. If you do allow this, Docker server will automatically make any required changes. We recommended letting Docker make changes to iptables automatically in order to avoid networking misconfigurations that could affect the communication between containers and with the outside world. Additionally, this reduces the administrative overhead of updating iptables every time you add containers or modify networking options. Impact: The Docker daemon service requires iptables rules to be enabled before it starts. Any restarts of iptables during Docker daemon operation may result in losing Docker created rules. Adding iptables-persistent to your iptables install can assist with mitigation of this impact.",
    "audit": "To confirm this setting you should review the dockerd start-up options and the settings in /etc/docker/daemon.json To review the dockerd startup options, use: ps -ef | grep dockerd Ensure that the --iptables parameter is either not present or not set to false. The contents of /etc/docker/daemon.json should also be reviewed for this setting.",
    "remediation": "Do not run the Docker daemon with --iptables=false parameter. For example, do not start the Docker daemon as below: dockerd --iptables=false Default Value: By default, iptables is set to true. References: 1. https://docs.docker.com/engine/reference/commandline/dockerd/ 2. https://docs.docker.com/network/iptables/",
    "function_names": [
      "docker_daemon_iptables_changes_allowed",
      "docker_firewall_rules_modification_enabled",
      "docker_iptables_management_permitted",
      "docker_network_iptables_access_granted",
      "docker_kernel_iptables_changes_authorized"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "The Docker daemon service requires iptables rules to be enabled before it starts. Any restarts of iptables during Docker daemon operation may result in losing Docker created rules. Adding iptables-persistent to your iptables install can assist with mitigation of this impact.",
    "references": "1. https://docs.docker.com/engine/reference/commandline/dockerd/ 2. https://docs.docker.com/network/iptables/"
  },
  {
    "id": "2.5",
    "title": "Ensure insecure registries are not used",
    "assessment": "Manual",
    "description": "Docker considers a private registry either secure or insecure. By default, registries are considered secure.",
    "rationale": "A secure registry uses TLS. A copy of registry's CA certificate is placed on the Docker host at /etc/docker/certs.d/<registry-name>/ directory. An insecure registry is one which does not have a valid registry certificate, or one not using TLS. Insecure registries should not be used as they present a risk of traffic interception and modification. Additionally, once a registry has been marked as insecure commands such as docker pull, docker push, and docker search will not result in an error message and users may indefinitely be working with this type of insecure registry without ever being notified of the risk of potential compromise. Impact: None.",
    "audit": "You should execute the command below to find out if any insecure registries are in use: docker info --format 'Insecure Registries: {{.RegistryConfig.InsecureRegistryCIDRs}}'",
    "remediation": "You should ensure that no insecure registries are in use. Default Value: By default, Docker assumes all, but local, registries are secure. References: 1. https://docs.docker.com/registry/insecure/",
    "function_names": [
      "container_registry_insecure_disabled",
      "container_registry_secure_only",
      "container_registry_insecure_usage_blocked",
      "container_registry_secure_connection_required",
      "container_registry_insecure_source_rejected"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/registry/insecure/"
  },
  {
    "id": "2.6",
    "title": "Ensure aufs storage driver is not used",
    "assessment": "Manual",
    "description": "Do not use aufs as the storage driver for your Docker instance.",
    "rationale": "The aufs storage driver is the oldest storage driver used on Linux systems. It is based on a Linux kernel patch-set that is unlikely in future to be merged into the main OS kernel. The aufs driver is also known to cause some serious kernel crashes. aufs only has legacy support within systems using Docker. Most importantly, aufs is not a supported driver in many Linux distributions using latest Linux kernels and has also been deprecated with Docker Engine release 20.10. Impact: aufs is the only storage driver that allows containers to share executable and shared library memory. It might be useful if you are running thousands of containers with the same program or libraries, however its use should be reviewed in line with your organization's security policy.",
    "audit": "Execute the below command and verify that aufs is not used as storage driver: docker info --format 'Storage Driver: {{ .Driver }}' The above command should not return aufs.",
    "remediation": "Do not explicitly use aufs as storage driver. For example, do not start Docker daemon as below: dockerd --storage-driver aufs Default Value: By default, Docker uses overlay2 as the storage driver on most of the platforms. The default storage driver can vary based on your OS vendor. You should use the storage driver that is recommended by your preferred vendor and which is in line with policy around the applications which are being deployed. References: 1. https://docs.docker.com/storage/storagedriver/select-storage-driver/",
    "function_names": [
      "compute_container_aufs_driver_disabled",
      "docker_storage_aufs_disabled",
      "container_runtime_aufs_unused",
      "docker_instance_aufs_driver_absent",
      "compute_container_aufs_prohibited"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "aufs is the only storage driver that allows containers to share executable and shared library memory. It might be useful if you are running thousands of containers with the same program or libraries, however its use should be reviewed in line with your organization's security policy.",
    "references": "1. https://docs.docker.com/storage/storagedriver/select-storage-driver/"
  },
  {
    "id": "2.7",
    "title": "Ensure TLS authentication for Docker daemon is configured",
    "assessment": "Manual",
    "description": "It is possible to make the Docker daemon available remotely over a TCP port. If this is required, you should ensure that TLS authentication is configured in order to restrict access to the Docker daemon via IP address and port.",
    "rationale": "By default, the Docker daemon binds to a non-networked Unix socket and runs with root privileges. If you change the default Docker daemon binding to a TCP port or any other Unix socket, anyone with access to that port or socket could have full access to the Docker daemon and therefore in turn to the host system. For this reason, you should not bind the Docker daemon to another IP/port or a Unix socket. If you must expose the Docker daemon via a network socket, you should configure TLS authentication for the daemon and for any Docker Swarm APIs (if they are in use). This type of configuration restricts the connections to your Docker daemon over the network to a limited number of clients who have access to the TLS client credentials. Impact: You would need to manage and guard certificates and keys for the Docker daemon and Docker clients.",
    "audit": "To confirm this setting, review the dockerd start-up options and any settings in /etc/docker/daemon.json. To review the dockerd startup options, use: ps -ef | grep dockerd Ensure that the below parameters are present: --tlsverify --tlscacert --tlscert --tlskey The contents of /etc/docker/daemon.json to ensure these settings are in place.",
    "remediation": "Follow the steps mentioned in the Docker documentation or other references. Default Value: By default, TLS authentication is not configured. References: 1. https://docs.docker.com/engine/security/https/",
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "You would need to manage and guard certificates and keys for the Docker daemon and Docker clients.",
    "references": "1. https://docs.docker.com/engine/security/https/"
  },
  {
    "id": "2.8",
    "title": "Ensure the default ulimit is configured appropriately",
    "assessment": "Manual",
    "description": "Set the default ulimit options as appropriate in your environment.",
    "rationale": "ulimit provides control over the resources available to the shell and to processes which it starts. Setting system resource limits judiciously can save you from disasters such as a fork bomb. On occasion, even friendly users and legitimate processes can overuse system resources and can make the system unusable. Setting the default ulimit for the Docker daemon enforces the ulimit for all container instances. In this case you would not need to setup ulimit for each container instance. However, the default ulimit can be overridden during container runtime, if needed. Therefore, in order to have proper control over system resources, define a default ulimit as is needed in your environment. Impact: If ulimits are set incorrectly this could cause issues with system resources, possibly causing a denial of service condition.",
    "audit": "To confirm this setting you should review the dockerd start-up options and any settings in /etc/docker/daemon.json. To review the dockerd startup options, use: ps -ef | grep dockerd Ensure that the --default-ulimit parameter is set as appropriate. The contents of /etc/docker/daemon.json should also be reviewed for this setting.",
    "remediation": "Run Docker in daemon mode and pass --default-ulimit as argument with respective ulimits as appropriate in your environment and in line with your security policy. For Example, dockerd --default-ulimit nproc=1024:2048 --default-ulimit nofile=100:200 Default Value: By default, no ulimit is set. References: 1. https://docs.docker.com/engine/reference/commandline/dockerd/#default-ulimit- settings",
    "function_names": [
      "compute_instance_ulimit_configured",
      "compute_instance_ulimit_secure_values",
      "compute_instance_ulimit_no_unlimited",
      "compute_instance_ulimit_hard_limits",
      "compute_instance_ulimit_soft_limits",
      "compute_instance_ulimit_no_insecure_values",
      "compute_instance_ulimit_cis_compliant",
      "compute_instance_ulimit_restricted",
      "compute_instance_ulimit_defined",
      "compute_instance_ulimit_enforced"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "If ulimits are set incorrectly this could cause issues with system resources, possibly causing a denial of service condition.",
    "references": "1. https://docs.docker.com/engine/reference/commandline/dockerd/#default-ulimit- settings"
  },
  {
    "id": "2.9",
    "title": "Enable user namespace support",
    "assessment": "Manual",
    "description": "You should enable user namespace support in Docker daemon to utilize container user to host user re-mapping. This recommendation is beneficial where the containers you are using do not have an explicit container user defined in the container image. If the container images that you are using have a pre-defined non-root user, this recommendation may be skipped as this feature is still in its infancy, and might result in unpredictable issues or difficulty in configuration.",
    "rationale": "The Linux kernel \"user namespace\" support within the Docker daemon provides additional security for the Docker host system. It allows a container to have a unique range of user and group IDs which are outside the traditional user and group range utilized by the host system. For example, the root user can have the expected administrative privileges inside the container but can effectively be mapped to an unprivileged UID on the host system. Impact: User namespace remapping is incompatible with a number of Docker features and also currently breaks some of its functionalities. Reference the Docker documentation and included links for details.",
    "audit": "docker inspect --format='{{ .State.Pid }}' $(docker ps -q) | while read -r line; do ps -h -p \"$line\" -o pid,user; done The above command will find the PID of the container and then list the host user associated with the container process. If the container process is running as root, then this configuration may be non-compliant with your organization's security policy. Alternatively, you can run docker info to ensure that the userns is listed under Security Options: docker info --format '{{ .SecurityOptions }}'",
    "remediation": "Please consult the Docker documentation for various ways in which this can be configured depending upon your requirements. Your steps might also vary based on platform - For example, on Red Hat, sub-UIDs and sub-GIDs mapping creation do not work automatically. You might have to create your own mapping. The high-level steps are as below: Step 1: Ensure that the files /etc/subuid and /etc/subgid exist. touch /etc/subuid /etc/subgid Step 2: Start the docker daemon with --userns-remap flag dockerd --userns-remap=default Default Value: By default, user namespace is not remapped. Consideration should be given to implementing this in line with the requirements of the applications being used and the organization's security policy. References: 1. https://man7.org/linux/man-pages/man7/user_namespaces.7.html 2. https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-user- namespace-options",
    "function_names": [
      "docker_daemon_user_namespace_enabled",
      "docker_daemon_user_remapping_enabled",
      "docker_daemon_namespace_support_enabled",
      "docker_daemon_user_namespace_configured",
      "docker_daemon_non_root_user_mapping_enabled"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "User namespace remapping is incompatible with a number of Docker features and also currently breaks some of its functionalities. Reference the Docker documentation and included links for details.",
    "references": "1. https://man7.org/linux/man-pages/man7/user_namespaces.7.html 2. https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-user- namespace-options"
  },
  {
    "id": "2.10",
    "title": "Ensure the default cgroup usage has been confirmed",
    "assessment": "Manual",
    "description": "The --cgroup-parent option allows you to set the default cgroup parent to use for all containers. If there is no specific usage requirement for this, the setting should be left at its default.",
    "rationale": "System administrators typically define cgroups under which containers are supposed to run. Even if cgroups are not explicitly defined by the system administrators, containers run under docker cgroup by default. It is possible to attach to a different cgroup other than the one which is the default, however this type of usage should be monitored and confirmed because attaching to a different cgroup other than the one that is a default, it could be possible to share resources unevenly causing resource utilization problems on the host. Impact: None.",
    "audit": "In order to confirm this setting, the dockerd start-up options and any settings in /etc/docker/daemon.json should be reviewed. To review the dockerd startup options, use: ps -ef | grep dockerd You should ensure that the --cgroup-parent parameter is either not set or is set as appropriate non-default cgroup. The contents of /etc/docker/daemon.json should also be checked for this setting.",
    "remediation": "The default setting is in line with good security practice and can be left in situ. If you wish to specifically set a non-default cgroup, pass the --cgroup-parent parameter to the Docker daemon when starting it. For example, dockerd --cgroup-parent=/foobar Default Value: By default, docker daemon uses /docker for fs cgroup driver and system.slice for systemd cgroup driver. References: 1. https://docs.docker.com/engine/reference/commandline/dockerd/#default-cgroup- parent",
    "function_names": [
      "compute_container_default_cgroup_parent",
      "compute_container_cgroup_parent_unmodified",
      "compute_container_cgroup_parent_default",
      "compute_container_cgroup_usage_confirmed",
      "compute_container_cgroup_parent_unchanged"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/engine/reference/commandline/dockerd/#default-cgroup- parent"
  },
  {
    "id": "2.11",
    "title": "Ensure base device size is not changed until needed",
    "assessment": "Manual",
    "description": "Under certain circumstances, you might need containers larger than 10G. Where this applies you should carefully choose the base device size.",
    "rationale": "The base device size can be increased on daemon restart. Increasing the base device size allows all future images and containers to be of the new base device size. A user can use this option to expand the base device size, however shrinking is not permitted. This value affects the system wide \u201cbase\u201d empty filesystem that may already be initialized and therefore inherited by pulled images. Although the file system does not allocate the increased size as long as it is empty, more space will be allocated for extra images. This may cause a denial of service condition if the allocated partition becomes full. Impact: None.",
    "audit": "To confirm this setting the dockerd start-up options and any settings in /etc/docker/daemon.json should be reviewed. To review the dockerd startup options, use: ps -ef | grep dockerd Execute the above command and it should not show any --storage-opt dm.basesize parameters. The contents of /etc/docker/daemon.json should also be reviewed",
    "remediation": "Do not set --storage-opt dm.basesize until needed. Default Value: The default base device size is 10G. References: 1. https://docs.docker.com/engine/reference/commandline/dockerd/#storage-driver- options",
    "function_names": [
      "compute_container_base_device_size_unchanged",
      "compute_container_base_device_size_default",
      "compute_container_base_device_size_unmodified",
      "compute_container_base_device_size_standard",
      "compute_container_base_device_size_preserved"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/engine/reference/commandline/dockerd/#storage-driver- options"
  },
  {
    "id": "2.12",
    "title": "Ensure that authorization for Docker client commands is enabled",
    "assessment": "Manual",
    "description": "You should use native Docker authorization plugins or a third party authorization mechanism with the Docker daemon to manage access to Docker client commands.",
    "rationale": "Docker\u2019s out-of-the-box authorization model is currently \"all or nothing\". This means that any user with permission to access the Docker daemon can run any Docker client command. The same is true for remote users accessing Docker\u2019s API to contact the daemon. If you require greater access control, you can create authorization plugins and add them to your Docker daemon configuration. Using an authorization plugin, a Docker administrator can configure granular access policies for managing access to the Docker daemon. Third party integrations of Docker may implement their own authorization models to require authorization with the Docker daemon outside of docker's native authorization plugin (i.e. Kubernetes, Cloud Foundry, Openshift). Impact: Each Docker command needs to pass through the authorization plugin mechanism. This may have a performance impact. It may be possible to use alternative mechanisms that do not have this performance hit.",
    "audit": "To confirm this setting the dockerd start-up options and any settings in /etc/docker/daemon.json should be reviewed. To review the dockerd startup options, use: ps -ef | grep dockerd You should ensure that the --authorization-plugin parameter is set as appropriate if you are using docker native authorization. The contents of /etc/docker/daemon.json should also be reviewed.",
    "remediation": "Step 1 : Install/Create an authorization plugin. Step 2 : Configure the authorization policy as desired. Step 3 : Start the docker daemon as below: dockerd --authorization-plugin=<PLUGIN_ID> Default Value: By default, authorization plugins are not set up. References: 1. https://docs.docker.com/engine/reference/commandline/dockerd/#access- authorization 2. https://docs.docker.com/engine/extend/plugins_authorization/ Additional Information: It should be noted that the native Docker authentication plugin is only one method of enforcing this control so other methods which could potentially be in use should be reviewed before assessing this as a pass or fail in an audit.",
    "function_names": [
      "docker_daemon_authorization_enabled",
      "docker_client_command_auth_required",
      "docker_native_auth_plugin_enabled",
      "docker_third_party_auth_enabled",
      "docker_command_access_control_enabled"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "Each Docker command needs to pass through the authorization plugin mechanism. This may have a performance impact. It may be possible to use alternative mechanisms that do not have this performance hit.",
    "references": "1. https://docs.docker.com/engine/reference/commandline/dockerd/#access- authorization 2. https://docs.docker.com/engine/extend/plugins_authorization/ Additional Information: It should be noted that the native Docker authentication plugin is only one method of enforcing this control so other methods which could potentially be in use should be reviewed before assessing this as a pass or fail in an audit."
  },
  {
    "id": "2.13",
    "title": "Ensure centralized and remote logging is configured",
    "assessment": "Manual",
    "description": "Docker supports various logging mechanisms. A preferable method for storing logs is one that supports centralized and remote management.",
    "rationale": "Centralized and remote logging ensures that all important log records are safe even in the event of a major data availability issue . Docker supports various logging methods and you should use the one that best corresponds to your IT security policy. Impact: None.",
    "audit": "Run docker info and ensure that the Logging Driver property set as appropriate. docker info --format '{{ .LoggingDriver }}' Alternatively, the below command would give you the --log-driver setting. If configured you should ensure that it is set appropriately. ps -ef | grep dockerd The contents of /etc/docker/daemon.json should also be reviewed for this setting.",
    "remediation": "Step 1 : Set up the desired log driver following its documentation. Step 2 : Start the docker daemon using that logging driver. For example: dockerd --log-driver=syslog --log-opt syslog-address=tcp://192.xxx.xxx.xxx Default Value: By default, container logs are maintained as json files References: 1. https://docs.docker.com/config/containers/logging/configure/",
    "function_names": [
      "docker_container_remote_logging_enabled",
      "docker_container_centralized_logging_enabled",
      "docker_container_log_driver_configured",
      "docker_container_log_rotation_enabled",
      "docker_container_log_retention_configured",
      "docker_container_log_destination_secure",
      "docker_container_log_forwarding_enabled",
      "docker_container_log_encryption_enabled"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/config/containers/logging/configure/"
  },
  {
    "id": "2.14",
    "title": "Ensure containers are restricted from acquiring new privileges",
    "assessment": "Manual",
    "description": "By default you should restrict containers from acquiring additional privileges via suid or sgid.",
    "rationale": "A process can set the no_new_priv bit in the kernel and this persists across forks, clones and execve. The no_new_priv bit ensures that the process and its child processes do not gain any additional privileges via suid or sgid bits. This reduces the security risks associated with many dangerous operations because there is a much reduced ability to subvert privileged binaries. Setting this at the daemon level ensures that by default all new containers are restricted from acquiring new privileges. Impact: no_new_priv prevents LSMs such as SELinux from escalating the privileges of individual containers.",
    "audit": "To confirm this setting, you should review the dockerd start-up options and a check of any settings in /etc/docker/daemon.json should also be carried out. To review the dockerd startup options, the following command can be used: ps -ef | grep dockerd You should ensure that the --no-new-privileges parameter is present and that it is not set to false. The contents of /etc/docker/daemon.json should also be reviewed.",
    "remediation": "You should run the Docker daemon as below: dockerd --no-new-privileges Default Value: By default, containers are not restricted from acquiring new privileges. References: 1. https://docs.docker.com/engine/reference/commandline/dockerd/ 2. https://github.com/moby/moby/pull/20727",
    "function_names": [
      "container_security_privilege_escalation_restricted",
      "container_runtime_no_new_privileges",
      "container_process_no_privilege_escalation",
      "container_security_no_suid_sgid",
      "container_runtime_privilege_escalation_disabled",
      "container_process_privilege_restriction_enabled",
      "container_security_no_additional_privileges",
      "container_runtime_privilege_restriction_active"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "no_new_priv prevents LSMs such as SELinux from escalating the privileges of individual containers.",
    "references": "1. https://docs.docker.com/engine/reference/commandline/dockerd/ 2. https://github.com/moby/moby/pull/20727"
  },
  {
    "id": "2.15",
    "title": "Ensure live restore is enabled",
    "assessment": "Manual",
    "description": "The --live-restore option enables full support of daemon-less containers within Docker. It ensures that Docker does not stop containers on shutdown or restore and that it properly reconnects to the container when restarted.",
    "rationale": "One of the important security triads is availability. Setting the --live-restore flag within the Docker daemon ensures that container execution is not interrupted when it is not available. This also makes it easier to update and patch the Docker daemon without application downtime. Impact: None.",
    "audit": "You should run docker info and ensure that the Live Restore Enabled property is set to true. docker info --format '{{ .LiveRestoreEnabled }}' Alternatively, you could run the below command and ensure that --live-restore is in use. ps -ef | grep dockerd The contents of /etc/docker/daemon.json should also be reviewed to ensure this setting is in place.",
    "remediation": "Run Docker in daemon mode and pass --live-restore to it as an argument. For Example, dockerd --live-restore Default Value: By default, --live-restore is not enabled. References: 1. https://docs.docker.com/config/containers/live-restore/",
    "function_names": [
      "docker_daemon_live_restore_enabled",
      "docker_container_restore_on_restart_enabled",
      "docker_service_daemonless_support_enabled",
      "docker_daemon_shutdown_restore_enabled",
      "docker_container_persistence_on_restart_enabled"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/config/containers/live-restore/"
  },
  {
    "id": "2.16",
    "title": "Ensure Userland Proxy is Disabled",
    "assessment": "Manual",
    "description": "The Docker daemon starts a userland proxy service for port forwarding whenever a port is exposed. Where hairpin NAT is available, this service is generally superfluous to requirements and can be disabled.",
    "rationale": "The Docker engine provides two mechanisms for forwarding ports from the host to containers, hairpin NAT, and the use of a userland proxy. In most circumstances, the hairpin NAT mode is preferred as it improves performance and makes use of native Linux iptables functionality instead of using an additional component. Where hairpin NAT is available, the userland proxy should be disabled on startup to reduce the attack surface of the installation. Impact: Some systems with older Linux kernels may not be able to support hairpin NAT and therefore require the userland proxy service. Also, some networking setups can be impacted by the removal of the userland proxy.",
    "audit": "To confirm this setting, you should review the dockerd start-up options and any settings in /etc/docker/daemon.json. To review the dockerd startup options, use: ps -ef | grep dockerd Ensure that the --userland-proxy parameter is set to false. The contents of /etc/docker/daemon.json should also be reviewed for this setting.",
    "remediation": "You should run the Docker daemon as below: dockerd --userland-proxy=false Default Value: By default, the userland proxy is enabled. References: 1. http://windsock.io/the-docker-proxy/ 2. https://github.com/docker/docker/issues/14856 3. https://github.com/docker/docker/issues/22741 4. https://docs.docker.com/config/containers/container-networking/",
    "function_names": [
      "docker_daemon_userland_proxy_disabled",
      "docker_service_proxy_disabled",
      "container_runtime_userland_proxy_disabled",
      "docker_config_proxy_disabled",
      "docker_engine_userland_proxy_disabled"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "Some systems with older Linux kernels may not be able to support hairpin NAT and therefore require the userland proxy service. Also, some networking setups can be impacted by the removal of the userland proxy.",
    "references": "1. http://windsock.io/the-docker-proxy/ 2. https://github.com/docker/docker/issues/14856 3. https://github.com/docker/docker/issues/22741 4. https://docs.docker.com/config/containers/container-networking/"
  },
  {
    "id": "2.17",
    "title": "Ensure that a daemon-wide custom seccomp profile is applied if appropriate",
    "assessment": "Manual",
    "description": "You can choose to apply a custom seccomp profile at a daemon-wide level if needed with this overriding Docker's default seccomp profile.",
    "rationale": "A large number of system calls are exposed to every userland process with many of them not utilized during the entire lifetime of the process. Many applications do not need all these system calls and therefore benefit by having each system call currently in use reviewed in line with organizational security policy. A reduced set of system calls reduces the total kernel surface exposed to the application and therefore improves application security. A custom seccomp profile can be applied instead of Docker's default seccomp profile. Alternatively, if Docker's default profile is adequate for your environment, you can choose to ignore this recommendation. Impact: A misconfigured seccomp profile could possibly interrupt your container environment. Docker-default blocked calls have been carefully scrutinized and address some critical vulnerabilities/issues within container environments (for example, kernel key ring calls). You should therefore exercise extreme care if you choose to override the default settings.",
    "audit": "You should run the command below and review the seccomp profile listed in the Security Options section. If it is default this indicates that Docker's default seccomp profile is applied. docker info --format '{{ .SecurityOptions }}'",
    "remediation": "By default, Docker's default seccomp profile is applied. If this is adequate for your environment, no action is necessary. Alternatively, if you choose to apply your own seccomp profile, use the --seccomp-profile flag at daemon start or put it in the daemon runtime parameters file. dockerd --seccomp-profile </path/to/seccomp/profile> Default Value: By default, Docker applies a default seccomp profile. References: 1. https://docs.docker.com/engine/security/seccomp/",
    "function_names": [
      "container_daemon_seccomp_profile_custom_applied",
      "container_daemon_seccomp_profile_default_overridden",
      "container_daemon_security_profile_custom_enabled",
      "container_seccomp_profile_daemon_wide_applied",
      "container_security_profile_custom_daemon_level_enabled"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "A misconfigured seccomp profile could possibly interrupt your container environment. Docker-default blocked calls have been carefully scrutinized and address some critical vulnerabilities/issues within container environments (for example, kernel key ring calls). You should therefore exercise extreme care if you choose to override the default settings.",
    "references": "1. https://docs.docker.com/engine/security/seccomp/"
  },
  {
    "id": "2.18",
    "title": "Ensure that experimental features are not implemented in production",
    "assessment": "Manual",
    "description": "Experimental features should not be enabled in production.",
    "rationale": "\"Experimental\" is currently a runtime Docker daemon flag rather than being a feature of a separate build. Passing --experimental as a runtime flag to the docker daemon activates experimental features. Whilst \"Experimental\" is considered a stable release, it has a number of features which may not have been fully tested and do not guarantee API stability. Impact: None",
    "audit": "You should run the command below and ensure that the Experimental property is set to false in the Server section. docker version --format '{{ .Server.Experimental }}'",
    "remediation": "You should not pass --experimental as a runtime parameter to the Docker daemon on production systems. Default Value: By default, experimental features are not activated in the Docker daemon. References: 1. https://docs.docker.com/engine/reference/commandline/dockerd/",
    "function_names": [
      "compute_instance_experimental_features_disabled",
      "compute_cluster_experimental_features_disabled",
      "compute_service_experimental_features_disabled",
      "cloud_service_experimental_features_disabled",
      "cloud_resource_experimental_features_disabled",
      "production_environment_experimental_features_disabled",
      "service_feature_experimental_mode_disabled",
      "resource_feature_experimental_mode_disabled"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None",
    "references": "1. https://docs.docker.com/engine/reference/commandline/dockerd/"
  },
  {
    "id": "3.1",
    "title": "Ensure that the docker.service file ownership is set to root:root",
    "assessment": "Automated",
    "description": "You should verify that the docker.service file ownership and group ownership are correctly set to root.",
    "rationale": "The docker.service file contains sensitive parameters that may alter the behavior of the Docker daemon. It should therefore be individually and group owned by the root user in order to ensure that it is not modified or corrupted by a less privileged user. Impact: None.",
    "audit": "Step 1 : Find out the file location: systemctl show -p FragmentPath docker.service Step 2 : If the file does not exist, this recommendation is not applicable. If the file exists, execute the command below including the correct file path in order to verify that the file is owned and group owned by root. For example: stat -c %U:%G /usr/lib/systemd/system/docker.service | grep -v root:root The command above should not return anything.",
    "remediation": "Step 1 : Find out the file location: systemctl show -p FragmentPath docker.service Step 2 : If the file does not exist, this recommendation is not applicable. If the file does exist, you should execute the command below, including the correct file path, in order to set the ownership and group ownership for the file to root. For example, chown root:root /usr/lib/systemd/system/docker.service Default Value: This file may not be present on the system and if it is not, this recommendation is not applicable. By default, if the file is present, the correct permissions are for the ownership and group ownership to be set to \"root\". References: 1. https://docs.docker.com/config/daemon/systemd/",
    "function_names": [
      "docker_service_file_root_ownership",
      "docker_service_file_root_group_ownership",
      "docker_service_file_ownership_root_root"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/config/daemon/systemd/"
  },
  {
    "id": "3.2",
    "title": "Ensure that docker.service file permissions are appropriately set",
    "assessment": "Automated",
    "description": "You should verify that the docker.service file permissions are either set to 644 or to a more restrictive value.",
    "rationale": "The docker.service file contains sensitive parameters that may alter the behavior of the Docker daemon. It should therefore not be writable by any other user other than root in order to ensure that it can not be modified by less privileged users. Impact: None.",
    "audit": "Step 1 : Find out the file location: systemctl show -p FragmentPath docker.service Step 2 : If the file does not exist, this recommendation is not applicable. If the file exists, execute the command below, including the correct file path in order to verify that the file permissions are set to 644 or a more restrictive value. For example: stat -c %a /usr/lib/systemd/system/docker.service",
    "remediation": "Step 1 : Find out the file location: systemctl show -p FragmentPath docker.service Step 2 : If the file does not exist, this recommendation is not applicable. If the file exists, execute the command below including the correct file path to set the file permissions to 644. For example, chmod 644 /usr/lib/systemd/system/docker.service Default Value: This file may not be present on the system. In that case, this recommendation is not applicable. By default, if the file is present, the file permissions are correctly set to 644. References: 1. https://docs.docker.com/articles/systemd/",
    "function_names": [
      "docker_service_file_permissions_restrictive",
      "docker_service_file_permissions_644_or_stricter",
      "docker_service_file_permissions_secure",
      "docker_service_file_permissions_cis_compliant",
      "docker_service_file_permissions_protected"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/articles/systemd/"
  },
  {
    "id": "3.3",
    "title": "Ensure that docker.socket file ownership is set to root:root",
    "assessment": "Automated",
    "description": "You should verify that the docker.socket file ownership and group ownership are correctly set to root.",
    "rationale": "The docker.socket file contains sensitive parameters that may alter the behavior of the Docker remote API. For this reason, it should be owned and group owned by root in order to ensure that it is not modified by less privileged users. Impact: None.",
    "audit": "Step 1 : Find out the file location: systemctl show -p FragmentPath docker.socket Step 2 : If the file does not exist, this recommendation is not applicable. If the file exists, execute the command below, including the correct file path to verify that the file is owned and group-owned by root. For example, stat -c %U:%G /usr/lib/systemd/system/docker.socket | grep -v root:root The command above should not return a value.",
    "remediation": "Step 1 : Find out the file location: systemctl show -p FragmentPath docker.socket Step 2 : If the file does not exist, this recommendation is not applicable. If the file exists, execute the command below, including the correct file path to set the ownership and group ownership for the file to root. For example, chown root:root /usr/lib/systemd/system/docker.socket Default Value: This file may not be present on the system. In that case, this recommendation is not applicable. By default, if the file is present, the ownership and group ownership for it should be set to root. References: 1. https://docs.docker.com/engine/reference/commandline/dockerd/#daemon- socket-option",
    "function_names": [
      "docker_socket_file_ownership_root",
      "docker_socket_group_ownership_root",
      "docker_socket_file_permissions_secure",
      "docker_socket_file_ownership_correct",
      "docker_socket_group_ownership_correct"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/engine/reference/commandline/dockerd/#daemon- socket-option"
  },
  {
    "id": "3.4",
    "title": "Ensure that docker.socket file permissions are set to 644 or more restrictive",
    "assessment": "Automated",
    "description": "You should verify that the file permissions on the docker.socket file are correctly set to 644 or more restrictively.",
    "rationale": "The docker.socket file contains sensitive parameters that may alter the behavior of the Docker remote API. It should therefore be writeable only by root in order to ensure that it is not modified by less privileged users. Impact: None.",
    "audit": "Step 1 : Find out the file location: systemctl show -p FragmentPath docker.socket Step 2 : If the file does not exist, this recommendation is not applicable. If the file exists, you should execute the command below, including the correct file path in order to verify that the file permissions are set to 644 or more restrictively. For example: stat -c %a /usr/lib/systemd/system/docker.socket",
    "remediation": "Step 1 : Find out the file location: systemctl show -p FragmentPath docker.socket Step 2 : If the file does not exist, this recommendation is not applicable. If the file does exist, you should execute the command below, including the correct file path to set the file permissions to 644. For example, chmod 644 /usr/lib/systemd/system/docker.socket Default Value: This file may not be present on the system and in that case, this recommendation is not applicable. By default, if the file is present, the permissions should be set to 644 or more restrictively. References: 1. https://docs.docker.com/engine/reference/commandline/dockerd/#bind-docker-to- another-hostport-or-a-unix-socket 2. https://github.com/YungSang/fedora-atomic- packer/blob/master/oem/docker.socket 3. http://daviddaeschler.com/2014/12/14/centos-7rhel-7-and-docker-containers-on- boot/",
    "function_names": [
      "docker_socket_file_permissions_restrictive",
      "docker_socket_file_permissions_644_or_stricter",
      "docker_socket_file_permissions_secure",
      "docker_socket_file_permissions_compliant",
      "docker_socket_file_permissions_cis_benchmark"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/engine/reference/commandline/dockerd/#bind-docker-to- another-hostport-or-a-unix-socket 2. https://github.com/YungSang/fedora-atomic- packer/blob/master/oem/docker.socket 3. http://daviddaeschler.com/2014/12/14/centos-7rhel-7-and-docker-containers-on- boot/"
  },
  {
    "id": "3.5",
    "title": "Ensure that the /etc/docker directory ownership is set to root:root",
    "assessment": "Automated",
    "description": "You should verify that the /etc/docker directory ownership and group ownership is correctly set to root.",
    "rationale": "The /etc/docker directory contains certificates and keys in addition to various other sensitive files. It should therefore be individual owned and group owned by root in order to ensure that it can not be modified by less privileged users. Impact: None.",
    "audit": "You should execute the command below to verify that the directory is owned and group owned by root: stat -c %U:%G /etc/docker | grep -v root:root This command should not return any data.",
    "remediation": "To resolve this issue you should run the following command: chown root:root /etc/docker This sets the ownership and group ownership for the directory to root. Default Value: By default, the ownership and group ownership for this directory is correctly set to root. References: 1. https://docs.docker.com/engine/security/https/",
    "function_names": [
      "docker_directory_root_ownership",
      "docker_directory_root_group_ownership",
      "docker_directory_secure_ownership",
      "docker_config_root_ownership",
      "docker_config_root_group_ownership",
      "docker_config_secure_ownership",
      "docker_etc_directory_root_ownership",
      "docker_etc_directory_root_group_ownership"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/engine/security/https/"
  },
  {
    "id": "3.6",
    "title": "Ensure that /etc/docker directory permissions are set to 755 or more restrictively",
    "assessment": "Automated",
    "description": "You should verify that the /etc/docker directory permissions are correctly set to 755 or more restrictively.",
    "rationale": "The /etc/docker directory contains certificates and keys in addition to various sensitive files. It should therefore only be writeable by root to ensure that it can not be modified by a less privileged user. Impact: None.",
    "audit": "You should execute the command below to verify that the directory has permissions of 755 or more restrictive ones: stat -c %a /etc/docker",
    "remediation": "You should run the following command: chmod 755 /etc/docker This sets the permissions for the directory to 755. Default Value: By default, the permissions for this directory are set to 755. References: 1. https://docs.docker.com/engine/security/https/",
    "function_names": [
      "docker_directory_permissions_restricted",
      "docker_directory_permissions_755_or_stricter",
      "docker_directory_permissions_secure",
      "docker_directory_permissions_compliant",
      "docker_directory_permissions_cis_benchmark"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/engine/security/https/"
  },
  {
    "id": "3.7",
    "title": "Ensure that registry certificate file ownership is set to root:root",
    "assessment": "Manual",
    "description": "You should verify that all the registry certificate files (usually found under /etc/docker/certs.d/<registry-name> directory) are individually owned and group owned by root.",
    "rationale": "The /etc/docker/certs.d/<registry-name> directory contains Docker registry certificates. These certificate files must be individually owned and group owned by root to ensure that less privileged users are unable to modify the contents of the directory. Impact: None.",
    "audit": "You should execute the command below to verify that the registry certificate files are individually owned and group owned by root: stat -c %U:%G /etc/docker/certs.d/* | grep -v root:root The above command should not return any value.",
    "remediation": "The following command could be executed: chown root:root /etc/docker/certs.d/<registry-name>/* This would set the individual ownership and group ownership for the registry certificate files to root. Default Value: By default, the individual ownership and group ownership for registry certificate files is correctly set to root. References: 1. https://docs.docker.com/registry/insecure/",
    "function_names": [
      "docker_registry_certificate_file_ownership_root",
      "docker_registry_certificate_file_group_ownership_root",
      "docker_certificate_file_ownership_root_root",
      "docker_certificate_file_permissions_root_only"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/registry/insecure/"
  },
  {
    "id": "3.8",
    "title": "Ensure that registry certificate file permissions are set to 444 or more restrictively",
    "assessment": "Manual",
    "description": "You should verify that all the registry certificate files (usually found under /etc/docker/certs.d/<registry-name> directory) have permissions of 444 or are set more restrictively. Note that, by default, this directory might not exist if no registry certificate files are in place.",
    "rationale": "The /etc/docker/certs.d/<registry-name> directory contains Docker registry certificates. These certificate files must have permissions of 444or more restrictive permissions in order to ensure that unprivileged users do not have full access to them.. Impact: None.",
    "audit": "You should execute the command below to verify that registry certificate files have permissions of 444 or are more restrictively set. find /etc/docker/certs.d/ -type f -exec stat -c \"%a %n\" {} \\;",
    "remediation": "You should execute the following command: find /etc/docker/certs.d/ -type f -exec chmod 0444 {} \\; This would set the permissions for the registry certificate files to 444. Default Value: By default, the permissions for registry certificate files might not be 444. The default file permissions are governed by the system or user specific umask values which are defined within the operating system itself. References: 1. https://docs.docker.com/registry/insecure/",
    "function_names": [
      "docker_registry_certificate_permissions_restricted",
      "docker_registry_certificate_permissions_444_or_stricter",
      "docker_certificate_file_permissions_restricted",
      "docker_certificate_file_permissions_444_or_stricter",
      "container_registry_certificate_permissions_restricted",
      "container_registry_certificate_permissions_444_or_stricter"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/registry/insecure/"
  },
  {
    "id": "3.9",
    "title": "Ensure that TLS CA certificate file ownership is set to root:root",
    "assessment": "Manual",
    "description": "You should verify that the TLS CA certificate file (the file that is passed along with the - -tlscacert parameter) is individually owned and group owned by root.",
    "rationale": "The TLS CA certificate file should be protected from any tampering. It is used to authenticate the Docker server based on a given CA certificate. It must be therefore be individually owned and group owned by root to ensure that it cannot be modified by less privileged users. Impact: None.",
    "audit": "You should execute the command below to verify that the TLS CA certificate file is owned and group owned by root: stat -c %U:%G <path to TLS CA certificate file> | grep -v root:root The above command should return no results.",
    "remediation": "You should execute the following command: chown root:root <path to TLS CA certificate file> This sets the individual ownership and group ownership for the TLS CA certificate file to root. Default Value: By default, the ownership and group-ownership for TLS CA certificate file is correctly set to root. References: 1. https://docs.docker.com/registry/insecure/ 2. https://docs.docker.com/engine/security/https/",
    "function_names": [
      "compute_tls_certificate_file_ownership_root",
      "compute_tls_certificate_group_ownership_root",
      "compute_tls_ca_certificate_root_owned",
      "compute_tls_ca_cert_file_ownership_root",
      "compute_tls_cert_file_root_ownership",
      "compute_tls_ca_cert_root_ownership",
      "compute_tls_certificate_root_ownership",
      "compute_tls_ca_cert_file_root_owned"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/registry/insecure/ 2. https://docs.docker.com/engine/security/https/"
  },
  {
    "id": "3.10",
    "title": "Ensure that TLS CA certificate file permissions are set to 444 or more restrictively",
    "assessment": "Manual",
    "description": "You should verify that the TLS CA certificate file (the file that is passed along with the - -tlscacert parameter) has permissions of 444 or is set more restrictively.",
    "rationale": "The TLS CA certificate file should be protected from any tampering. It is used to authenticate the Docker server based on a given CA certificate. It must therefore have permissions of 444, or more restrictive permissions to ensure that the file cannot be modified by a less privileged user. Impact: None.",
    "audit": "You should execute the command below to verify that the TLS CA certificate file has permissions of 444 or that these are more restrictively set: stat -c %a <path to TLS CA certificate file>",
    "remediation": "You should execute the following command: chmod 444 <path to TLS CA certificate file> This sets the file permissions on the TLS CA file to 444. Default Value: By default, the permissions for the TLS CA certificate file might not be 444. The default file permissions are governed by the operating system or user specific umask values. References: 1. https://docs.docker.com/registry/insecure/ 2. https://docs.docker.com/engine/security/https/",
    "function_names": [
      "compute_tls_certificate_permissions_restrictive",
      "compute_tls_certificate_permissions_444_or_stricter",
      "compute_ca_certificate_file_permissions_restrictive",
      "compute_ca_certificate_file_permissions_444_or_stricter",
      "compute_tls_cacert_file_permissions_restrictive",
      "compute_tls_cacert_file_permissions_444_or_stricter"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/registry/insecure/ 2. https://docs.docker.com/engine/security/https/"
  },
  {
    "id": "3.11",
    "title": "Ensure that Docker server certificate file ownership is set to root:root",
    "assessment": "Manual",
    "description": "You should verify that the Docker server certificate file (the file that is passed along with the --tlscert parameter) is individual owned and group owned by root.",
    "rationale": "The Docker server certificate file should be protected from any tampering. It is used to authenticate the Docker server based on the given server certificate. It must therefore be individually owned and group owned by root to prevent modification by less privileged users. Impact: None.",
    "audit": "You should execute the command below to verify that the Docker server certificate file is individually owned and group owned by root: stat -c %U:%G <path to Docker server certificate file> | grep -v root:root The above command should return no results.",
    "remediation": "You should run the following command: chown root:root <path to Docker server certificate file> This sets the individual ownership and the group ownership for the Docker server certificate file to root. Default Value: By default, the ownership and group-ownership for Docker server certificate file is correctly set to root. References: 1. https://docs.docker.com/registry/insecure/ 2. https://docs.docker.com/engine/security/https/",
    "function_names": [
      "docker_certificate_file_root_owned",
      "docker_server_cert_root_ownership",
      "docker_tls_cert_file_root_ownership",
      "docker_cert_file_root_user_group",
      "docker_tls_cert_root_ownership",
      "docker_server_cert_file_root_owned"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/registry/insecure/ 2. https://docs.docker.com/engine/security/https/"
  },
  {
    "id": "3.12",
    "title": "Ensure that the Docker server certificate file permissions are set to 444 or more restrictively",
    "assessment": "Manual",
    "description": "You should verify that the Docker server certificate file (the file that is passed along with the --tlscert parameter) has permissions of 444 or more restrictive permissions.",
    "rationale": "The Docker server certificate file should be protected from any tampering. It is used to authenticate the Docker server based on the given server certificate. It should therefore have permissions of 444 to prevent its modification. Impact: None.",
    "audit": "You should execute the command below to verify that the Docker server certificate file has permissions of 444 or more restrictive permissions: stat -c %a <path to Docker server certificate file>",
    "remediation": "You should execute the command below: chmod 444 <path to Docker server certificate file> This sets the file permissions of the Docker server certificate file to 444. Default Value: By default, the permissions for the Docker server certificate file might not be 444. The default file permissions are governed by the operating system or user specific umask values. References: 1. https://docs.docker.com/registry/insecure/ 2. https://docs.docker.com/engine/security/https/",
    "function_names": [
      "docker_certificate_file_permissions_restricted",
      "docker_certificate_file_permissions_444_or_stricter",
      "docker_server_certificate_file_permissions_restricted",
      "docker_server_certificate_file_permissions_444_or_stricter",
      "docker_tls_certificate_file_permissions_restricted",
      "docker_tls_certificate_file_permissions_444_or_stricter"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/registry/insecure/ 2. https://docs.docker.com/engine/security/https/"
  },
  {
    "id": "3.13",
    "title": "Ensure that the Docker server certificate key file ownership is set to root:root",
    "assessment": "Manual",
    "description": "You should verify that the Docker server certificate key file (the file that is passed along with the --tlskey parameter) is individually owned and group owned by root.",
    "rationale": "The Docker server certificate key file should be protected from any tampering or unneeded reads/writes. As it holds the private key for the Docker server certificate, it must be individually owned and group owned by root to ensure that it cannot be accessed by less privileged users. Impact: None.",
    "audit": "You should execute the command below to verify that the Docker server certificate key file is individually owned and group owned by root: stat -c %U:%G <path to Docker server certificate key file> | grep -v root:root The command above should return no results.",
    "remediation": "You should execute the following command: chown root:root <path to Docker server certificate key file> This sets the individual ownership and group ownership for the Docker server certificate key file to root. Default Value: By default, the individual ownership and group ownership for the Docker server certificate key file is correctly set to root. References: 1. https://docs.docker.com/registry/insecure/ 2. https://docs.docker.com/engine/security/https/",
    "function_names": [
      "docker_certificate_key_file_owner_root",
      "docker_certificate_key_file_group_owner_root",
      "docker_tls_key_file_permissions_root_only",
      "docker_server_certificate_key_ownership_root",
      "docker_tls_key_ownership_root_root"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/registry/insecure/ 2. https://docs.docker.com/engine/security/https/"
  },
  {
    "id": "3.14",
    "title": "Ensure that the Docker server certificate key file permissions are set to 400",
    "assessment": "Manual",
    "description": "You should verify that the Docker server certificate key file (the file that is passed along with the --tlskey parameter) has permissions of 400.",
    "rationale": "The Docker server certificate key file should be protected from any tampering or unneeded reads. It holds the private key for the Docker server certificate. It must therefore have permissions of 400 to ensure that the certificate key file is not modified. Impact: None.",
    "audit": "You should execute the command below to verify that the Docker server certificate key file has permissions of 400: stat -c %a <path to Docker server certificate key file>",
    "remediation": "You should execute the following command: chmod 400 <path to Docker server certificate key file> This sets the Docker server certificate key file permissions to 400. Default Value: By default, the permissions for the Docker server certificate key file might not be 400. The default file permissions are governed by the operating system or user specific umask values. References: 1. https://docs.docker.com/registry/insecure/ 2. https://docs.docker.com/engine/security/https/",
    "function_names": [
      "docker_certificate_key_file_permissions_400",
      "docker_tls_key_file_permissions_restricted",
      "docker_server_certificate_key_file_permissions_secure",
      "docker_tlskey_file_permissions_400",
      "docker_certificate_key_file_permissions_read_only"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/registry/insecure/ 2. https://docs.docker.com/engine/security/https/"
  },
  {
    "id": "3.15",
    "title": "Ensure that the Docker socket file ownership is set to root:docker",
    "assessment": "Automated",
    "description": "You should verify that the Docker socket file is owned by root and group owned by docker.",
    "rationale": "The Docker daemon runs as root. The default Unix socket therefore must be owned by root. If any other user or process owns this socket, it might be possible for that non- privileged user or process to interact with the Docker daemon. Additionally, in this case a non-privileged user or process might be able to interact with containers which is neither a secure nor desired behavior. Additionally, the Docker installer creates a Unix group called docker. You can add users to this group, and in this case, those users would be able to read and write to the default Docker Unix socket. The membership of the docker group is tightly controlled by the system administrator. However, ff any other group owns this socket, then it might be possible for members of that group to interact with the Docker daemon. Such a group might not be as tightly controlled as the docker group. Again, this is not in line with good security practice. For these reason, the default Docker Unix socket file should be owned by root and group owned by docker to maintain the integrity of the socket file. Impact: None.",
    "audit": "You should execute the below command to verify that the Docker socket file is owned by root and group owned by docker: stat -c %U:%G /var/run/docker.sock | grep -v root:docker The command above should return no results.",
    "remediation": "You should execute the following command: chown root:docker /var/run/docker.sock This sets the ownership to root and group ownership to docker for the default Docker socket file. Default Value: By default, the ownership and group ownership for the Docker socket file is correctly set to root:docker. References: 1. https://docs.docker.com/engine/reference/commandline/dockerd/#daemon- socket-option 2. https://docs.docker.com/engine/reference/commandline/dockerd/#bind-docker-to- another-hostport-or-a-unix-socket",
    "function_names": [
      "docker_socket_file_root_owned",
      "docker_socket_file_docker_group_owned",
      "docker_socket_file_root_docker_owned"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/engine/reference/commandline/dockerd/#daemon- socket-option 2. https://docs.docker.com/engine/reference/commandline/dockerd/#bind-docker-to- another-hostport-or-a-unix-socket"
  },
  {
    "id": "3.16",
    "title": "Ensure that the Docker socket file permissions are set to 660 or more restrictively",
    "assessment": "Automated",
    "description": "You should verify that the Docker socket file has permissions of 660 or are configured more restrictively.",
    "rationale": "Only root and the members of the docker group should be allowed to read and write to the default Docker Unix socket. The Docker socket file should therefore have permissions of 660 or more restrictive permissions. Impact: None.",
    "audit": "You should execute the command below to verify that the Docker socket file has permissions of 660 or more restrictive permissions stat -c %a /var/run/docker.sock",
    "remediation": "You should execute the command below. chmod 660 /var/run/docker.sock This sets the file permissions of the Docker socket file to 660. Default Value: By default, the permissions for the Docker socket file is correctly set to 660. References: 1. https://docs.docker.com/engine/reference/commandline/dockerd/#daemon- socket-option 2. https://docs.docker.com/engine/reference/commandline/dockerd/#bind-docker-to- another-hostport-or-a-unix-socket",
    "function_names": [
      "docker_socket_file_permissions_restrictive",
      "docker_socket_file_permissions_660_or_stricter",
      "docker_socket_file_permissions_secure",
      "docker_socket_file_permissions_protected",
      "docker_socket_file_permissions_minimum_660"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/engine/reference/commandline/dockerd/#daemon- socket-option 2. https://docs.docker.com/engine/reference/commandline/dockerd/#bind-docker-to- another-hostport-or-a-unix-socket"
  },
  {
    "id": "3.17",
    "title": "Ensure that the daemon.json file ownership is set to root:root",
    "assessment": "Manual",
    "description": "You should verify that the daemon.json file individual ownership and group ownership is correctly set to root, if it is in use.",
    "rationale": "The daemon.json file contains sensitive parameters that could alter the behavior of the docker daemon. It should therefore be owned and group owned by root to ensure it can not be modified by less privileged users. Impact: None.",
    "audit": "You should execute the command below to verify that the file is owned and group owned by root: stat -c %U:%G /etc/docker/daemon.json | grep -v root:root The command above should not return any results or, if there is no daemon.json file present it will return: stat: cannot stat '/etc/docker/daemon.json': No such file or directory",
    "remediation": "If the daemon.json file is present, you should execute the command below: chown root:root /etc/docker/daemon.json This sets the ownership and group ownership for the file to root. Default Value: This file may not be present on the system, and in that case, this recommendation is not applicable. References: 1. https://docs.docker.com/engine/reference/commandline/dockerd/#daemon- configuration-file",
    "function_names": [
      "docker_daemon_file_root_ownership",
      "docker_daemon_file_root_group_ownership",
      "docker_daemon_file_root_ownership_set",
      "docker_daemon_file_root_group_set",
      "docker_daemon_json_root_ownership",
      "docker_daemon_json_root_group_ownership"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/engine/reference/commandline/dockerd/#daemon- configuration-file"
  },
  {
    "id": "3.18",
    "title": "Ensure that daemon.json file permissions are set to 644 or more restrictive",
    "assessment": "Manual",
    "description": "You should verify that if the daemon.json is present its file permissions are correctly set to 644 or more restrictively.",
    "rationale": "The daemon.json file contains sensitive parameters that may alter the behavior of the docker daemon. Therefore it should be writeable only by root to ensure it is not modified by less privileged users. Impact: None.",
    "audit": "You should execute the command below to verify that the file permissions are correctly set to 644 or more restrictively: stat -c %a /etc/docker/daemon.json If the command returns the result below, the file is not present and this check does not apply: stat: cannot stat '/etc/docker/daemon.json': No such file or directory",
    "remediation": "If the file is present, you should execute the command below: chmod 644 /etc/docker/daemon.json This sets the file permissions for this file to 644. Default Value: This file may not be present on the system, and in that case, this recommendation is not applicable. References: 1. https://docs.docker.com/engine/reference/commandline/dockerd/#daemon- configuration-file",
    "function_names": [
      "docker_daemon_file_permissions_restrictive",
      "docker_daemon_json_permissions_644_or_stricter",
      "container_daemon_config_file_permissions_secure",
      "docker_daemon_config_file_permissions_compliant",
      "container_daemon_json_file_permissions_restricted"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/engine/reference/commandline/dockerd/#daemon- configuration-file"
  },
  {
    "id": "3.19",
    "title": "Ensure that the /etc/default/docker file ownership is set to root:root",
    "assessment": "Manual",
    "description": "You should verify that the /etc/default/docker file ownership and group-ownership is correctly set to root.",
    "rationale": "The /etc/default/docker file contains sensitive parameters that may alter the behavior of the Docker daemon. It should therefore be individually owned and group owned by root to ensure that it cannot be modified by less privileged users. Impact: None.",
    "audit": "You should execute the command below to verify that the file is individually owned and group owned by root: stat -c %U:%G /etc/default/docker | grep -v root:root The command above should return no results.",
    "remediation": "You should execute the following command chown root:root /etc/default/docker This sets the ownership and group ownership of the file to root. Default Value: This file may not be present on the system, and in this case, this recommendation is not applicable. References: 1. https://docs.docker.com/engine/admin/configuring/",
    "function_names": [
      "docker_file_root_ownership",
      "docker_file_root_group_ownership",
      "docker_default_file_root_ownership",
      "docker_default_file_root_group_ownership",
      "docker_config_file_root_ownership",
      "docker_config_file_root_group_ownership"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/engine/admin/configuring/"
  },
  {
    "id": "3.20",
    "title": "Ensure that the /etc/default/docker file permissions are set to 644 or more restrictively",
    "assessment": "Manual",
    "description": "You should verify that the /etc/default/docker file permissions are correctly set to 644 or more restrictively.",
    "rationale": "The /etc/default/docker file contains sensitive parameters that may alter the behavior of the Docker daemon. It should therefore be writeable only by root in order to ensure that it is not modified by less privileged users. Impact: None.",
    "audit": "You should execute the command below to verify that the file permissions are correctly set to 644 or more restrictively: stat -c %a /etc/default/docker",
    "remediation": "You should execute the following command: chmod 644 /etc/default/docker This sets the file permissions for this file to 644. Default Value: This file may not be present on the system and in this case, this recommendation is not applicable. References: 1. https://docs.docker.com/engine/admin/configuring/",
    "function_names": [
      "docker_file_permissions_restrictive",
      "docker_default_file_permissions_secure",
      "docker_config_file_permissions_644",
      "docker_default_file_permissions_644_or_stricter"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/engine/admin/configuring/"
  },
  {
    "id": "3.21",
    "title": "Ensure that the /etc/sysconfig/docker file permissions are set to 644 or more restrictively",
    "assessment": "Manual",
    "description": "You should verify that the /etc/sysconfig/docker file permissions are correctly set to 644 or more restrictively.",
    "rationale": "The /etc/sysconfig/docker file contains sensitive parameters that may alter the behavior of the Docker daemon. It should therefore be writeable only by root in order to ensure that it is not modified by less privileged users. Impact: None.",
    "audit": "You should execute the command below to verify that the file permissions are correctly set to 644 or more restrictively: stat -c %a /etc/sysconfig/docker",
    "remediation": "You should execute the following command: chmod 644 /etc/sysconfig/docker This sets the file permissions for this file to 644. Default Value: This file may not be present on the system and in this case, this recommendation is not applicable. References: 1. https://docs.docker.com/engine/admin/configuring/",
    "function_names": [
      "compute_docker_config_file_permissions_restricted",
      "compute_docker_config_file_permissions_644_or_stricter",
      "compute_docker_config_file_permissions_secure",
      "compute_docker_config_file_permissions_compliant",
      "compute_docker_config_file_permissions_cis_benchmark"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/engine/admin/configuring/"
  },
  {
    "id": "3.22",
    "title": "Ensure that the /etc/sysconfig/docker file ownership is set to root:root",
    "assessment": "Manual",
    "description": "You should verify that the /etc/sysconfig/docker file individual ownership and group ownership is correctly set to root.",
    "rationale": "The /etc/sysconfig/docker file contains sensitive parameters that may alter the behavior of the Docker daemon. It should therefore be individually owned and group owned by root to ensure that it is not modified by less privileged users. Impact: None.",
    "audit": "You should execute the command below to verify that the file is indiviually owned and group owned by root: stat -c %U:%G /etc/sysconfig/docker | grep -v root:root The command above should return no results.",
    "remediation": "You should execute the following command: chown root:root /etc/sysconfig/docker This sets the ownership and group ownership for the file to root. Default Value: This file may not be present on the system, and in this case, this recommendation is not applicable. References: 1. https://docs.docker.com/engine/admin/configuring/",
    "function_names": [
      "compute_docker_config_root_ownership",
      "compute_docker_config_file_secure_ownership",
      "compute_docker_file_root_user_group",
      "compute_sysconfig_docker_root_ownership",
      "compute_docker_config_privileged_ownership"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/engine/admin/configuring/"
  },
  {
    "id": "3.23",
    "title": "Ensure that the Containerd socket file ownership is set to root:root",
    "assessment": "Automated",
    "description": "You should verify that the Containerd socket file is owned by root and group owned by root.",
    "rationale": "Containerd is an underlying component used by Docker to create and manage containers. It provides a socket file similar to the Docker socket, which must be protected from unauthorized access. If any other user or process owns this socket, it might be possible for that non-privileged user or process to interact with the Containerd daemon. Additionally, in this case a non-privileged user or process might be able to interact with containers which is neither a secure nor desired behavior. Unlike the Docker socket, there is usually no requirement for non-privileged users to connect to the socket, so the ownership should be root:root. Impact: None.",
    "audit": "You should execute the below command to verify that the Containerd socket file is owned by root and group owned by root: stat -c %U:%G /run/containerd/containerd.sock | grep -v root:root The command above should return no results.",
    "remediation": "You should execute the following command: chown root:root /run/containerd/containerd.sock This sets the ownership to root and group ownership to root for the default Containerd socket file. Default Value: By default, the ownership and group ownership for the Containerd socket file is correctly set to root:root.",
    "function_names": [
      "containerd_socket_file_owner_root",
      "containerd_socket_file_group_owner_root",
      "containerd_socket_file_ownership_root_root"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None."
  },
  {
    "id": "3.24",
    "title": "Ensure that the Containerd socket file permissions are set to 660 or more restrictively",
    "assessment": "Automated",
    "description": "You should verify that the Containerd socket file has permissions of 660 or are configured more restrictively.",
    "rationale": "Only root and the members of the root group should be allowed to read and write to the default Containerd Unix socket. The Containerd socket file should therefore have permissions of 660 or more restrictive permissions. Impact: None.",
    "audit": "You should execute the command below to verify that the Docker socket file has permissions of 660 or more restrictive permissions stat -c %a /run/containerd/containerd.sock",
    "remediation": "You should execute the command below. chmod 660 /run/containerd/containerd.sock This sets the file permissions of the Containerd socket file to 660. Default Value: By default, the permissions for the Containerd socket file is correctly set to 660.",
    "function_names": [
      "containerd_socket_file_permissions_restrictive",
      "containerd_socket_file_permissions_660_or_stricter",
      "containerd_socket_file_mode_restricted",
      "containerd_socket_file_permissions_secure",
      "containerd_socket_file_mode_660_or_lower"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None."
  },
  {
    "id": "4.1",
    "title": "Ensure that a user for the container has been created",
    "assessment": "Manual",
    "description": "Containers should run as a non-root user.",
    "rationale": "It is good practice to run the container as a non-root user, where possible. This can be done either via the USER directive in the Dockerfile or through gosu or similar where used as part of the CMD or ENTRYPOINT directives. Impact: Running as a non-root user can present challenges where you wish to bind mount volumes from the underlying host. In this case, care should be taken to ensure that the user running the contained process can read and write to the bound directory, according to their requirements.",
    "audit": "You should run the following command docker ps --quiet | xargs --max-args=1 -I{} docker exec {} cat /proc/1/status | grep '^Uid:' | awk '{print $3}' This should return the effective UID for each container and where it returns 0, it indicates that the container process is running as root. Note that some services may start as the root user and then starts all other related processes as an unprivileged user.",
    "remediation": "You should ensure that the Dockerfile for each container image contains the information below: USER <username or ID> In this case, the user name or ID refers to the user that was found in the container base image. If there is no specific user created in the container base image, then make use of the useradd command to add a specific user before the USER instruction in the Dockerfile. For example, add the below lines in the Dockerfile to create a user in the container: RUN useradd -d /home/username -m -s /bin/bash username USER username Note: If there are users in the image that are not needed, you should consider deleting them. After deleting those users, commit the image and then generate new instances of the containers. Alternatively, if it is not possible to set the USER directive in the Dockerfile, a script running as part of the CMD or ENTRYPOINT sections of the Dockerfile should be used to ensure that the container process switches to a non-root user. Default Value: By default, containers are run with root privileges and also run as the root user inside the container. References: 1. https://docs.docker.com/engine/reference/builder/#user 2. https://docs.docker.com/engine/reference/run/#user",
    "function_names": [
      "compute_container_non_root_user",
      "compute_container_user_created",
      "container_runtime_non_root_user",
      "container_runtime_user_configured",
      "container_user_non_root_configured",
      "container_user_non_privileged",
      "container_runtime_non_privileged_user",
      "container_user_min_privilege"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "Running as a non-root user can present challenges where you wish to bind mount volumes from the underlying host. In this case, care should be taken to ensure that the user running the contained process can read and write to the bound directory, according to their requirements.",
    "references": "1. https://docs.docker.com/engine/reference/builder/#user 2. https://docs.docker.com/engine/reference/run/#user"
  },
  {
    "id": "4.2",
    "title": "Ensure that containers use only trusted base images",
    "assessment": "Manual",
    "description": "You should ensure that container images you use are either written from scratch or are based on another established and trusted base image downloaded over a secure channel.",
    "rationale": "Official repositories contain Docker images curated and optimized by the Docker community or by their vendor. There is no guarantee that these images are safe and do not contain security vulnerabilities or malicious code. Caution should therefore be exercised when obtaining container images from Docker and third parties and running these images should be reviewed in line with organizational security policy. Impact: None.",
    "audit": "You should review what Docker images are present on the host by executing the command below: docker images This command lists all the container images that are currently available for use on the Docker host. You should then review the origin of each image and review its contents in line with your organization's security policy. You can use the command below to review the history of commits to the image. docker history <imageName>",
    "remediation": "The following procedures are useful for establishing trust for a specific image. \u2022 Configure and use Docker Content trust. \u2022 View the history of each Docker image to evaluate its risk, dependent on the sensitivity of the application you wish to deploy using it. \u2022 Scan Docker images for vulnerabilities at regular intervals. Default Value: Not Applicable. References: 1. https://docs.docker.com/engine/reference/commandline/pull/ 2. https://registry.hub.docker.com/ 3. https://access.redhat.com/blogs/766093/posts/1976473",
    "function_names": [
      "container_image_trusted_base",
      "container_image_secure_channel",
      "container_image_no_untrusted_base",
      "container_image_established_base",
      "container_image_scratch_or_trusted",
      "container_image_secure_download",
      "container_image_approved_base",
      "container_image_no_custom_base"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/engine/reference/commandline/pull/ 2. https://registry.hub.docker.com/ 3. https://access.redhat.com/blogs/766093/posts/1976473"
  },
  {
    "id": "4.3",
    "title": "Ensure that unnecessary packages are not installed in the container",
    "assessment": "Manual",
    "description": "Containers should have as small a footprint as possible, and should not contain unnecessary software packages which could increase their attack surface.",
    "rationale": "Unnecessary software should not be installed into containers, as doing so increases their attack surface. Only packages strictly necessary for the correct operation of the application being deployed should be installed. Impact: None.",
    "audit": "List all the running instances of containers by executing the command below: docker ps --quiet For each container instance, execute the relevant command for listing all installed packages, e.g.: docker exec $INSTANCE_ID rpm -qa The command above lists the packages installed. You should review the list and ensure that everything installed is actually required.",
    "remediation": "You should not install anything within the container that is not required. You should consider using a minimal base image rather than the standard Centos, Debian, or Red Hat images if you can. Some of the options available include BusyBox and Alpine. Not only can this trim your image size considerably, but there would also be fewer pieces of software which could contain vectors for attack. Default Value: Not Applicable. References: 1. https://docs.docker.com/develop/develop-images/baseimages/ 2. https://jpetazzo.github.io/2020/02/01/quest-minimal-docker-images-part-1/",
    "function_names": [
      "container_image_unnecessary_packages_removed",
      "container_image_minimal_footprint_enforced",
      "container_image_unused_software_absent",
      "container_image_attack_surface_reduced",
      "container_image_non_essential_packages_removed"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/develop/develop-images/baseimages/ 2. https://jpetazzo.github.io/2020/02/01/quest-minimal-docker-images-part-1/"
  },
  {
    "id": "4.4",
    "title": "Ensure images are scanned and rebuilt to include security patches",
    "assessment": "Manual",
    "description": "Images should be scanned frequently for any vulnerabilities. You should rebuild all images to include these patches and then instantiate new containers from them.",
    "rationale": "Vulnerabilities are loopholes or bugs that can be exploited by hackers or malicious users, and security patches are updates to resolve these vulnerabilities. Image vulnerability scanning tools can be use to find vulnerabilities in images and then check for available patches to mitigate these. Patches update the system to a more recent code base which does not contain these problems, and being on a supported version of the code base is very important, as vendors do not tend to supply patches for older versions which have gone out of support. Security patches should be evaluated before applying and patching should be implemented in line with the organization's IT Security Policy. Care should be taken with the results returned by vulnerability assessment tools, as some will simply return results based on software banners, and these may not be entirely accurate. Impact: None",
    "audit": "List all the running instances of containers by executing the command below: docker ps --quiet For each container instance, use the package manager within the container (assuming there is one available) to check for the availability of security patches. Alternatively, run image vulnerability assessment tools to scan all the images in your environment.",
    "remediation": "Images should be re-built ensuring that the latest version of the base images are used, to keep the operating system patch level at an appropriate level. Once the images have been re-built, containers should be re-started making use of the updated images. Default Value: By default, containers and images are not updated automatically to address missing operating system security patches. References: 1. https://docs.docker.com/engine/reference/builder/#onbuild",
    "function_names": [
      "compute_image_vulnerability_scanning_enabled",
      "compute_image_security_patches_applied",
      "compute_image_rebuild_after_scan",
      "compute_image_container_security_updated",
      "compute_image_scan_frequency_compliance",
      "compute_image_patch_rebuild_enforced",
      "compute_image_vulnerability_remediation_active",
      "compute_image_scan_rebuild_cycle_automated"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None",
    "references": "1. https://docs.docker.com/engine/reference/builder/#onbuild"
  },
  {
    "id": "4.5",
    "title": "Ensure Content trust for Docker is Enabled",
    "assessment": "Manual",
    "description": "Content trust is disabled by default and should be enabled in line with organizational security policy.",
    "rationale": "Content trust provides the ability to use digital signatures for data sent to and received from remote Docker registries. These signatures allow client-side verification of the identity and the publisher of specific image tags and ensures the provenance of container images. Impact: In an environment where DOCKER_CONTENT_TRUST is set, you are required to follow trust procedures whilst working with the image related commands - build, create, pull, push and run. You can use the --disable-content-trust flag to run individual operations on tagged images without content trust on an as needed basis, but this defeats the purpose of enabling content trust and therefore should be avoided wherever possible. Note: Content trust is currently only available for users of the public Docker Hub. It is currently not available for the Docker Trusted Registry or for private registries.",
    "audit": "You should execute the following command: echo $DOCKER_CONTENT_TRUST This should return a value of 1.",
    "remediation": "To enable content trust in a bash shell, you should enter the following command: export DOCKER_CONTENT_TRUST=1 Alternatively, you could set this environment variable in your profile file so that content trust in enabled on every login. Default Value: By default, content trust is disabled. References: 1. https://docs.docker.com/engine/security/trust/ 2. https://docs.docker.com/notary/service_architecture/ 3. https://docs.docker.com/engine/reference/commandline/cli/#environment- variables",
    "function_names": [
      "docker_image_content_trust_enabled",
      "docker_image_content_trust_required",
      "docker_image_content_trust_enforced",
      "docker_image_content_trust_configured",
      "docker_image_content_trust_active"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "In an environment where DOCKER_CONTENT_TRUST is set, you are required to follow trust procedures whilst working with the image related commands - build, create, pull, push and run. You can use the --disable-content-trust flag to run individual operations on tagged images without content trust on an as needed basis, but this defeats the purpose of enabling content trust and therefore should be avoided wherever possible. Note: Content trust is currently only available for users of the public Docker Hub. It is currently not available for the Docker Trusted Registry or for private registries.",
    "references": "1. https://docs.docker.com/engine/security/trust/ 2. https://docs.docker.com/notary/service_architecture/ 3. https://docs.docker.com/engine/reference/commandline/cli/#environment- variables"
  },
  {
    "id": "4.6",
    "title": "Ensure that HEALTHCHECK instructions have been added to container images",
    "assessment": "Manual",
    "description": "You should add the HEALTHCHECK instruction to your Docker container images in order to ensure that health checks are executed against running containers.",
    "rationale": "An important security control is that of availability. Adding the HEALTHCHECK instruction to your container image ensures that the Docker engine periodically checks the running container instances against that instruction to ensure that containers are still operational. Based on the results of the health check, the Docker engine could terminate containers which are not responding correctly, and instantiate new ones. Impact: None.",
    "audit": "You should run the command below to ensure that Docker images have the appropriate HEALTHCHECK instruction configured. docker inspect --format='{{ .Config.Healthcheck }}' <IMAGE>",
    "remediation": "You should follow the Docker documentation and rebuild your container images to include the HEALTHCHECK instruction. Default Value: By default, HEALTHCHECK is not set. References: 1. https://docs.docker.com/engine/reference/builder/#healthcheck",
    "function_names": [
      "container_image_healthcheck_instruction_added",
      "container_image_healthcheck_configured",
      "container_image_healthcheck_defined",
      "container_image_healthcheck_present",
      "container_image_healthcheck_required"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/engine/reference/builder/#healthcheck"
  },
  {
    "id": "4.7",
    "title": "Ensure update instructions are not used alone in Dockerfiles",
    "assessment": "Manual",
    "description": "You should not use OS package manager update instructions such as apt-get update or yum update either alone or in a single line in any Dockerfiles used to generate images under review.",
    "rationale": "Adding update instructions in a single line on the Dockerfile will cause the update layer to be cached. When you then build any image later using the same instruction, this will cause the previously cached update layer to be used, potentially preventing any fresh updates from being applied to later builds. Impact: None",
    "audit": "Step 1: Run the command below to get the list of images: docker images Step 2: Run the command below against each image in the list above, looking for any update instructions which are incorporated in a single line: docker history <Image_ID> Alternatively, if you have access to the Dockerfile for the image, you should verify that there are no update instructions configured as described above.",
    "remediation": "You should use update instructions together with install instructions and version pinning for packages while installing them. This will prevent caching and force the extraction of the required versions. Alternatively, you could use the --no-cache flag during the docker build process to avoid using cached layers. Default Value: By default, Docker does not enforce any restrictions on using update instructions. References: 1. https://docs.docker.com/develop/develop-images/dockerfile_best-practices/",
    "function_names": [
      "dockerfile_update_instructions_not_alone",
      "dockerfile_package_manager_update_secure",
      "dockerfile_os_update_instruction_compliance",
      "dockerfile_apt_get_update_restricted",
      "dockerfile_yum_update_restricted",
      "dockerfile_update_instruction_proper_usage",
      "dockerfile_package_update_multi_line",
      "dockerfile_update_instruction_not_standalone"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None",
    "references": "1. https://docs.docker.com/develop/develop-images/dockerfile_best-practices/"
  },
  {
    "id": "4.8",
    "title": "Ensure setuid and setgid permissions are removed",
    "assessment": "Manual",
    "description": "Removing setuid and setgid permissions in the images can prevent privilege escalation attacks within containers.",
    "rationale": "setuid and setgid permissions can be used for privilege escalation. Whilst these permissions can on occasion be legitimately needed, you should consider removing them from packages which do not need them. This should be reviewed for each image. Impact: The above command would break all executables that depend on setuid or setgid permissions including legitimate ones. You should therefore be careful to modify the command to suit your requirements so that it does not reduce the permissions of legitimate programs excessively. Because of this, you should exercise a degree of caution and examine all processes carefully before making this type of modification in order to avoid outages.",
    "audit": "You should run the command below against each image to list the executables which have either setuid or setgid permissions: docker export <IMAGE ID> | tar -tv 2>/dev/null | grep -E '^[- rwx].*(s|S).*\\s[0-9]' You should then review the list and ensure that all executables configured with these permissions actually require them.",
    "remediation": "You should allow setuid and setgid permissions only on executables which require them. You could remove these permissions at build time by adding the following command in your Dockerfile, preferably towards the end of the Dockerfile: RUN find / -perm /6000 -type f -exec chmod a-s {} \\; || true Default Value: Not Applicable References: 1. https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux- capabilities 2. http://man7.org/linux/man-pages/man2/setuid.2.html 3. http://man7.org/linux/man-pages/man2/setgid.2.html",
    "function_names": [
      "compute_image_setuid_removed",
      "compute_image_setgid_removed",
      "compute_image_privilege_escalation_protected",
      "compute_image_special_permissions_disabled",
      "compute_image_secure_permissions_enforced"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "The above command would break all executables that depend on setuid or setgid permissions including legitimate ones. You should therefore be careful to modify the command to suit your requirements so that it does not reduce the permissions of legitimate programs excessively. Because of this, you should exercise a degree of caution and examine all processes carefully before making this type of modification in order to avoid outages.",
    "references": "1. https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux- capabilities 2. http://man7.org/linux/man-pages/man2/setuid.2.html 3. http://man7.org/linux/man-pages/man2/setgid.2.html"
  },
  {
    "id": "4.9",
    "title": "Ensure that COPY is used instead of ADD in Dockerfiles",
    "assessment": "Manual",
    "description": "You should use the COPY instruction instead of the ADD instruction in the Dockerfile.",
    "rationale": "The COPY instruction simply copies files from the local host machine to the container file system. The ADD instruction could potentially retrieve files from remote URLs and perform operations such as unpacking them. The ADD instruction therefore introduces security risks. For example, malicious files may be directly accessed from URLs without scanning, or there may be vulnerabilities associated with decompressing them. Impact: Care needs to be taken in implementing this control if the application requires functionality that is part of the ADD instruction, for example, if you need to retrieve files from remote URLs.",
    "audit": "Run the command below to get the list of images: docker images Run the command below against each image in the list above and look for any ADD instructions: docker history <IMAGE ID> Alternatively, if you have access to the Dockerfile for the image, you should verify that there are no ADD instructions.",
    "remediation": "You should use COPY rather than ADD instructions in Dockerfiles. Default Value: Not Applicable References: 1. https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#add- or-copy",
    "function_names": [
      "dockerfile_copy_instead_of_add",
      "dockerfile_no_add_instruction",
      "dockerfile_copy_used",
      "dockerfile_add_avoided",
      "dockerfile_instruction_copy_only"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "Care needs to be taken in implementing this control if the application requires functionality that is part of the ADD instruction, for example, if you need to retrieve files from remote URLs.",
    "references": "1. https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#add- or-copy"
  },
  {
    "id": "4.10",
    "title": "Ensure secrets are not stored in Dockerfiles",
    "assessment": "Manual",
    "description": "Do not store any secrets in Dockerfiles.",
    "rationale": "Docker images are not opaque and contain information about the commands used to build them. As such secrets should not be included in Dockerfiles used to build images as they will be visible to any users of the image. Impact: A proper secrets management process will be required for Docker image building.",
    "audit": "Run the below command to get the list of images: docker images Run the below command for each image in the list above, and look for any secrets: docker history <IMAGE ID> Alternatively, if you have access to Dockerfile for the image, verify that there are no secrets as described above.",
    "remediation": "Do not store any kind of secrets within Dockerfiles. Where secrets are required during the build process, make use of a secrets management tool, such as the buildkit builder included with Docker. Default Value: By default, there are no restrictions on storing config secrets in the Dockerfiles. References: 1. https://docs.docker.com/develop/develop-images/build_enhancements/#new- docker-build-secret-information",
    "function_names": [
      "dockerfile_secrets_not_stored",
      "dockerfile_no_hardcoded_secrets",
      "dockerfile_secret_free",
      "dockerfile_no_sensitive_data",
      "dockerfile_secure_build_practices"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "A proper secrets management process will be required for Docker image building.",
    "references": "1. https://docs.docker.com/develop/develop-images/build_enhancements/#new- docker-build-secret-information"
  },
  {
    "id": "4.11",
    "title": "Ensure only verified packages are installed",
    "assessment": "Manual",
    "description": "You should verify the authenticity of packages before installing them into images.",
    "rationale": "Verifying authenticity of software packages is essential for building a secure container image. Packages with no known provenance could potentially be malicious or have vulnerabilities that could be exploited. Impact: None",
    "audit": "Run the command below to get the list of images: docker images Run the command below for each image in the list above, and check how the authenticity of the packages is being determined. This could be via the use of GPG keys or other secure package distribution mechanisms. docker history <IMAGE ID> Alternatively, if you have access to Dockerfile for the image, verify that the authenticity of the packages is checked.",
    "remediation": "You should use a secure package distribution mechanism of your choice to ensure the authenticity of software packages. Default Value: Not Applicable References: 1. https://www.redhat.com/sysadmin/rpm-gpg-verify-packages 2. https://help.ubuntu.com/community/SecureApt",
    "function_names": [
      "compute_image_verified_packages_installed",
      "compute_image_package_authentication_enabled",
      "compute_image_unverified_packages_absent",
      "compute_image_package_signature_validation_enabled",
      "compute_image_trusted_sources_only",
      "compute_image_package_integrity_verified",
      "compute_image_secure_package_repositories_enabled",
      "compute_image_package_verification_required"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "None",
    "references": "1. https://www.redhat.com/sysadmin/rpm-gpg-verify-packages 2. https://help.ubuntu.com/community/SecureApt"
  },
  {
    "id": "4.12",
    "title": "Ensure all signed artifacts are validated",
    "assessment": "Manual",
    "description": "Validate artifacts signatures before uploading to the package registry.",
    "rationale": "Cryptographic signature is a tool to verify artifact authenticity. Every artifact is supposed to be signed by its creator in order to verify that it wasn't compromised until it got to the client. Validating artifact signature before delivering it is another level of protection, which checks that the signature hasn't been changed, which means that no one tried or succeeded in tampering with the artifact. That sets trust between the supplier and the client.",
    "audit": "Ensure every artifact in the package has been validated with its signature.",
    "remediation": "Validate every artifact with its signature. It is recommended to do so automatically.",
    "function_names": [
      "package_registry_artifact_signature_validated",
      "package_registry_artifact_signature_verified_before_upload",
      "package_registry_upload_signature_validation_enabled",
      "package_registry_signed_artifact_validation_required",
      "package_registry_artifact_integrity_checked_before_upload"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux"
  },
  {
    "id": "5.1",
    "title": "Ensure swarm mode is not Enabled, if not needed",
    "assessment": "Manual",
    "description": "Do not enable swarm mode on a Docker engine instance unless this is needed.",
    "rationale": "By default, a Docker engine instance will not listen on any network ports, with all communications with the client coming over the Unix socket. When Docker swarm mode is enabled on a Docker engine instance, multiple network ports are opened on the system and made available to other systems on the network for the purposes of cluster management and node communications. Opening network ports on a system increases its attack surface and this should be avoided unless required. It should be noted that swarm mode is required for the operation of Docker Enterprise components. Impact: Disabling swarm mode will impact the operation of Docker Enterprise components if these are in use.",
    "audit": "Review the output of docker info --format '{{ .Swarm }}' If the output includes active true it indicates that swarm mode has been activated on the Docker engine. In this case, you should confirm if swarm mode on the Docker engine instance is actually needed.",
    "remediation": "If swarm mode has been enabled on a system in error, you should run the command below: docker swarm leave Default Value: By default, Docker swarm mode is not enabled. References: 1. https://docs.docker.com/engine/reference/commandline/swarm_leave/",
    "function_names": [
      "docker_engine_swarm_mode_disabled",
      "docker_engine_swarm_mode_unused_disabled",
      "docker_engine_unnecessary_swarm_mode_disabled",
      "docker_engine_swarm_mode_not_enabled",
      "docker_engine_swarm_mode_unrequired_disabled"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "Disabling swarm mode will impact the operation of Docker Enterprise components if these are in use.",
    "references": "1. https://docs.docker.com/engine/reference/commandline/swarm_leave/"
  },
  {
    "id": "5.2",
    "title": "Ensure that, if applicable, an AppArmor Profile is enabled",
    "assessment": "Manual",
    "description": "AppArmor is an effective and easy-to-use Linux application security system. It is available on some Linux distributions by default, for example, on Debian and Ubuntu.",
    "rationale": "AppArmor protects the Linux OS and applications from various threats by enforcing a security policy which is also known as an AppArmor profile. You can create your own AppArmor profile for containers or use Docker's default profile. Enabling this feature enforces security policies on containers as defined in the profile. Impact: The container will have the security controls defined in the AppArmor profile. It should be noted that if the AppArmor profile is misconfigured, this may cause issues with the operation of the container.",
    "audit": "You should run the command below: docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: AppArmorProfile={{ .AppArmorProfile }}' This command should return a valid AppArmor Profile for each container instance.",
    "remediation": "If AppArmor is applicable for your Linux OS, you should enable it. 1. Verify AppArmor is installed. 2. Create or import a AppArmor profile for Docker containers. 3. Enable enforcement of the policy. 4. Start your Docker container using the customized AppArmor profile. For example: docker run --interactive --tty --security-opt=\"apparmor:PROFILENAME\" ubuntu /bin/bash Alternatively, Docker's default AppArmor policy can be used. Default Value: By default, the docker-default AppArmor profile is applied to running containers. The Docker binary generates this profile and then loads it into the kernel. References: 1. https://docs.docker.com/engine/security/apparmor/ 2. https://docs.docker.com/engine/reference/run/#security-configuration 3. https://docs.docker.com/engine/security/#other-kernel-security-features",
    "function_names": [
      "linux_app_armor_profile_enabled",
      "linux_app_armor_profile_active",
      "linux_app_armor_profile_configured",
      "linux_app_armor_profile_applied",
      "linux_app_armor_profile_enforced"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "The container will have the security controls defined in the AppArmor profile. It should be noted that if the AppArmor profile is misconfigured, this may cause issues with the operation of the container.",
    "references": "1. https://docs.docker.com/engine/security/apparmor/ 2. https://docs.docker.com/engine/reference/run/#security-configuration 3. https://docs.docker.com/engine/security/#other-kernel-security-features"
  },
  {
    "id": "5.3",
    "title": "Ensure that, if applicable, SELinux security options are set",
    "assessment": "Manual",
    "description": "SELinux is an effective and easy-to-use Linux application security system. It is available by default on some distributions such as Red Hat and Fedora.",
    "rationale": "SELinux provides a Mandatory Access Control (MAC) system that greatly augments the default Discretionary Access Control (DAC) model. You can therefore add an extra layer of safety to your containers by enabling SELinux on your Linux host. Impact: Any restrictions defined in the SELinux policy will be applied to your containers. It should be noted that if your SELinux policy is misconfigured, this may have an impact on the correct operation of the affected containers.",
    "audit": "You should run the following command docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: SecurityOpt={{ .HostConfig.SecurityOpt }} MountLabel={{ .MountLabel }} ProcessLabel={{ .ProcessLabel }}' This command returns all the security options currently configured on the containers listed. Note that even if an empty SecurityOpt is returned, the MountLabel and ProcessLabel values will indicate if SELinux is in use.",
    "remediation": "If SELinux is applicable for your Linux OS, you should use it. 1. Set the SELinux State. 2. Set the SELinux Policy. 3. Create or import a SELinux policy template for Docker containers. 4. Start Docker in daemon mode with SELinux enabled. For example: docker daemon --selinux-enabled or by adding the following to the daemon.json configuration file: { \"selinux-enabled\": true }  5. Start your Docker container using the security options. For example, docker run --interactive --tty --security-opt label=level:TopSecret centos /bin/bash Default Value: By default, no SELinux security options are applied on containers. References: 1. https://docs.docker.com/engine/security/#other-kernel-security-features 2. https://docs.docker.com/engine/reference/run/#security-configuration 3. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux_atomic_host/7/html/container_security_guide/docker _selinux_security_policy",
    "function_names": [
      "linux_selinux_security_options_enabled",
      "linux_selinux_enforcing_mode_enabled",
      "linux_selinux_policy_configured",
      "linux_selinux_booleans_secure_settings",
      "linux_selinux_context_correctly_labeled",
      "linux_selinux_no_unconfined_processes",
      "linux_selinux_audit_logging_enabled",
      "linux_selinux_deny_ptrace_scope_enabled",
      "linux_selinux_no_direct_root_logins",
      "linux_selinux_no_unconfined_services"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "Any restrictions defined in the SELinux policy will be applied to your containers. It should be noted that if your SELinux policy is misconfigured, this may have an impact on the correct operation of the affected containers.",
    "references": "1. https://docs.docker.com/engine/security/#other-kernel-security-features 2. https://docs.docker.com/engine/reference/run/#security-configuration 3. https://access.redhat.com/documentation/en- us/red_hat_enterprise_linux_atomic_host/7/html/container_security_guide/docker _selinux_security_policy"
  },
  {
    "id": "5.4",
    "title": "Ensure that Linux kernel capabilities are restricted within containers",
    "assessment": "Manual",
    "description": "By default, Docker starts containers with a restricted set of Linux kernel capabilities. This means that any process can be granted the required capabilities instead of giving it root access. Using Linux kernel capabilities, processes in general do not need to run as the root user.",
    "rationale": "Docker supports the addition and removal of capabilities. You should remove all capabilities not required for the correct function of the container. Specifically, in the default capability set provided by Docker, the NET_RAW capability should be removed if not explicitly required, as it can give an attacker with access to a container the ability to create spoofed network traffic. Impact: Restrictions on processes within a container are based on which Linux capabilities are in force.",
    "audit": "You should run the following command: docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: CapAdd={{ .HostConfig.CapAdd }} CapDrop={{ .HostConfig.CapDrop }}' Verify that the added and deleted Linux kernel capabilities are in line with the ones needed by the container process in each container instance. Specifically, ensure that the NET_RAW capability is removed if not required.",
    "remediation": "You should execute the command below to add required capabilities: docker run --cap-add={\"Capability 1\",\"Capability 2\"} <Run arguments> <Container Image Name or ID> <Command> You should execute the command below to remove unneeded capabilities: docker run --cap-drop={\"Capability 1\",\"Capability 2\"} <Run arguments> <Container Image Name or ID> <Command> Alternatively, you could remove all the currently configured capabilities and then restore only the ones you specifically use: docker run --cap-drop=all --cap-add={\"Capability 1\",\"Capability 2\"} <Run arguments> <Container Image Name or ID> <Command> Note that some settings also can be configured using the --sysctl option, reducing the need for container capabilities even further. This includes unprivileged ICMP echo sockets without NET_RAW and allow opening any port less than 1024 without NET_BIND_SERVICE. Adding and removing capabilities are also possible when the docker service command is used: docker service create --cap-drop=all --cap-add={\"Capability 1\",\"Capability 2\"} <Run arguments> <Container Image Name or ID> <Command> Default Value: By default, the capabilities below are applied to containers: AUDIT_WRITE CHOWN DAC_OVERRIDE FOWNER FSETID KILL MKNOD NET_BIND_SERVICE NET_RAW SETFCAP SETGID SETPCAP SETUID SYS_CHROOT References: 1. https://docs.docker.com/engine/security/#linux-kernel-capabilities 2. https://docs.docker.com/compose/compose-file/compose-file-v3/#cap_add- cap_drop 3. https://docs.docker.com/engine/reference/commandline/service_create/#options 4. https://docs.docker.com/engine/reference/commandline/run/#configure- namespaced-kernel-parameters-sysctls-at-runtime",
    "function_names": [
      "container_kernel_capabilities_restricted",
      "container_kernel_capabilities_no_root_access",
      "container_kernel_capabilities_minimal_privileges",
      "container_kernel_capabilities_default_restricted",
      "container_kernel_capabilities_process_isolation",
      "container_kernel_capabilities_non_root_process",
      "container_kernel_capabilities_secure_defaults",
      "container_kernel_capabilities_limited_privileges"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "Restrictions on processes within a container are based on which Linux capabilities are in force.",
    "references": "1. https://docs.docker.com/engine/security/#linux-kernel-capabilities 2. https://docs.docker.com/compose/compose-file/compose-file-v3/#cap_add- cap_drop 3. https://docs.docker.com/engine/reference/commandline/service_create/#options 4. https://docs.docker.com/engine/reference/commandline/run/#configure- namespaced-kernel-parameters-sysctls-at-runtime"
  },
  {
    "id": "5.5",
    "title": "Ensure that privileged containers are not used",
    "assessment": "Manual",
    "description": "Using the --privileged flag provides all Linux kernel capabilities to the container to which it is applied and therefore overwrites the --cap-add and --cap-drop flags. For this reason you should ensure that it is not used.",
    "rationale": "The --privileged flag provides all capabilities to the container to which it is applied, and also lifts all the limitations enforced by the device cgroup controller. As a consequence this the container has most of the rights of the underlying host. This flag only exists to allow for specific use cases (for example running Docker within Docker) and should not generally be used. Impact: If you start a container without the --privileged flag, it will not have excessive default capabilities.",
    "audit": "You should run the command below: docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: Privileged={{ .HostConfig.Privileged }}' The above command should return Privileged=false for each container instance.",
    "remediation": "You should not run containers with the --privileged flag. For example, do not start a container using the command below: docker run --interactive --tty --privileged centos /bin/bash Default Value: False. References: 1. https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux- capabilities",
    "function_names": [
      "compute_container_no_privileged_flag",
      "compute_container_privileged_disabled",
      "container_runtime_privileged_restricted",
      "container_runtime_no_privileged_mode",
      "container_privileged_flag_disabled",
      "container_privileged_escalation_prevented",
      "container_runtime_privileged_denied",
      "container_security_privileged_prohibited"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "If you start a container without the --privileged flag, it will not have excessive default capabilities.",
    "references": "1. https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux- capabilities"
  },
  {
    "id": "5.6",
    "title": "Ensure sensitive host system directories are not mounted on containers",
    "assessment": "Manual",
    "description": "You should not allow sensitive host system directories such as those listed below to be mounted as container volumes, especially in read-write mode. / /boot /dev /etc /lib /lib64 /proc /sys /usr",
    "rationale": "If sensitive directories are mounted in read-write mode, it could be possible to make changes to files within them. This has obvious security implications and should be avoided. Impact: None.",
    "audit": "You should run the following command: docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: Volumes={{ .Mounts }}' This command returns a list of currently mapped directories and indicates whether they are mounted in read-write mode for each container instance.",
    "remediation": "You should not mount directories which are security sensitive on the host within containers, especially in read-write mode. Default Value: Docker defaults to using a read-write volume but you can also mount a directory read- only. By default, no sensitive host directories are mounted within containers. References: 1. https://docs.docker.com/storage/volumes/",
    "function_names": [
      "compute_container_sensitive_host_dirs_unmounted",
      "compute_container_host_dirs_restricted",
      "compute_container_volume_sensitive_paths_blocked",
      "compute_container_host_system_dirs_protected",
      "compute_container_privileged_paths_unmounted",
      "compute_container_volume_sensitive_mounts_disabled",
      "compute_container_host_dirs_read_only",
      "compute_container_system_dirs_unmounted"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/storage/volumes/"
  },
  {
    "id": "5.7",
    "title": "Ensure sshd is not run within containers",
    "assessment": "Manual",
    "description": "The SSH daemon should not be running within the container. You should SSH into the Docker host, and use docker exec to enter a container.",
    "rationale": "Running SSH within the container increases the complexity of security management by making it \u2022 Difficult to manage access policies and security compliance for SSH server \u2022 Difficult to manage keys and passwords across various containers \u2022 Difficult to manage security upgrades for SSH server It is possible to have shell access to a container without using SSH, the needlessly increasing the complexity of security management should be avoided. Impact: None.",
    "audit": "List all the running instances of containers by executing below command: docker ps --quiet For each container instance, execute the below command: docker exec <CONTAINER ID> ps -el Ensure that there is no process for SSH server.",
    "remediation": "Uninstall the SSH daemon from the container and use and use docker exec to enter a container on the remote host. docker exec --interactive --tty <CONTAINER ID> sh OR docker attach <CONTAINER ID> Default Value: By default, SSH server is not running inside the container. Only one process per container is allowed. References: 1. https://jpetazzo.github.io/2014/06/23/docker-ssh-considered-evil/",
    "function_names": [
      "compute_container_sshd_disabled",
      "container_sshd_not_running",
      "compute_container_no_sshd",
      "container_sshd_service_disabled",
      "compute_container_sshd_absent"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://jpetazzo.github.io/2014/06/23/docker-ssh-considered-evil/"
  },
  {
    "id": "5.8",
    "title": "Ensure privileged ports are not mapped within containers",
    "assessment": "Manual",
    "description": "The TCP/IP port numbers below 1024 are considered privileged ports. Normal users and processes are not allowed to use them for various security reasons. Docker does, however allow a container port to be mapped to a privileged port.",
    "rationale": "By default, if the user does not specifically declare a container port to host port mapping, Docker automatically and correctly maps the container port to one available in the 49153-65535 range on the host. Docker does, however, allow a container port to be mapped to a privileged port on the host if the user explicitly declares it. This is because containers are executed with NET_BIND_SERVICE Linux kernel capability which does not restrict privileged port mapping. The privileged ports receive and transmit various pieces of data which are security sensitive and allowing containers to use them is not in line with good security practice. Impact: None.",
    "audit": "You can list all running containers instances and their port mappings by executing the command below: docker ps --quiet | xargs docker inspect --format '{{ .Id }}: Ports={{ .NetworkSettings.Ports }}' You should then review the list and ensure that container ports are not mapped to host port numbers below 1024.",
    "remediation": "You should not map container ports to privileged host ports when starting a container. You should also, ensure that there is no such container to host privileged port mapping declarations in the Dockerfile. Default Value: By default, mapping a container port to a privileged port on the host is allowed. Note: There might be certain cases where you want to map privileged ports, because if you forbid it, then the corresponding application has to run outside of a container. For example: HTTP and HTTPS load balancers have to bind 80/tcp and 443/tcp respectively. Forbidding to map privileged ports effectively forbids from running those in a container, and mandates using an external load balancer. In such cases, those containers instances should be marked as exceptions for this recommendation. References: 1. https://docs.docker.com/network/",
    "function_names": [
      "container_port_no_privileged_mapping",
      "container_port_privileged_range_restricted",
      "container_port_below_1024_blocked",
      "container_port_privileged_ports_unmapped",
      "container_port_high_ports_only_allowed"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/network/"
  },
  {
    "id": "5.9",
    "title": "Ensure that only needed ports are open on the container",
    "assessment": "Manual",
    "description": "The dockerfile for a container image defines the ports which are opened by default on a container instance. The list of ports are relevant to the application you are running within the container and should only be open if they are needed.",
    "rationale": "A container can be run with only the ports defined in the Dockerfile for its image or can alternatively be arbitrarily passed run time parameters to open a list of ports. Additionally, in the course of time, the Dockerfile may undergo various changes and the list of exposed ports may or may not still be relevant to the application you are running within the container. Opening unneeded ports increases the attack surface of the container and the associated containerized application. Good security practice is to only open ports that are needed for the correct operation of the application. Impact: None.",
    "audit": "You should list all the running instances of containers and their associated port mappings by executing the command below: docker ps --quiet | xargs docker inspect --format '{{ .Id }}: Ports={{ .NetworkSettings.Ports }}' You should then review the list and ensure that all the ports mapped are in fact genuinely required by each container.",
    "remediation": "You should ensure that the Dockerfile for each container image only exposes needed ports. You can also completely ignore the list of ports defined in the Dockerfile by NOT using -P (UPPERCASE) or the --publish-all flag when starting the container. Instead, use the -p (lowercase) or --publish flag to explicitly define the ports that you need for a particular container instance. For example: docker run --interactive --tty --publish 5000 --publish 5001 --publish 5002 centos /bin/bash Default Value: By default, all the ports that are listed in the Dockerfile under the EXPOSE instruction for an image are opened when a container is run with the -P or --publish-all flags. References: 1. https://docs.docker.com/engine/userguide/networking/",
    "function_names": [
      "container_image_unneeded_ports_closed",
      "container_image_exposed_ports_minimized",
      "container_image_default_ports_restricted",
      "container_image_unused_ports_disabled",
      "container_image_open_ports_required_only"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/engine/userguide/networking/"
  },
  {
    "id": "5.10",
    "title": "Ensure that the host's network namespace is not shared",
    "assessment": "Manual",
    "description": "When the networking mode on a container is set to --net=host, the container is not placed inside a separate network stack. Effectively, applying this option instructs Docker to not containerize the container's networking. The consequence of this is that the container lives \"outside\" in the main Docker host and has full access to its network interfaces.",
    "rationale": "Selecting this option is potentially dangerous. It allows the container process to open reserved low numbered ports in the way that any other root process can. It also allows the container to access network services such as D-bus on the Docker host. A container process could potentially carry out undesired actions, such as shutting down the Docker host. This option should not be used unless there is a very specific reason for enabling it. Impact: None.",
    "audit": "You should use the command below: docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: NetworkMode={{ .HostConfig.NetworkMode }}' If this returns NetworkMode=host, it means that the --net=host option was passed when the container was started.",
    "remediation": "You should not pass the --net=host option when starting any container. Default Value: By default, containers connect to the Docker bridge when starting and do not run in the context of the host's network stack. References: 1. https://docs.docker.com/network/ 2. https://docs.docker.com/engine/reference/run/#network-settings",
    "function_names": [
      "compute_container_host_network_disabled",
      "container_host_network_namespace_isolated",
      "container_network_stack_separate",
      "container_host_network_mode_restricted",
      "container_network_isolation_enabled",
      "container_host_network_access_blocked",
      "container_network_namespace_protected",
      "container_network_mode_no_host_sharing"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/network/ 2. https://docs.docker.com/engine/reference/run/#network-settings"
  },
  {
    "id": "5.11",
    "title": "Ensure that the memory usage for containers is limited",
    "assessment": "Manual",
    "description": "By default, all containers on a Docker host share resources equally. By using the resource management capabilities of the Docker host, you can control the amount of memory that a container is able to use.",
    "rationale": "By default a container can use all of the memory on the host. You can use memory limit mechanisms to prevent a denial of service occurring where one container consumes all of the host\u2019s resources and other containers on the same host are therefore not able to function. Having no limit on memory usage can lead to issues where one container can easily make the whole system unstable and as a result unusable. Impact: If correct memory limits are not set on each container, one process can expand its usage and cause other containers to run out of resources.",
    "audit": "You should run the command below: docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: Memory={{ .HostConfig.Memory }}' If this command returns 0, it means that memory limits are not in place; if it returns a non-zero value, it means that they are in place.",
    "remediation": "You should run the container with only as much memory as it requires by using the -- memory argument. For example, you could run a container using the command below: docker run -d --memory 256m centos sleep 1000 In the example above, the container is started with a memory limit of 256 MB. Verify the memory settings by using the command below: docker inspect --format='{{ .Id }}: Memory={{.HostConfig.Memory}} KernelMemory={{.HostConfig.KernelMemory}} Swap={{.HostConfig.MemorySwap}}' <CONTAINER ID> Default Value: By default, all containers on a Docker host share their resources equally and no memory limits are enforced. References: 1. https://docs.docker.com/config/containers/resource_constraints/#limit-a- containers-access-to-memory 2. https://docs.docker.com/config/containers/runmetrics/",
    "function_names": [
      "compute_container_memory_limit_enabled",
      "compute_container_memory_usage_restricted",
      "compute_container_memory_quota_set",
      "compute_container_memory_constraints_applied",
      "compute_container_memory_allocation_limited"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "If correct memory limits are not set on each container, one process can expand its usage and cause other containers to run out of resources.",
    "references": "1. https://docs.docker.com/config/containers/resource_constraints/#limit-a- containers-access-to-memory 2. https://docs.docker.com/config/containers/runmetrics/"
  },
  {
    "id": "5.12",
    "title": "Ensure that CPU priority is set appropriately on containers",
    "assessment": "Manual",
    "description": "By default, all containers on a Docker host share resources equally. By using the resource management capabilities of the Docker host you can control the host CPU resources that a container may consume.",
    "rationale": "By default, CPU time is divided between containers equally. If you wish to control available CPU resources amongst container instances, you can use the CPU sharing feature. CPU sharing allows you to prioritize one container over others and prevents lower priority containers from absorbing CPU resources which may be required by other processes. This ensures that high priority containers are able to claim the CPU runtime they require. Impact: If you do not correctly assign CPU thresholds, the container process may run out of resources and become unresponsive. If CPU resources on the host are not constrainted, CPU shares do not place any restrictions on individual resources.",
    "audit": "You should run the following command. docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: CpuShares={{ .HostConfig.CpuShares }}' If the above command returns 0 or 1024, it means that CPU shares are not in place. If it returns a non-zero value other than 1024, it means that they are in place.",
    "remediation": "You should manage the CPU runtime between your containers dependent on their priority within your organization. To do so start the container using the --cpu-shares argument. For example, you could run a container as below: docker run -d --cpu-shares 512 centos sleep 1000 In the example above, the container is started with CPU shares of 50% of what other containers use. So if the other container has CPU shares of 80%, this container will have CPU shares of 40%. Every new container will have 1024 shares of CPU by default. However, this value is shown as 0 if you run the command mentioned in the audit section. If you set one container\u2019s CPU shares to 512 it will receive half of the CPU time compared to the other containers. So if you take 1024 as 100% you can then derive the number that you should set for respective CPU shares. For example, use 512 if you want to set it to 50% and 256 if you want to set it 25%. You can also view the current CPU shares in the file /sys/fs/cgroup/cpu/docker/<CONTAINER ID>/cpu.shares. Default Value: By default, all containers on a Docker host share their resources equally. No CPU shares are enforced. References: 1. https://docs.docker.com/config/containers/resource_constraints/#cpu 2. https://docs.docker.com/engine/reference/commandline/run/#options 3. https://docs.docker.com/engine/admin/runmetrics/",
    "function_names": [
      "compute_container_cpu_priority_set",
      "compute_container_cpu_shares_configured",
      "compute_container_cpu_quota_limited",
      "compute_container_cpu_reservation_defined",
      "compute_container_cpu_period_set",
      "compute_container_cpu_limits_enforced",
      "compute_container_cpu_resources_managed",
      "compute_container_cpu_allocation_optimized"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "If you do not correctly assign CPU thresholds, the container process may run out of resources and become unresponsive. If CPU resources on the host are not constrainted, CPU shares do not place any restrictions on individual resources.",
    "references": "1. https://docs.docker.com/config/containers/resource_constraints/#cpu 2. https://docs.docker.com/engine/reference/commandline/run/#options 3. https://docs.docker.com/engine/admin/runmetrics/"
  },
  {
    "id": "5.13",
    "title": "Ensure that the container's root filesystem is mounted as read only",
    "assessment": "Manual",
    "description": "The container's root filesystem should be treated as a 'golden image' by using Docker run's --read-only option. This prevents any writes to the container's root filesystem at container runtime and enforces the principle of immutable infrastructure.",
    "rationale": "Enabling this option forces containers at runtime to explicitly define their data writing strategy to persist or not persist their data. This also reduces security attack vectors since the container instance's filesystem cannot be tampered with or written to unless it has explicit read-write permissions on its filesystem folder and directories. Impact: Enabling --read-only at container runtime may break some container OS packages if a data writing strategy is not defined. You should define what the container's data should and should not persist at runtime in order to decide which strategy to use. Example: \u2022 Enable use --tmpfs for temporary file writes to /tmp \u2022 Use Docker shared data volumes for persistent data writes",
    "audit": "You should run the following command on the docker host: docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: ReadonlyRootfs={{ .HostConfig.ReadonlyRootfs }}' If the above command returns true, it means the container's root filesystem is mounted read-only. If the above command returns false, it means the container's root filesystem is writeable.",
    "remediation": "You should add a --read-only flag at a container's runtime to enforce the container's root filesystem being mounted as read only. docker run <Run arguments> --read-only <Container Image Name or ID> <Command> Enabling the --read-only option at a container's runtime should be used by administrators to force a container's executable processes to only write container data to explicit storage locations during its lifetime. Examples of explicit storage locations during a container's runtime include, but are not limited to: 1. Using the --tmpfs option to mount a temporary file system for non-persistent data writes. docker run --interactive --tty --read-only --tmpfs \"/run\" --tmpfs \"/tmp\" centos /bin/bash  2. Enabling Docker rw mounts at a container's runtime to persist container data directly on the Docker host filesystem. docker run --interactive --tty --read-only -v /opt/app/data:/run/app/data:rw centos /bin/bash  3. Utilizing the Docker shared-storage volume plugin for Docker data volume to persist container data. docker volume create -d convoy --opt o=size=20GB my-named-volume docker run --interactive --tty --read-only -v my-named-volume:/run/app/data centos /bin/bash  3. Transmitting container data outside of the Docker controlled area during the container's runtime for container data in order to ensure that it is persistent. Examples include hosted databases, network file shares and APIs. Default Value: By default, a container has its root filesystem writeable, allowing all container processes to write files owned by the container's actual runtime user. References: 1. https://docs.docker.com/storage/volumes/ 2. https://docs.docker.com/storage/volumes/#use-a-read-only-volume 3. https://docs.docker.com/engine/reference/commandline/run/#mount-tmpfs--- tmpfs",
    "function_names": [
      "container_root_filesystem_read_only",
      "container_filesystem_read_only_enabled",
      "container_runtime_root_filesystem_read_only",
      "container_root_filesystem_immutable",
      "container_root_filesystem_write_protected"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "Enabling --read-only at container runtime may break some container OS packages if a data writing strategy is not defined. You should define what the container's data should and should not persist at runtime in order to decide which strategy to use. Example: \u2022 Enable use --tmpfs for temporary file writes to /tmp \u2022 Use Docker shared data volumes for persistent data writes",
    "references": "1. https://docs.docker.com/storage/volumes/ 2. https://docs.docker.com/storage/volumes/#use-a-read-only-volume 3. https://docs.docker.com/engine/reference/commandline/run/#mount-tmpfs--- tmpfs"
  },
  {
    "id": "5.14",
    "title": "Ensure that incoming container traffic is bound to a specific host interface",
    "assessment": "Manual",
    "description": "By default, Docker containers can make connections to the outside world, but the outside world cannot connect to containers and each outgoing connection will appear to originate from one of the host machine's own IP addresses. You should only allow container services to be contacted through a specific external interface on the host machine.",
    "rationale": "If you have multiple network interfaces on your host machine, the container can accept connections on exposed ports on any network interface. This might not be desirable and may not be secured. In many cases a specific, desired interface is exposed externally and services such as intrusion detection, intrusion prevention, firewall, load balancing, etc. are all run by intention there to screen incoming public traffic. You should therefore not accept incoming connections on any random interface, but only the one designated for this type of traffic. Impact: None.",
    "audit": "You should list all running instances of containers and their port mappings by executing the command below: docker ps --quiet | xargs docker inspect --format '{{ .Id }}: Ports={{ .NetworkSettings.Ports }}' Then review the list and ensure that the exposed container ports are bound to a specific interface and not to the wildcard IP address 0.0.0.0. For example, if the command above returns the results below, this is non-compliant and the container can accept connections on any host interface on the specified port 49153. Ports=map[443/tcp:<nil> 80/tcp:[map[HostPort:49153 HostIp:0.0.0.0]]] However, if the exposed port is bound to a specific interface on the host as below, then this is configured in line with good security practice. Ports=map[443/tcp:<nil> 80/tcp:[map[HostIp:10.2.3.4 HostPort:49153]]]",
    "remediation": "You should bind the container port to a specific host interface on the desired host port. For example, docker run --detach --publish 10.2.3.4:49153:80 nginx In the example above, the container port 80 is bound to the host port on 49153 and would accept incoming connection only from the 10.2.3.4 external interface. Default Value: By default, Docker exposes the container ports on 0.0.0.0, the wildcard IP address that will match any possible incoming network interface on the host machine. References: 1. https://docs.docker.com/network/",
    "function_names": [
      "container_network_host_interface_bound",
      "container_network_incoming_traffic_restricted",
      "container_network_external_interface_specific",
      "container_network_host_binding_enabled",
      "container_network_interface_isolation_enforced",
      "container_network_inbound_traffic_limited",
      "container_network_host_interface_specific",
      "container_network_external_access_restricted"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/network/"
  },
  {
    "id": "5.15",
    "title": "Ensure that the 'on-failure' container restart policy is set to '5'",
    "assessment": "Manual",
    "description": "By using the --restart flag in the docker run command you can specify a restart policy for how a container should or should not be restarted on exit. You should choose the on-failure restart policy and limit the restart attempts to 5.",
    "rationale": "If you indefinitely keep trying to start the container, it could possibly lead to a denial of service on the host. It could be an easy way to do a distributed denial of service attack especially if you have many containers on the same host. Additionally, ignoring the exit status of the container and always attempting to restart the container, leads to non- investigation of the root cause behind containers getting terminated. If a container gets terminated, you should investigate on the reason behind it instead of just attempting to restart it indefinitely. You should use the on-failure restart policy to limit the number of container restarts to a maximum of 5 attempts. Impact: If this option is set, a container will only attempt to restart itself 5 times.",
    "audit": "You should use the command below docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: RestartPolicyName={{ .HostConfig.RestartPolicy.Name }} MaximumRetryCount={{ .HostConfig.RestartPolicy.MaximumRetryCount }}' If this command returns RestartPolicyName=always, then the system is not configured optimally. If the above command returns RestartPolicyName=no or just RestartPolicyName=, then restart policies are not being used and the container would never be restarted automatically. Whilst this may be a secure option, it is not the best option from a usability standpoint. If the above command returns RestartPolicyName=on-failure, then verify that the number of restart attempts is set to 5 or less by looking at MaximumRetryCount.",
    "remediation": "If you wish a container to be automatically restarted, a sample command is as below: docker run --detach --restart=on-failure:5 nginx Default Value: By default, containers are not configured with restart policies. References: 1. https://docs.docker.com/engine/reference/commandline/run/#restart-policies--- restart",
    "function_names": [
      "container_restart_policy_on_failure_max_5",
      "container_restart_policy_on_failure_limit_5",
      "container_restart_policy_failure_attempts_5",
      "container_restart_policy_failure_max_retries_5",
      "container_restart_policy_failure_retry_limit_5"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "If this option is set, a container will only attempt to restart itself 5 times.",
    "references": "1. https://docs.docker.com/engine/reference/commandline/run/#restart-policies--- restart"
  },
  {
    "id": "5.16",
    "title": "Ensure that the host's process namespace is not shared",
    "assessment": "Manual",
    "description": "The Process ID (PID) namespace isolates the process ID space, meaning that processes in different PID namespaces can have the same PID. This creates process level isolation between the containers and the host.",
    "rationale": "PID namespace provides separation between processes. It prevents system processes from being visible, and allows process ids to be reused including PID 1. If the host's PID namespace is shared with containers, it would basically allow these to see all of the processes on the host system. This reduces the benefit of process level isolation between the host and the containers. Under these circumstances a malicious user who has access to a container could get access to processes on the host itself, manipulate them, and even be able to kill them. This could allow for the host itself being shut down, which could be extremely serious, particularly in a multi-tenanted environment. You should not share the host's process namespace with the containers running on it. Impact: Container processes cannot see processes on the host system. In certain circumstances, you may want your container to share the host's process namespace. For example, you could build a container containing debugging tools such as strace or gdb, and want to use these tools when debugging processes on the host. If this is desired, then share specific host processes using the -p switch. For example: docker run --pid=host rhel7 strace -p 1234",
    "audit": "You should run the following command: docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: PidMode={{ .HostConfig.PidMode }}' If the command above returns host, it means that the host PID namespace is shared with its containers; any other result means that the system is configured in line with good security practice.",
    "remediation": "You should not start a container with the --pid=host argument. For example, do not start a container with the command below: docker run --interactive --tty --pid=host centos /bin/bash Default Value: By default, all containers have the PID namespace enabled and the therefore the host's process namespace is not shared with its containers. References: 1. https://docs.docker.com/engine/reference/run/#pid-settings---pid 2. https://man7.org/linux/man-pages/man7/pid_namespaces.7.html",
    "function_names": [
      "compute_container_pid_namespace_isolated",
      "compute_container_host_pid_sharing_disabled",
      "compute_container_process_isolation_enabled",
      "compute_container_pid_namespace_not_shared",
      "compute_container_host_process_namespace_separated"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "Container processes cannot see processes on the host system. In certain circumstances, you may want your container to share the host's process namespace. For example, you could build a container containing debugging tools such as strace or gdb, and want to use these tools when debugging processes on the host. If this is desired, then share specific host processes using the -p switch. For example: docker run --pid=host rhel7 strace -p 1234",
    "references": "1. https://docs.docker.com/engine/reference/run/#pid-settings---pid 2. https://man7.org/linux/man-pages/man7/pid_namespaces.7.html"
  },
  {
    "id": "5.17",
    "title": "Ensure that the host's IPC namespace is not shared",
    "assessment": "Manual",
    "description": "IPC (POSIX/SysV IPC) namespace provides separation of named shared memory segments, semaphores and message queues. The IPC namespace on the host should therefore not be shared with containers and should remain isolated.",
    "rationale": "The IPC namespace provides separation of IPC between the host and containers. If the host's IPC namespace is shared with the container, it would allow processes within the container to see all of IPC communications on the host system. This would remove the benefit of IPC level isolation between host and containers. An attacker with access to a container could get access to the host at this level with major consequences. The IPC namespace should therefore not be shared between the host and its containers. Impact: Shared memory segments are used in order to accelerate interprocess communications, commonly in high-performance applications. If this type of application is containerized into multiple containers, you might need to share the IPC namespace of the containers in order to achieve high performance. Under these circumstances, you should still only share container specific IPC namespaces and not the host IPC namespace. A container's IPC namespace can be shared with another container as shown below: docker run --interactive --tty --ipc=container:e3a7a1a97c58 centos /bin/bash",
    "audit": "You should run the following command: docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: IpcMode={{ .HostConfig.IpcMode }}' If the command returns host, it means that the host IPC namespace is shared with the container. Any other result means that it is not shared, and that the system is therefore configured in line with good security practice.",
    "remediation": "You should not start a container with the --ipc=host argument. For example, do not start a container as below: docker run --interactive --tty --ipc=host centos /bin/bash Default Value: By default, all containers have their IPC namespace enabled and host IPC namespace is not shared with any container. References: 1. https://docs.docker.com/engine/reference/run/#ipc-settings---ipc 2. https://www.man7.org/linux/man-pages/man7/ipc_namespaces.7.html",
    "function_names": [
      "compute_container_ipc_namespace_isolated",
      "compute_container_ipc_namespace_not_shared",
      "container_ipc_namespace_host_isolation_enabled",
      "container_ipc_namespace_sharing_disabled",
      "host_ipc_namespace_container_isolation_enabled"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "Shared memory segments are used in order to accelerate interprocess communications, commonly in high-performance applications. If this type of application is containerized into multiple containers, you might need to share the IPC namespace of the containers in order to achieve high performance. Under these circumstances, you should still only share container specific IPC namespaces and not the host IPC namespace. A container's IPC namespace can be shared with another container as shown below: docker run --interactive --tty --ipc=container:e3a7a1a97c58 centos /bin/bash",
    "references": "1. https://docs.docker.com/engine/reference/run/#ipc-settings---ipc 2. https://www.man7.org/linux/man-pages/man7/ipc_namespaces.7.html"
  },
  {
    "id": "5.18",
    "title": "Ensure that host devices are not directly exposed to containers",
    "assessment": "Manual",
    "description": "Host devices can be directly exposed to containers at runtime. Do not directly expose host devices to containers, especially to containers that are not trusted.",
    "rationale": "The --device option exposes host devices to containers and as a result of this, containers can directly access these devices. The the container would not need to run in privileged mode to access and manipulate them, as by default, the container is granted this type of access. Additionally, it would possible for containers to remove block devices from the host. You therefore should not expose host devices to containers directly. If for some reason you wish to expose the host device to a container you should consider which sharing permissions you wish to use on a case by case base as appropriate to your organization: \u2022 r - read only \u2022 w - writable \u2022 m - mknod allowed Impact: You would not be able to use host devices directly within containers.",
    "audit": "You should use the command below: docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: Devices={{ .HostConfig.Devices }}' The above command would list out each device with below information: \u2022 CgroupPermissions - For example, rwm \u2022 PathInContainer - Device path within the container \u2022 PathOnHost - Device path on the host You should verify that the host device is needed to be accessed from within the container and that the permissions required are correctly set. If the above command returns [], then the container does not have access to host devices and is configured in line with good security practice.",
    "remediation": "You should not directly expose host devices to containers. If you do need to expose host devices to containers, you should use granular permissions as appropriate to your organization: For example, do not start a container using the command below: docker run --interactive --tty --device=/dev/tty0:/dev/tty0:rwm -- device=/dev/temp_sda:/dev/temp_sda:rwm centos bash You should only share the host device using appropriate permissions: docker run --interactive --tty --device=/dev/tty0:/dev/tty0:rw -- device=/dev/temp_sda:/dev/temp_sda:r centos bash Default Value: By default, host devices are not exposed to containers. If you do not provide sharing permissions and choose to expose a host device to a container, the host device is be exposed with read, write and mknod permissions. References: 1. https://docs.docker.com/engine/reference/commandline/run/#add-host-device-to- container---device",
    "function_names": [
      "compute_container_host_device_exposure_disabled",
      "compute_container_host_device_access_restricted",
      "compute_container_untrusted_host_device_blocked",
      "compute_container_host_device_isolation_enabled",
      "compute_container_host_device_mapping_disabled"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "You would not be able to use host devices directly within containers.",
    "references": "1. https://docs.docker.com/engine/reference/commandline/run/#add-host-device-to- container---device"
  },
  {
    "id": "5.19",
    "title": "Ensure that the default ulimit is overwritten at runtime if needed",
    "assessment": "Manual",
    "description": "The default ulimit is set at the Docker daemon level. However, if you need to, you may override the default ulimit setting during container runtime.",
    "rationale": "ulimit provides control over the resources available to the shell and to processes started by it. Setting system resource limits in a prudent fashion, protects against denial of service conditions. On occasion, legitimate users and processes can accidentally overuse system resources and cause systems be degraded or even unresponsive. The default ulimit set at the Docker daemon level should be honored. If the default ulimit settings are not appropriate for a particular container instance, you may override them as an exception, but this should not be done routinely. If many of your container instances are exceeding your ulimit settings, you should consider changing the default settings to something that is more appropriate for your needs. Impact: If ulimits are not set correctly, overutilization by individual containers could make the host system unusable.",
    "audit": "You should run the command below: docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: Ulimits={{ .HostConfig.Ulimits }}' This command should return Ulimits=<no value> for each container instance unless there is a need in a specific case to override the default settings.",
    "remediation": "You should only override the default ulimit settings if needed in a specific case. For example, to override default ulimit settings start a container as below: docker run -ti -d --ulimit nofile=1024:1024 centos sleep 1000 Default Value: Container instances inherit the default ulimit settings set at the Docker daemon level. References: 1. https://docs.docker.com/engine/reference/commandline/run/#set-ulimits-in- container---ulimit",
    "function_names": [
      "compute_container_ulimit_overwritten",
      "compute_container_ulimit_customized",
      "compute_container_ulimit_configured",
      "compute_container_ulimit_override_enabled",
      "compute_container_ulimit_runtime_adjusted"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "If ulimits are not set correctly, overutilization by individual containers could make the host system unusable.",
    "references": "1. https://docs.docker.com/engine/reference/commandline/run/#set-ulimits-in- container---ulimit"
  },
  {
    "id": "5.20",
    "title": "Ensure mount propagation mode is not set to shared",
    "assessment": "Manual",
    "description": "Mount propagation mode allows mounting volumes in shared, slave or private mode on a container. Do not use shared mount propagation mode unless explicitly needed.",
    "rationale": "A shared mount is replicated at all mounts and changes made at any mount point are propagated to all other mount points. Mounting a volume in shared mode does not restrict any other container from mounting and making changes to that volume. As this is likely not a desirable option from a security standpoint, this feature should not be used unless explicitly required. Impact: None.",
    "audit": "docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: Propagation={{range $mnt := .Mounts}} {{json $mnt.Propagation}} {{end}}' The above command returns the propagation mode for mounted volumes. The propagation mode should not be set to shared unless needed. The above command might throw errors if there are no mounts. In that case, this recommendation is not applicable.",
    "remediation": "Do not mount volumes in shared mode propagation. For example, do not start a container as below: docker run <Run arguments> --volume=/hostPath:/containerPath:shared <Container Image Name or ID> <Command> Default Value: By default, the container mounts are private. References: 1. https://docs.docker.com/storage/bind-mounts/#configure-bind-propagation 2. https://docs.docker.com/engine/reference/run/#volume-shared-filesystems",
    "function_names": [
      "compute_container_no_shared_mount_propagation",
      "container_mount_propagation_private_or_slave",
      "container_mount_propagation_not_shared",
      "compute_container_mount_propagation_restricted",
      "container_mount_propagation_mode_secure"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/storage/bind-mounts/#configure-bind-propagation 2. https://docs.docker.com/engine/reference/run/#volume-shared-filesystems"
  },
  {
    "id": "5.21",
    "title": "Ensure that the host's UTS namespace is not shared",
    "assessment": "Manual",
    "description": "UTS namespaces provide isolation between two system identifiers: the hostname and the NIS domain name. It is used to set the hostname and the domain which are visible to running processes in that namespace. Processes running within containers do not typically require to know either the hostname or the domain name. The UTS namespace should therefore not be shared with the host.",
    "rationale": "Sharing the UTS namespace with the host provides full permission for each container to change the hostname of the host. This is not in line with good security practice and should not be permitted. Impact: None.",
    "audit": "You should run the following command: docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: UTSMode={{ .HostConfig.UTSMode }}' If the above command returns host, it means the host UTS namespace is shared with the container and this recommendation is non-compliant. If the above command returns nothing, then the host's UTS namespace is not shared. This recommendation is then compliant.",
    "remediation": "You should not start a container with the --uts=host argument. For example, do not start a container using the command below: docker run --rm --interactive --tty --uts=host rhel7.2 Default Value: By default, all containers have the UTS namespace enabled and the host UTS namespace is not shared with any containers. References: 1. https://docs.docker.com/engine/reference/run/#uts-settings---uts 2. https://www.man7.org/linux/man-pages/man7/uts_namespaces.7.html",
    "function_names": [
      "compute_container_uts_namespace_isolated",
      "compute_container_host_uts_namespace_not_shared",
      "container_runtime_uts_namespace_restricted",
      "container_hostname_isolation_enabled",
      "container_namespace_uts_isolation_required"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/engine/reference/run/#uts-settings---uts 2. https://www.man7.org/linux/man-pages/man7/uts_namespaces.7.html"
  },
  {
    "id": "5.22",
    "title": "Ensure the default seccomp profile is not Disabled",
    "assessment": "Manual",
    "description": "Seccomp filtering provides a means for a process to specify a filter for incoming system calls. The default Docker seccomp profile works on a whitelist basis and allows for a large number of common system calls, whilst blocking all others. This filtering should not be disabled unless it causes a problem with your container application usage.",
    "rationale": "A large number of system calls are exposed to every userland process with many of them going unused for the entire lifetime of the process. Most of applications do not need all these system calls and would therefore benefit from having a reduced set of available system calls. Having a reduced set of system calls reduces the total kernel surface exposed to the application and thus improvises application security. Impact: With Docker 1.10 and greater, the default seccomp profile blocks syscalls, regardless of --cap-add passed to the container. You should create your own custom seccomp profile in such cases. You may also disable the default seccomp profile by passing -- security-opt=seccomp:unconfined on docker run.",
    "audit": "You should run the following command: docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: SecurityOpt={{ .HostConfig.SecurityOpt }}' This should return either <no value> or your modified seccomp profile. If it returns [seccomp:unconfined], the container is running without any seccomp profiles and is therefore not configured in line with good security practice.",
    "remediation": "By default, seccomp profiles are enabled. You do not need to do anything unless you want to modify and use a modified seccomp profile. Default Value: When you run a container, it uses the default profile unless you override it with the -- security-opt option. References: 1. https://docs.docker.com/engine/reference/run/#security-configuration 2. https://github.com/moby/moby/blob/master/profiles/seccomp/default.json 3. https://docs.docker.com/engine/security/seccomp/ 4. https://www.kernel.org/doc/Documentation/prctl/seccomp_filter.txt",
    "function_names": [
      "container_runtime_seccomp_profile_enabled",
      "container_runtime_seccomp_profile_not_disabled",
      "container_runtime_default_seccomp_profile_active",
      "container_runtime_seccomp_filtering_enabled",
      "container_runtime_seccomp_whitelist_active"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "With Docker 1.10 and greater, the default seccomp profile blocks syscalls, regardless of --cap-add passed to the container. You should create your own custom seccomp profile in such cases. You may also disable the default seccomp profile by passing -- security-opt=seccomp:unconfined on docker run.",
    "references": "1. https://docs.docker.com/engine/reference/run/#security-configuration 2. https://github.com/moby/moby/blob/master/profiles/seccomp/default.json 3. https://docs.docker.com/engine/security/seccomp/ 4. https://www.kernel.org/doc/Documentation/prctl/seccomp_filter.txt"
  },
  {
    "id": "5.23",
    "title": "Ensure that docker exec commands are not used with the privileged option",
    "assessment": "Manual",
    "description": "You should not use docker exec with the --privileged option.",
    "rationale": "Using the --privileged option in docker exec commands gives extended Linux capabilities to the command. This could potentially be an insecure practice, particularly when you are running containers with reduced capabilities or with enhanced restrictions. Impact: If you need enhanced capabilities within a container, then run it with all the permissions it requires. These should be specified individually.",
    "audit": "If you have auditing enabled as recommended in Section 1, you can use the command below to filter out docker exec commands that use the --privileged option. ausearch -k docker | grep exec | grep privileged",
    "remediation": "You should not use the --privileged option in docker exec commands. Default Value: By default, the docker exec command runs without the --privileged option. References: 1. https://docs.docker.com/engine/reference/commandline/exec/ 2. https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux- capabilities",
    "function_names": [
      "container_exec_no_privileged_option",
      "docker_exec_privileged_disabled",
      "container_runtime_privileged_exec_restricted",
      "docker_exec_privileged_flag_denied",
      "container_exec_privileged_mode_blocked"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "If you need enhanced capabilities within a container, then run it with all the permissions it requires. These should be specified individually.",
    "references": "1. https://docs.docker.com/engine/reference/commandline/exec/ 2. https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux- capabilities"
  },
  {
    "id": "5.24",
    "title": "Ensure that docker exec commands are not used with the user=root option",
    "assessment": "Manual",
    "description": "You should not use docker exec with the --user=root option.",
    "rationale": "Using the --user=root option in a docker exec command, executes it within the container as the root user. This could potentially be insecure, particularly when you are running containers with reduced capabilities or enhanced restrictions. For example, if your container is running as a tomcat user (or any other non-root user), it would be possible to run a command through docker exec as root with the -- user=root option. This could potentially be dangerous. Impact: None.",
    "audit": "If you have auditing enabled as recommended in Section 1, you can use the command below to filter out docker exec commands that use the --user=root option. ausearch -k docker | grep exec | grep user",
    "remediation": "You should not use the --user=root option in docker exec commands. Default Value: By default, the docker exec command runs without the --user option. References: 1. https://docs.docker.com/engine/reference/commandline/exec/",
    "function_names": [
      "compute_container_no_root_exec",
      "compute_container_exec_user_restricted",
      "compute_container_exec_root_disabled",
      "compute_container_exec_non_root_only",
      "compute_container_exec_user_not_root"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/engine/reference/commandline/exec/"
  },
  {
    "id": "5.25",
    "title": "Ensure that cgroup usage is confirmed",
    "assessment": "Manual",
    "description": "It is possible to attach to a particular cgroup when a container is instantiated. Confirming cgroup usage would ensure that containers are running in defined cgroups.",
    "rationale": "System administrators typically define cgroups in which containers are supposed to run. If cgroups are not explicitly defined by the system administrator, containers run in the docker cgroup by default. At run time, it is possible to attach a container to a different cgroup other than the one originally defined. This usage should be monitored and confirmed, as by attaching to a different cgroup, excess permissions and resources might be granted to the container and this can therefore prove to be a security risk. Impact: None.",
    "audit": "You should run the following command: docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: CgroupParent={{ .HostConfig.CgroupParent }}' The above command returns the cgroup where the containers are running. If it is blank, it means that containers are running under the default docker cgroup. Any other return value indicates that the system is not configured in line with good security practice.",
    "remediation": "You should not use the --cgroup-parent option within the docker run command unless strictly required. Default Value: By default, containers run under docker cgroup. References: 1. https://docs.docker.com/engine/reference/run/#specify-custom-cgroups",
    "function_names": [
      "compute_container_cgroup_usage_confirmed",
      "compute_container_cgroup_attached",
      "compute_container_cgroup_defined",
      "compute_container_cgroup_verified",
      "compute_container_cgroup_enforced"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/engine/reference/run/#specify-custom-cgroups"
  },
  {
    "id": "5.26",
    "title": "Ensure that the container is restricted from acquiring additional privileges",
    "assessment": "Manual",
    "description": "You should restrict the container from acquiring additional privileges via suid or sgid bits.",
    "rationale": "A process can set the no_new_priv bit in the kernel and this persists across forks, clones and execve. The no_new_priv bit ensures that the process and its child processes do not gain any additional privileges via suid or sgid bits. This reduces the danger associated with many operations because the possibility of subverting privileged binaries is lessened. Impact: The no_new_priv option prevents LSMs like SELinux from allowing processes to acquire new privileges",
    "audit": "You should run the following command: docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: SecurityOpt={{ .HostConfig.SecurityOpt }}' This command should return all the security options currently configured for containers. no-new-privileges should be one of them. Note that the SecurityOpt response will be empty (i.e. SecurityOpt=<no value>) even if \"no-new-privileges\": true has been configured in the Docker daemon.json configuration file.",
    "remediation": "You should start your container with the options below: docker run --rm -it --security-opt=no-new-privileges ubuntu bash Default Value: By default, new privileges are not restricted. References: 1. https://docs.docker.com/engine/reference/run/#security-configuration 2. https://www.kernel.org/doc/Documentation/prctl/no_new_privs.txt",
    "function_names": [
      "container_security_privilege_escalation_restricted",
      "container_security_additional_privileges_blocked",
      "container_security_suid_sgid_disabled",
      "container_security_privilege_acquisition_restricted",
      "container_security_privilege_escalation_prevented"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "The no_new_priv option prevents LSMs like SELinux from allowing processes to acquire new privileges",
    "references": "1. https://docs.docker.com/engine/reference/run/#security-configuration 2. https://www.kernel.org/doc/Documentation/prctl/no_new_privs.txt"
  },
  {
    "id": "5.27",
    "title": "Ensure that container health is checked at runtime",
    "assessment": "Manual",
    "description": "If the container image does not have an HEALTHCHECK instruction defined, you should use the --health-cmd parameter at container runtime to check container health.",
    "rationale": "If the container image you are using does not have a pre-defined HEALTHCHECK instruction, use the --health-cmd parameter to check container health at runtime. Based on the reported health status, remedial actions can be taken if necessary. Impact: None.",
    "audit": "You should run the command below and ensure that all containers are reporting their health status: docker ps --quiet | xargs docker inspect --format '{{ .Id }}: Health={{ .State.Health.Status }}'",
    "remediation": "You should run the container using the --health-cmd parameter. For example: docker run -d --health-cmd='stat /etc/passwd || exit 1' nginx Default Value: By default, health checks are not carried out at container runtime. References: 1. https://docs.docker.com/engine/reference/run/#healthcheck",
    "function_names": [
      "container_image_healthcheck_defined",
      "container_runtime_health_cmd_configured",
      "container_health_runtime_monitoring_enabled",
      "container_healthcheck_instruction_present",
      "container_runtime_healthcheck_active"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None.",
    "references": "1. https://docs.docker.com/engine/reference/run/#healthcheck"
  },
  {
    "id": "5.28",
    "title": "Ensure that Docker commands always make use of the latest version of their image",
    "assessment": "Manual",
    "description": "You should always ensure that you are using the latest version of the images within your repository and not cached older versions.",
    "rationale": "Multiple Docker commands such as docker pull, docker run etc. are known to have an issue where by default, they extract the local copy of the image, if present, even though there is an updated version of the image with the same tag in the upstream repository. This could lead to using older images containing known vulnerabilites. Impact: None",
    "audit": "You should carry out the following steps: Step 1 : Open your image repository and list the image version history for the image you are inspecting. Step 2 : Observe the status when the docker pull command is triggered. If the status is shown as Image is up to date, it means that you are getting the cached version of the image. Step 3 : Match the version of the image you are running to the latest version reported in your repository and this will tell you whether you are running the cached version or the latest copy.",
    "remediation": "You should use proper version pinning mechanisms (the \"latest\" tag which is assigned by default is still vulnerable to caching attacks) to avoid extracting cached older versions. Version pinning mechanisms should be used for base images, packages, and entire images. You can customize version pinning rules according to your requirements. Default Value: By default, Docker commands extract the local copy unless version pinning mechanisms are used or the local cache is cleared. References: 1. https://docs.docker.com/engine/reference/commandline/pull/",
    "function_names": [
      "compute_container_image_latest_version_required",
      "compute_container_image_no_cached_versions",
      "compute_container_image_pull_policy_always",
      "compute_container_image_tag_latest",
      "compute_container_image_update_enabled"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None",
    "references": "1. https://docs.docker.com/engine/reference/commandline/pull/"
  },
  {
    "id": "5.29",
    "title": "Ensure that the PIDs cgroup limit is used",
    "assessment": "Manual",
    "description": "You should use the --pids-limit flag at container runtime.",
    "rationale": "Attackers could launch a fork bomb with a single command inside the container. This fork bomb could crash the entire system and would require a restart of the host to make the system functional again. Using the PIDs cgroup parameter --pids-limit would prevent this kind of attack by restricting the number of forks that can happen inside a container within a specified time frame. Impact: Set the PIDs limit value as appropriate. Incorrect values might leave containers unusable.",
    "audit": "You should run the command below and ensure that PidsLimit is not set to 0 or -1. A PidsLimit of 0 or -1 means that any number of processes can be forked concurrently inside the container. docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: PidsLimit={{ .HostConfig.PidsLimit }}'",
    "remediation": "Use --pids-limit flag with an appropriate value when launching the container. For example: docker run -it --pids-limit 100 <Image ID> In the above example, the number of processes allowed to run at any given time is set to 100. After a limit of 100 concurrently running processes is reached, Docker would restrict any new process creation. Default Value: The Default value for --pids-limit is 0 which means there is no restriction on the number of forks. Note that the PIDs cgroup limit works only for kernel versions 4.3 and higher. References: 1. https://docs.docker.com/engine/reference/commandline/run/",
    "function_names": [
      "compute_container_pids_limit_enabled",
      "compute_container_pids_limit_configured",
      "compute_container_pids_limit_enforced",
      "compute_container_runtime_pids_limit_set",
      "compute_container_runtime_pids_limit_used"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "Set the PIDs limit value as appropriate. Incorrect values might leave containers unusable.",
    "references": "1. https://docs.docker.com/engine/reference/commandline/run/"
  },
  {
    "id": "5.30",
    "title": "Ensure that Docker's default bridge \"docker0\" is not used",
    "assessment": "Manual",
    "description": "You should not use Docker's default bridge docker0. Instead you should use Docker's user-defined networks for container networking.",
    "rationale": "Docker connects virtual interfaces created in bridge mode to a common bridge called docker0. This default networking model is vulnerable to ARP spoofing and MAC flooding attacks as there is no filtering applied to it. Impact: User-defined networks need to be configured and managed in line with organizational security policy.",
    "audit": "You should run the command below, and verify that containers are on a user-defined network and not the default docker0 bridge. docker network ls --quiet | xargs docker network inspect --format '{{ .Name }}: {{ .Options }}'",
    "remediation": "You should follow the Docker documentation and set up a user-defined network. All the containers should be run in this network. Default Value: By default, Docker runs containers within the default docker0 bridge. References: 1. https://docs.docker.com/network/bridge/",
    "function_names": [
      "compute_container_default_bridge_unused",
      "compute_container_user_defined_network_used",
      "compute_container_docker0_disabled",
      "compute_container_network_non_default_bridge",
      "compute_container_bridge_custom_network_required"
    ],
    "profile_applicability": "\u2022  Level 2 - Docker - Linux",
    "impact": "User-defined networks need to be configured and managed in line with organizational security policy.",
    "references": "1. https://docs.docker.com/network/bridge/"
  },
  {
    "id": "5.31",
    "title": "Ensure that the host's user namespaces are not shared",
    "assessment": "Manual",
    "description": "You should not share the host's user namespaces with containers running on it.",
    "rationale": "User namespaces ensure that a root process inside the container will be mapped to a non-root process outside the container. Sharing the user namespaces of the host with the container does not therefore isolate users on the host from users in the containers. Impact: None",
    "audit": "You should run the command below and ensure that it does not return any value for UsernsMode. If it returns a value of host, it means that the host user namespace is shared with its containers. docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: UsernsMode={{ .HostConfig.UsernsMode }}'",
    "remediation": "You should not share user namespaces between host and containers. For example, you should not run the command below: docker run --rm -it --userns=host ubuntu bash Default Value: By default, the host user namespace is shared with containers unless user namespace support is enabled. References: 1. https://docs.docker.com/engine/security/userns-remap/ 2. https://docs.docker.com/engine/reference/commandline/run/#options",
    "function_names": [
      "compute_container_user_namespace_not_shared",
      "compute_container_host_namespace_isolated",
      "compute_container_user_namespace_restricted",
      "compute_container_namespace_sharing_disabled",
      "compute_container_host_namespace_protected"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None",
    "references": "1. https://docs.docker.com/engine/security/userns-remap/ 2. https://docs.docker.com/engine/reference/commandline/run/#options"
  },
  {
    "id": "5.32",
    "title": "Ensure that the Docker socket is not mounted inside any containers",
    "assessment": "Manual",
    "description": "The Docker socket docker.sock should not be mounted inside a container.",
    "rationale": "If the Docker socket is mounted inside a container it could allow processes running within the container to execute Docker commands which would effectively allow for full control of the host. Impact: None",
    "audit": "You should run the following command: docker ps --quiet --all | xargs docker inspect --format '{{ .Id }}: Volumes={{ .Mounts }}' | grep docker.sock This would return any instances where docker.sock had been mapped to a container as a volume.",
    "remediation": "You should ensure that no containers mount docker.sock as a volume. Default Value: By default, docker.sock is not mounted inside containers. References: 1. https://docs.docker.com/engine/reference/commandline/dockerd/#daemon- socket-option",
    "function_names": [
      "compute_container_no_docker_socket_mounted",
      "container_runtime_no_socket_mount",
      "compute_container_docker_socket_unmounted",
      "container_no_host_socket_mount",
      "compute_container_host_socket_protected"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "None",
    "references": "1. https://docs.docker.com/engine/reference/commandline/dockerd/#daemon- socket-option"
  },
  {
    "id": "6.1",
    "title": "Ensure that image sprawl is avoided",
    "assessment": "Manual",
    "description": "You should not keep a large number of container images on the same host. Use only tagged images as appropriate.",
    "rationale": "Tagged images are useful if you need to fall back from the \"latest\" version to a specific version of an image in production. Images with unused or old tags may contain vulnerabilities that might be exploited if instantiated. Impact: docker system prune -a removes all exited containers as well as all images and volumes that are not referenced by running containers. If any images are removed, this would result in needing to reload the images to the host.",
    "audit": "Step 1 Make a list of all image IDs that are currently instantiated by executing the command below: docker images --quiet | xargs docker inspect --format '{{ .Id }}: Image={{ .Config.Image }}' Step 2 : List all the images present on the system by executing the command below: docker images Step 3 : Compare the list of image IDs from Step 1 and Step 2 and look for images that are currently not in use. If any unused or old images are found, discuss with the system administrator the need to keep such images on the system. If images are no longer needed they should be deleted.",
    "remediation": "You should keep only the images that you actually need and establish a workflow to remove old or stale images from the host. Additionally, you should use features such as pull-by-digest to get specific images from the registry. You can follow the steps below to find unused images on the system so they can be deleted. Step 1 Make a list of all image IDs that are currently instantiated by executing the command below: docker images --quiet | xargs docker inspect --format '{{ .Id }}: Image={{ .Config.Image }}' Step 2 : List all the images present on the system by executing the command below: docker images Step 3 : Compare the list of image IDs created from Step 1 and Step 2 to find out images which are currently not being instantiated. Step 4 : Decide if you want to keep the images that are not currently in use. If they are not needed, delete them by executing the following command: docker rmi <IMAGE ID> Alternatively, the docker system prune command can be used to remove dangling images which are not tagged or, if necessary, all images that are not currently used by a running container when used with the -a option. Default Value: Images and layered filesystems remain accessible on the host until the administrator removes all tags that refer to those images or layers. References: 1. https://docs.docker.com/config/pruning/ 2. https://docs.docker.com/engine/reference/commandline/rmi/ 3. https://docs.docker.com/engine/reference/commandline/pull/",
    "function_names": [
      "compute_image_sprawl_avoided",
      "compute_image_tagged_only",
      "compute_image_count_limit",
      "compute_image_untagged_removed",
      "compute_image_cleanup_enabled",
      "compute_image_retention_policy_set",
      "compute_image_orphaned_removed",
      "compute_image_version_limit",
      "compute_image_rotation_enabled",
      "compute_image_storage_optimized"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "docker system prune -a removes all exited containers as well as all images and volumes that are not referenced by running containers. If any images are removed, this would result in needing to reload the images to the host.",
    "references": "1. https://docs.docker.com/config/pruning/ 2. https://docs.docker.com/engine/reference/commandline/rmi/ 3. https://docs.docker.com/engine/reference/commandline/pull/"
  },
  {
    "id": "6.2",
    "title": "Ensure that container sprawl is avoided",
    "assessment": "Manual",
    "description": "You should not keep a large number of containers on the same host.",
    "rationale": "The flexibility of containers makes it easy to run multiple instances of applications and therefore indirectly leads to Docker images that can exist at varying security patch levels. It also means that you are consuming host resources that otherwise could have been used for running 'useful' containers. Having more than just an essential number of containers on a particular host makes the system vulnerable to mishandling, misconfiguration and fragmentation. You should therefore keep the number of containers on a given host to the minimum number commensurate with serving production applications. Impact: You should retain containers that are actively in use, and delete ones which are no longer needed.",
    "audit": "Step 1 - Find the total number of containers you have on the host: docker info --format '{{ .Containers }}' Step 2 - Execute the commands below to find the total number of containers that are actually running or in the stopped state on the host. docker info --format '{{ .ContainersStopped }}' docker info --format '{{ .ContainersRunning }}' If the difference between the number of containers that are stopped on the host and the number of containers that are actually running is excessive, you may be suffering from \"Container sprawl\" and should review the unused containers for potential deletion.",
    "remediation": "You should periodically check your container inventory on each host and clean up containers which are not in active use with the command below: docker container prune Default Value: By default, Docker does not restrict the number of containers you may have on a host. References: 1. https://docs.docker.com/config/pruning/#prune-containers",
    "profile_applicability": "\u2022  Level 1 - Docker - Linux",
    "impact": "You should retain containers that are actively in use, and delete ones which are no longer needed.",
    "references": "1. https://docs.docker.com/config/pruning/#prune-containers"
  },
  {
    "id": "7.1",
    "title": "Ensure that the minimum number of manager nodes have been created in a swarm",
    "assessment": "Manual",
    "description": "You should ensure that the minimum number of required manager nodes is created in a swarm.",
    "rationale": "Manager nodes within a swarm have control over the swarm and can change its configuration, including modifying security parameters. Having excessive manager nodes could render the swarm more susceptible to compromise. If fault tolerance is not required in the manager nodes, a single node should be elected as a manger. If fault tolerance is required then the smallest odd number to achieve the appropriate level of tolerance should be configured. This should always be an odd number in order to ensure that a quorum is reached. Impact: None",
    "audit": "Run docker info and verify the number of managers. docker info --format '{{ .Swarm.Managers }}' Alternatively run the below command. docker node ls | grep 'Leader'",
    "remediation": "If an excessive number of managers is configured, the excess nodes can be demoted to workers using the following command: docker node demote <ID> Where <ID> is the node ID value of the manager to be demoted. Default Value: Only a single manager is required to start a given cluster. References: 1. https://docs.docker.com/engine/swarm/manage-nodes/ 2. https://docs.docker.com/engine/swarm/admin_guide/#add-manager-nodes-for- fault-tolerance",
    "function_names": [
      "swarm_manager_nodes_min_count",
      "swarm_manager_nodes_sufficient_count",
      "swarm_manager_nodes_quorum_configured",
      "swarm_manager_nodes_high_availability",
      "swarm_manager_nodes_recommended_count"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker Swarm",
    "impact": "None",
    "references": "1. https://docs.docker.com/engine/swarm/manage-nodes/ 2. https://docs.docker.com/engine/swarm/admin_guide/#add-manager-nodes-for- fault-tolerance"
  },
  {
    "id": "7.2",
    "title": "Ensure that swarm services are bound to a specific host interface",
    "assessment": "Manual",
    "description": "By default, Docker swarm services will listen on all interfaces on the host. This may not be necessary for the operation of the swarm where the host has multiple network interfaces.",
    "rationale": "When a swarm is initialized the default value for the --listen-addr flag is 0.0.0.0:2377 which means that swarm services will listen on all interfaces on the host. If a host has multiple network interfaces this may be undesirable as it could expose swarm services to networks which are not involved with the operation of the swarm. By passing a specific IP address to the --listen-addr, a specific network interface can be specified, limiting this exposure. Impact: None",
    "audit": "You should check the network listener on port 2377 (the default for docker swarm) and 7946 (container network discovery), and confirm that it is only listening on specific interfaces. For example, in this could be done using the following command: ss -lp | grep -iE ':2377|:7946'",
    "remediation": "Resolving this issues requires re-initialization of the swarm, specifying a specific interface for the --listen-addr parameter. Default Value: By default, Docker swarm services listen on all available host interfaces. References: 1. https://docs.docker.com/engine/reference/commandline/swarm_init/#--listen-addr 2. https://docs.docker.com/engine/swarm/admin_guide/#recover-from-disaster",
    "function_names": [
      "swarm_service_host_interface_bound",
      "swarm_service_specific_interface_required",
      "swarm_service_no_all_interfaces",
      "swarm_service_interface_restricted",
      "swarm_service_network_interface_bound"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker Swarm",
    "impact": "None",
    "references": "1. https://docs.docker.com/engine/reference/commandline/swarm_init/#--listen-addr 2. https://docs.docker.com/engine/swarm/admin_guide/#recover-from-disaster"
  },
  {
    "id": "7.3",
    "title": "Ensure that all Docker swarm overlay networks are encrypted",
    "assessment": "Manual",
    "description": "Ensure that all Docker swarm overlay networks are encrypted.",
    "rationale": "By default, data exchanged between containers on nodes on the overlay network is not encrypted. This could potentially expose traffic between containers. Impact: None",
    "audit": "You should run the command below to ensure that each overlay network has been encrypted. docker network ls --filter driver=overlay --quiet | xargs docker network inspect --format '{{.Name}} {{ .Options }}'",
    "remediation": "You should create overlay networks the with --opt encrypted flag. Default Value: By default, data exchanged in overlay networks in Docker swarm mode is not encrypted. References: 1. https://docs.docker.com/network/overlay/#encrypt-traffic-on-an-overlay-network",
    "function_names": [
      "docker_swarm_overlay_network_encryption_enabled",
      "docker_swarm_network_encryption_enabled",
      "docker_overlay_network_encryption_enabled",
      "docker_network_encryption_enabled",
      "swarm_overlay_network_encryption_enabled"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker Swarm",
    "impact": "None",
    "references": "1. https://docs.docker.com/network/overlay/#encrypt-traffic-on-an-overlay-network"
  },
  {
    "id": "7.4",
    "title": "Ensure that Docker's secret management commands are used for managing secrets in a swarm cluster",
    "assessment": "Manual",
    "description": "You should use Docker's in-built secret management command for control of secrets.",
    "rationale": "Docker has various commands for managing secrets in a swarm cluster. Impact: None",
    "audit": "On a swarm manager node, you should run the command below and ensure docker secret management is used in your environment where this is in line with your IT security policy. docker secret ls",
    "remediation": "You should follow the docker secret documentation and use it to manage secrets effectively. Default Value: Not Applicable References: 1. https://docs.docker.com/engine/reference/commandline/secret/",
    "function_names": [
      "docker_swarm_secret_management_enabled",
      "docker_swarm_secret_management_used",
      "docker_secret_management_commands_used",
      "docker_swarm_secret_management_required",
      "docker_secret_management_compliance_enforced"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker Swarm",
    "impact": "None",
    "references": "1. https://docs.docker.com/engine/reference/commandline/secret/"
  },
  {
    "id": "7.5",
    "title": "Ensure that swarm manager is run in auto-lock mode",
    "assessment": "Manual",
    "description": "You should review whether you wish to run Docker swarm manager in auto-lock mode.",
    "rationale": "When Docker restarts, both the TLS key used to encrypt communication among swarm nodes, and the key used to encrypt and decrypt Raft logs on disk, are loaded into each manager node's memory. You could protect the mutual TLS encryption key and the key used to encrypt and decrypt Raft logs at rest. This protection could be enabled by initializing the swarm with the --autolock flag. With --autolock enabled, when Docker restarts, you must unlock the swarm first, using a key encryption key generated by Docker when the swarm was initialized. This has benefits in a high security environment, however these should be balanced against the support issues caused by the swarm not starting automatically if, for example the host were to experience an outage. Impact: A swarm in auto-lock mode will not recover from a restart without manual intervention from an administrator to enter the unlock key. This may not always be desirable, and should be reviewed at a policy level.",
    "audit": "You should run the command below docker info --format 'Swarm Autolock: {{ .Swarm.Cluster.Spec.EncryptionConfig.AutoLockManagers }}' If the result is true, auto-lock mode is enable. You could also run the command below. If a key value is returned, it means that the swarm was initialized with the --autolock flag. If the output is no unlock key is set, it means that swarm was NOT initialized with the --autolock flag. This should be reviewed in line with the organization's IT Security policy. docker swarm unlock-key",
    "remediation": "If you are initializing a swarm, use the command below. docker swarm init --autolock If you want to set --autolock on an existing swarm manager node, use the following command. docker swarm update --autolock Default Value: By default, the swarm manager does not run in auto-lock mode. References: 1. https://docs.docker.com/engine/swarm/swarm_manager_locking/",
    "function_names": [
      "compute_swarm_manager_auto_lock_enabled",
      "compute_swarm_manager_auto_lock_configured",
      "compute_swarm_manager_auto_lock_active",
      "compute_swarm_manager_auto_lock_required",
      "compute_swarm_manager_auto_lock_enforced"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker Swarm",
    "impact": "A swarm in auto-lock mode will not recover from a restart without manual intervention from an administrator to enter the unlock key. This may not always be desirable, and should be reviewed at a policy level.",
    "references": "1. https://docs.docker.com/engine/swarm/swarm_manager_locking/"
  },
  {
    "id": "7.6",
    "title": "Ensure that the swarm manager auto-lock key is rotated periodically",
    "assessment": "Manual",
    "description": "You should rotate the swarm manager auto-lock key periodically.",
    "rationale": "The swarm manager auto-lock key is not automatically rotated. Good security practice is to rotate keys. Impact: None",
    "audit": "Currently, there is no mechanism to find out when the key was last rotated on a swarm manager node. You should check with the system administrator to see if there is a key rotation process, and how often the key is rotated.",
    "remediation": "You should run the command below to rotate the keys. docker swarm unlock-key --rotate Additionally, to facilitate auditing of this recommendation, you should maintain key rotation records and ensure that you establish a pre-defined frequency for key rotation. Default Value: By default, keys are not rotated automatically. References: 1. https://docs.docker.com/engine/reference/commandline/swarm_unlock-key/",
    "function_names": [
      "swarm_manager_auto_lock_key_rotated_periodically",
      "swarm_manager_auto_lock_key_rotation_enabled",
      "swarm_manager_auto_lock_key_rotation_over_90d",
      "swarm_manager_auto_lock_key_rotation_frequency",
      "swarm_manager_auto_lock_key_rotation_compliance"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker Swarm",
    "impact": "None",
    "references": "1. https://docs.docker.com/engine/reference/commandline/swarm_unlock-key/"
  },
  {
    "id": "7.7",
    "title": "Ensure that node certificates are rotated as appropriate",
    "assessment": "Manual",
    "description": "You should rotate swarm node certificates in line with your organizational security policy.",
    "rationale": "Docker Swarm uses TLS for clustering operations between its nodes. Certificate rotation ensures that in an event such as a compromised node or key, it is difficult to impersonate a node. By default, node certificates are rotated every 90 days, but you should rotate them more often or as appropriate in your environment. Impact: None",
    "audit": "Run one of the commands below and ensure that the node certificate Expiry Duration is set as appropriate. docker info | grep \"Expiry Duration\" docker info --format 'NodeCertExpiry: {{ .Swarm.Cluster.Spec.CAConfig.NodeCertExpiry }}'",
    "remediation": "You should run the command to set the desired expiry time on the node certificate. For example: docker swarm update --cert-expiry 48h Default Value: By default, node certificates are rotated automatically every 90 days. References: 1. https://docs.docker.com/engine/reference/commandline/swarm_update/#exampl es",
    "function_names": [
      "compute_node_certificate_rotated",
      "compute_node_certificate_rotated_over_90d",
      "compute_node_certificate_rotation_enabled",
      "compute_node_certificate_expiry_under_30d",
      "compute_node_certificate_auto_rotation_enabled"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker Swarm",
    "impact": "None",
    "references": "1. https://docs.docker.com/engine/reference/commandline/swarm_update/#exampl es"
  },
  {
    "id": "7.8",
    "title": "Ensure that CA certificates are rotated as appropriate",
    "assessment": "Manual",
    "description": "You should rotate root CA certificates as appropriate.",
    "rationale": "Docker Swarm uses TLS for clustering operations between its nodes. Certificate rotation ensures that in an event such as a compromised node or key, it is difficult to impersonate a node. Node certificates depend upon root CA certificates. For operational security, it is important to rotate these frequently. Currently, root CA certificates are not rotated automatically and you should therefore establish a process for rotating them in line with your organizational security policy. Impact: None",
    "audit": "You should check the time stamp on the root CA certificate file. For example: ls -l /var/lib/docker/swarm/certificates/swarm-root-ca.crt The certificate should show a time stamp in line with the organizational rotation policy.",
    "remediation": "You should run the command below to rotate a certificate. docker swarm ca --rotate Default Value: By default, root CA certificates are not rotated. References: 1. https://docs.docker.com/engine/swarm/how-swarm-mode-works/pki/#rotating- the-ca-certificate",
    "function_names": [
      "cloud_cdn_ssl_certificate_rotated_as_appropriate",
      "cloud_cdn_ssl_certificate_rotation_enabled",
      "cloud_cdn_ca_certificate_rotated_periodically",
      "cloud_cdn_ca_certificate_rotation_compliance",
      "cloud_cdn_ssl_certificate_expiry_monitored",
      "cloud_cdn_ca_certificate_rotation_schedule",
      "cloud_cdn_ssl_certificate_rotation_policy",
      "cloud_cdn_ca_certificate_rotation_enabled",
      "cloud_cdn_ssl_certificate_rotation_valid",
      "cloud_cdn_ca_certificate_rotation_automated"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker Swarm",
    "impact": "None",
    "references": "1. https://docs.docker.com/engine/swarm/how-swarm-mode-works/pki/#rotating- the-ca-certificate"
  },
  {
    "id": "7.9",
    "title": "Ensure that management plane traffic is separated from data plane traffic",
    "assessment": "Manual",
    "description": "You should separate management plane traffic from data plane traffic.",
    "rationale": "Separating management plane traffic from data plane traffic ensures that these types of traffic are segregated from each other. These traffic flows can then be individually monitored and tied to different traffic control policies and monitoring. This also ensures that the management plane is always reachable even if there is a great deal of traffic on the data plane. Impact: This requires two network interfaces per node.",
    "audit": "You should run the command below on each swarm node and ensure that the management plane address is different from the data plane address. docker node inspect  --format '{{ .Status.Addr }}' self",
    "remediation": "You should initialize the swarm with dedicated interfaces for management and data planes respectively. For example, docker swarm init --advertise-addr=192.168.0.1 --data-path-addr=17.1.0.3 Default Value: By default, data plane traffic is not separated from management plane traffic. References: 1. https://docs.docker.com/engine/reference/commandline/swarm_init/#--data-path- addr",
    "function_names": [
      "network_vpc_management_plane_separated",
      "network_subnet_data_plane_isolated",
      "network_route_table_management_plane_restricted",
      "network_security_group_management_plane_only",
      "network_firewall_data_plane_denied",
      "network_nacl_management_plane_allowed",
      "network_peering_management_plane_segregated",
      "network_transit_gateway_data_plane_separated",
      "network_endpoint_management_plane_exclusive",
      "network_vpc_flow_logs_management_plane_monitored"
    ],
    "profile_applicability": "\u2022  Level 1 - Docker Swarm",
    "impact": "This requires two network interfaces per node.",
    "references": "1. https://docs.docker.com/engine/reference/commandline/swarm_init/#--data-path- addr"
  }
]