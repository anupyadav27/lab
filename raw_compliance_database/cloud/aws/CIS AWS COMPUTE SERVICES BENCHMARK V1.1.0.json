[
  {
    "id": "2.1.1",
    "title": "Ensure Consistent Naming Convention is used for Organizational AMI",
    "assessment": "Manual",
    "description": "The naming convention for AMI (Amazon Machine Images) should be documented and followed for any AMI's created.",
    "rationale": "The majority of AWS resources can be named and tagged. Most organizations have already created standardize naming conventions, and have existing rules in effect. They simply need to extend that for all AWS cloud resources to include Amazon Machine Images (AMI)",
    "audit": "Perform the following to determine what AMI's are created: From the Console: 1. Login to the EC2 console at https://console.aws.amazon.com/ec2/. 2. In the left pane, under Images, click AMIs. 3. Review the list of AMIs. 4. Confirm that the AMI Name matches the organizational image naming policy. From the Command Line: 1. Run aws ec2 describe-images. aws ec2 describe-images --owner self --region us-west-2 2. Review the list of AMIs. 3. Confirm that the AMI Name matches the organizational image naming policy. If any of the AMI Name's do not match the Organization policy refer to the remediation below.",
    "remediation": "If the AMI Name for an AMI doesn't follow Organization policy Perform the following to copy and rename the AMI: From the Console: 1. Login to the EC2 console at https://console.aws.amazon.com/ec2/. 2. In the left pane click Images, click AMIs. 3. Select the AMI that does not comply to the naming policy. 4. Click on Actions. 5. Click on Copy AMI. Destination region - Select the region the AMI is in. Name - `Enter the new Name` Description - `Enter the new description` Encryption - `Select` if it matches your image policy 6. Click on Copy AMI Once the AMI has finished copying. 7. Select the AMI that does not comply to the naming policy. 8. Click on Actions. 9. Click on Deregister References: 1. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/describ e-images.html 2. https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/AMIs.html",
    "profile_applicability": "•  Level 1",
    "references": "1. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/describ e-images.html 2. https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/AMIs.html",
    "function_names": [
      "compute_ami_consistent_naming",
      "compute_ami_naming_convention_followed",
      "compute_ami_standardized_naming",
      "compute_ami_documented_naming",
      "compute_ami_naming_compliance",
      "compute_ami_org_naming_convention",
      "compute_ami_naming_policy_enforced"
    ]
  },
  {
    "id": "2.1.2",
    "title": "Ensure Amazon Machine Images (AMIs) are encrypted",
    "assessment": "Automated",
    "description": "Amazon Machine Images should utilize EBS Encrypted snapshots",
    "rationale": "AMIs backed by EBS snapshots should use EBS encryption. Snapshot volumes can be encrypted and attached to an AMI.",
    "audit": "Perform the following to determine AMIs are encrypted: From the Console: 1. Login to the IAM console at https://console.aws.amazon.com/ec2/. 2. In the left pane click Instances, click AMIs. 3. In the Details tab. 4. Review the 'Block Devices' 5. Confirm that it ends with encrypted. If it doesn't end with encrypted, refer to the remediation below. From the Command Line: 1. Run the aws ec2 describe-images command aws ec2 describe-images --region us-east-1 --owner self --filter \"Name=block- device-mapping.encrypted,Values=false\" --query \"Images[*].[ImageId]\" 2. If this produces a list of AMI's make note as these are not encrypted, then refer to the remediation below.",
    "remediation": "Perform the following to encrypt AMI EBS Snapshots: From the Console: 1. Login to the EC2 console at https://console.aws.amazon.com/ec2/. 2. In the left pane click on AMIs. 3. Select the AMI that does not comply to the encryption policy. 4. Click on Actions. 5. Click on Copy AMI. Destination region - `Select the region the AMI is in`. Name - `Enter the new Name` Description - `Enter the new description` Encryption - `Select` Encrypt target EBS snapshots 6. Click on Copy AMI Once the AMI has finished copying. 7. Select the AMI that does not have encrypted EBS snapshots. 8. Click on Actions. 9. Click on Deregister From the Command Line: 1. Run the aws ec2 copy-image command to copy AMI with encrypted block device aws ec2 copy-image --name <New_AMI_Name> --source-image-id <Image-ID> -- source-region <region> --encrypted 2. Run aws ec2 deregister-image to deregister older AMIs aws ec2 deregister-image --image-id <Image-ID> References: 1. https://aws.amazon.com/premiumsupport/knowledge-center/view-ami-snapshot- encryption-details/ 2. https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/AMIEncryption.ht ml 3. https://docs.aws.amazon.com/cli/latest/reference/ec2/copy-image.html 4. https://docs.aws.amazon.com/cli/latest/reference/ec2/deregister-image.html 5. https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DeregisterIma ge.html 6. https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CopyImage.ht ml",
    "profile_applicability": "•  Level 1",
    "references": "1. https://aws.amazon.com/premiumsupport/knowledge-center/view-ami-snapshot- encryption-details/ 2. https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/AMIEncryption.ht ml 3. https://docs.aws.amazon.com/cli/latest/reference/ec2/copy-image.html 4. https://docs.aws.amazon.com/cli/latest/reference/ec2/deregister-image.html 5. https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DeregisterIma ge.html 6. https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CopyImage.ht ml",
    "function_names": [
      "ec2",
      "ec2_snapshot_secure_encryption",
      "ec2_snapshot_ebs_encryption_enabled",
      "ec2_snapshot_encrypted_volumes"
    ]
  },
  {
    "id": "2.1.3",
    "title": "Ensure Only Approved Amazon Machine Images (AMIs) are Used",
    "assessment": "Manual",
    "description": "Ensure that all base AMIs utilized are approved for use by your organization.",
    "rationale": "An approved AMI is a base EC2 machine image that is a pre-configured OS configured to run your application. Using approved AMIs helps enforce consistency and security.",
    "audit": "Perform the following to confirm only approved AMIs are being used. From the Console: 1. Login to the EC2 console at https://console.aws.amazon.com/ec2/. 2. In the left pane click on Images. 3. Then choose AMIs 4. Confirm that Owned by me is selected 5. Review the list of AMIs. 6. Confirm that the AMIs listed are all approved for use 7. In the left pane click on Instances 8. Then choose Instances 9. Select the EC2 instance for review. 10. In the Details tab review: AMI Name AMI location 11. Confirm that the AMI name matches an approved AMI and the AMI location is within your account. 12. Repeat steps 9 – 11 to verify the AMI is approved Repeat the process for all other regions. If any of the AMIs are not approved refer to the remediation below.",
    "remediation": "Perform the following to remove unauthorized AMIs.  From the Console: 1. Login to the EC2 console at https://console.aws.amazon.com/ec2/. 2. In the left pane click on Images. 3. Then choose AMIs 4. Confirm that Owned by me is selected 5. Review the list of AMIs. 6. Confirm that the AMIs listed are all approved for use 7. If an AMI is listed that is not approved select it. 8. Click on Actions and choose Deregister After all unauthorized AMIs have been De-registered review all EC2 instances. 1. Click on Instances 2. Then choose Instances 3. Select the EC2 instance for review. 4. In the Details tab review: AMI Name AMI location] 5. If this information is listed as not available this instance was built with an unauthorized AMI. 6. Follow organization steps to secure this instance and replace it with an instance built from an approved AMI if applicable. 7. Repeat steps 3 – 6 to verify all instance have been created with approved AMIs Repeat the process for all other regions.",
    "profile_applicability": "•  Level 1",
    "function_names": [
      "compute_image_approved_ami",
      "compute_ami_approved_list",
      "compute_ami_approved_only",
      "compute_image_approved_list",
      "compute_ami_approved_usage"
    ]
  },
  {
    "id": "2.1.4",
    "title": "Ensure Images (AMI) are not older than 90 days",
    "assessment": "Automated",
    "description": "Ensure that your AMIs are not older than 90 days.",
    "rationale": "Using up-to-date AMIs will provide many benefits from OS updates and security patches helping to ensure reliability, security and compliance.",
    "audit": "Perform the following to determine the age of an AMI. From the Console 1. Login to the EC2 console at https://console.aws.amazon.com/ec2/. 2. In the left pane, under Images, click AMIs. 3. Select the AMI for review. 4. Under the Details tab 5. Review the Creation date. If the age of the selected AMI is greater than 90 days, the AMI is considered outdated and it should be updated. 6. Repeat steps no. 3 – 5 to verify the date of the other approved AMIs available. Repeat all steps for the other regions. Refer to the remediation procedure below to update the AMI. From the Command Line: Run the aws ec2 describe-images command aws ec2 describe-images \\ --region <region> \\ --image-ids <image-ID> Look for CreationDate in response. If the age of the selected AMI is greater than 90 days, the AMI is considered outdated and it should be updated.",
    "remediation": "Perform these steps if the Creation date is older than 90 days. From the Console 1. Login to the EC2 console at https://console.aws.amazon.com/ec2/. 2. In the left pane, under Images, click AMIs. 3. Select the AMI to be updated. 4. Click on Launch 5. Go through the EC2 Instance creation process. 6. Apply all system, security and application updates that are applicable to the EC2 instance. 7. Once completed click on Instance state, `Stop instance1. 8. Click on Actions, Image and templates, Create image 9. Once the image process has complete return to the AMI list but clicking on Images, AMIs 10. Select the AMI that is older than 90 days. 11. Click on Actions, Deregister Repeat these steps for any other AMIs older than 90 days. References: 1. https://docs.aws.amazon.com/cli/latest/reference/ec2/describe-images.html 2. https://docs.aws.amazon.com/cli/latest/reference/ec2/deregister-image.html",
    "profile_applicability": "•  Level 1",
    "references": "1. https://docs.aws.amazon.com/cli/latest/reference/ec2/describe-images.html 2. https://docs.aws.amazon.com/cli/latest/reference/ec2/deregister-image.html",
    "function_names": [
      "compute_image_recent_over_90d",
      "compute_ami_age_within_90d",
      "compute_image_no_older_than_90d",
      "compute_ami_recently_updated",
      "compute_image_freshness_within_90d"
    ]
  },
  {
    "id": "2.1.5",
    "title": "Ensure Images are not Publicly Available",
    "assessment": "Manual",
    "description": "EC2 allows you to make an AMI public, sharing it with all AWS accounts.",
    "rationale": "Publicly sharing an AMI with all AWS accounts could expose organizational data and configuration information.",
    "audit": "Perform the steps below to determine if any AMIs are shared with all AWS accounts. From the Console 1. Login to the EC2 console at https://console.aws.amazon.com/ec2/. 2. In the left pane, under Images, click AMIs. 3. Confirm the Owned by me is set. 4. Select the AMI from the list. 5. Click on the Permissions Tab 6. If this reads This image is currently Public. Please refer to the remediation below.",
    "remediation": "Perform the steps below to set an AMIs to Private. From the Console 1. Login to the EC2 console at https://console.aws.amazon.com/ec2/. 2. In the left pane, under Images, click AMIs. 3. Confirm the Owned by me is set. 4. Select the AMI from the list. 5. Click on the Permissions Tab 6. Click on Edit 7. Click on the radio button Private Add AWS Account Number if you have a need to share with other Internal AWS accounts that your Organization owns. References: 1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/sharing-amis.html",
    "profile_applicability": "•  Level 1",
    "references": "1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/sharing-amis.html",
    "function_names": [
      "ec2"
    ]
  },
  {
    "id": "2.2.1",
    "title": "Ensure EBS volume encryption is enabled",
    "assessment": "Automated",
    "description": "Elastic Compute Cloud (EC2) supports encryption at rest when using the Elastic Block Store (EBS) service. While disabled by default, forcing encryption at EBS volume creation is supported.",
    "rationale": "Encrypting data at rest reduces the likelihood that it is unintentionally exposed and can nullify the impact of disclosure if the encryption remains unbroken.",
    "audit": "From Console: 1. Login to the EC2 console using https://console.aws.amazon.com/ec2/ 2. Under Account attributes, click EBS encryption. 3. Verify Always encrypt new EBS volumes displays Enabled. 4. Review every region in-use. Note: EBS volume encryption is configured per region. From Command Line: 1. Run aws --region <region> ec2 get-ebs-encryption-by-default 2. Verify that \"EbsEncryptionByDefault\": true is displayed. 3. Review every region in-use. Note: EBS volume encryption is configured per region. From Console: 1. Login to the EC2 console using https://console.aws.amazon.com/ec2/ 2. Under Account attributes, click EBS encryption. 3. Click Manage. 4. Click the Enable checkbox. 5. Click Update EBS encryption 6. Repeat for every region requiring the change. Note: EBS volume encryption is configured per region. From Command Line: 1. Run aws --region <region> ec2 enable-ebs-encryption-by-default 2. Verify that \"EbsEncryptionByDefault\": true is displayed. 3. Repeat every region requiring the change. Note: EBS volume encryption is configured per region. References: 1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html 2. https://aws.amazon.com/blogs/aws/new-opt-in-to-default-encryption-for-new-ebs- volumes/ 3. AWS Config rule - ec2_ebs_encryption_by_default",
    "remediation": null,
    "profile_applicability": "•  Level 1",
    "references": "1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html 2. https://aws.amazon.com/blogs/aws/new-opt-in-to-default-encryption-for-new-ebs- volumes/ 3. AWS Config rule - ec2_ebs_encryption_by_default",
    "function_names": [
      "ebs_volume_encryption_enabled",
      "ebs_volume_default_encryption_enabled",
      "ebs_volume_encryption_enabled_all_regions",
      "ebs_volume_encryption_enabled_new_volumes",
      "ebs_volume_encryption_enabled_existing_volumes"
    ]
  },
  {
    "id": "2.2.2",
    "title": "Ensure Public Access to EBS Snapshots is Disabled",
    "assessment": "Automated",
    "description": "To protect your data disable the public mode of EBS snapshots.",
    "rationale": "This protects your data so that it is not accessible to all AWS accounts preventing accidental access and leaks.",
    "audit": "Perform the following to determine if a snapshot is shared publicly: From the Console 1. Login to the EC2 console at https://console.aws.amazon.com/ec2/. 2. In the left pane click Snapshots. 3. Select the snapshot then click Actions, Modify Permissions. 4. Confirm that the snapshot is set to Private 5. Repeat for any additional Snapshots, Regions and AWS accounts. If the snapshot is set to public refer to the remediation below. From the CLI 1. For each snapshot, run aws ec2 describe-snapshot-attribute \\ --snapshot-id <snapshot-ID> \\ --attribute createVolumePermission 2. Validate Group is not set to all.",
    "remediation": "Perform the following to set a snapshot to private: From the Console 1. Login to the EC2 console at https://console.aws.amazon.com/ec2/. 2. In the left pane click Snapshots. 3. Select the snapshot then click 'Actions, Modify Permissions`. 4. Click the radio button for Private 5. Click Save 6. Repeat for any additional Snapshots, Regions and AWS accounts. From the CLI 1. For each snapshot, run aws ec2 modify-snapshot-attribute \\ --snapshot-id <snapshot-ID> \\ --attribute createVolumePermission \\ --operation remove --group-name all References: 1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/describ e-snapshot-attribute.html Additional Information: 1. Snapshots are constrained to the Region in which they were created. To share a snapshot with another Region, copy the snapshot to that Region. 2. AWS prevents you from sharing snapshots that were encrypted with your default CMK. Snapshots that you intend to share must instead be encrypted with a customer managed CMK. 3. The public option is not valid for encrypted snapshots or snapshots with an AWS Marketplace product code.",
    "profile_applicability": "•  Level 1",
    "references": "1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSSnapshots.html 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/describ e-snapshot-attribute.html Additional Information: 1. Snapshots are constrained to the Region in which they were created. To share a snapshot with another Region, copy the snapshot to that Region. 2. AWS prevents you from sharing snapshots that were encrypted with your default CMK. Snapshots that you intend to share must instead be encrypted with a customer managed CMK. 3. The public option is not valid for encrypted snapshots or snapshots with an AWS Marketplace product code."
  },
  {
    "id": "2.2.3",
    "title": "Ensure EBS volume snapshots are encrypted",
    "assessment": "Automated",
    "description": "Elastic Compute Cloud (EC2) supports encryption at rest when using the Elastic Block Store (EBS) service.",
    "rationale": "Encrypting data at rest reduces the likelihood that it is unintentionally exposed and can nullify the impact of disclosure if the encryption remains unbroken.",
    "audit": "From Console: 1. Login to the EC2 console using https://console.aws.amazon.com/ec2/ 2. Under Elastic Block Store, click Snapshots. 3. Click the snapshot you want to review. 4. Select the Description tab. 5. Review the Encryption setting. 6. If it reads encrypted you are all set. If it is set to Not Encrypted refer to the remediation below. Note: EBS snapshot volume encryption is configured per snapshot. From Command Line: 1. Run describe-snapshots aws ec2 describe-snapshots --owner-ids <account number> --filter Name=status,Values=completed --query \"Snapshots[*].{ID:SnapshotId}\" 2. This will provide a list of all the snapshots associated with that account in the region. 3. For every snapshot listed - Run - describe-snapshots aws ec2 describe-snapshots --snapshot-id <snap-name> --query \"Snapshots[*].{Encrypt:Encrypted}\" 4. If the output reads \"Encrypt\": true, Encryption is set on the snapshot. If the output reads \"Encrypt\": false refer to the remediation below. Note: EBS snapshot volume encryption is configured per snapshot.",
    "remediation": "From Console: 1. Login to the EC2 console using https://console.aws.amazon.com/ec2/ 2. Under Elastic Block Store, click Snapshots`. 3. Select the snapshot you want to encrypt. 4. Click on Actions select Copy. Confirm `Snapshot ID` Set the `Destination Region` Update the `Description` Select the check box for `Encryption` 5. Check the box for Encrypt this snapshot 6. Set the Master Key 7. Click on Copy 8. Repeat steps 3-7 for the snapshots that need to be encrypted. 9. Delete any of the unencrypted snapshots that are not longer needed. Note: EBS snapshot volume encryption is configured per snapshot. From Command Line: Using the snapshot ids gathered from the Audit section 1. Run - copy-snapshot aws ec2 copy-snapshot --source-region  <region> --source-snapshot-id <snap- id> --description \"Name of the new snapshot\" --encrypted 2. This will copy the existing unencrypted snapshot and set it to encrypted The output will show the new SnapshotId 3. Run - describe-snapshots aws ec2 describe-snapshots --owner-ids <account id> --filter Name=status,Values=completed --query \"Snapshots[*].{ID:SnapshotId}\" Once the new Snapshot shows in the list confirm encryption is set 4. Run - describe-snapshots aws ec2 describe-snapshots --snapshot-id <snap-name> --query \"Snapshots[*].{Encrypt:Encrypted}\" 5.Repeat steps 1-4 for the snapshots that need to be encrypted. Delete snapshots that are no longer needed. 6. Run - delete-snapshot aws ec2 delete-snapshot --snapshot-id <snap-name> 7. Repeat for all unencrypted snapshots that have been copied and encrypted. Note: EBS snapshot volume encryption is configured per snapshot. References: 1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/describ e-snapshots.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/delete- snapshot.html 4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/copy- snapshot.html",
    "profile_applicability": "•  Level 1",
    "references": "1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/describ e-snapshots.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/delete- snapshot.html 4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/copy- snapshot.html",
    "function_names": [
      "ebs_snapshot_encryption_enabled",
      "ebs_snapshot_encryption_enabled_all_regions",
      "ebs_snapshot_default_encryption_enabled",
      "kms",
      "ebs_snapshot_encryption_enabled_over_90d"
    ]
  },
  {
    "id": "2.2.4",
    "title": "Ensure unused EBS volumes are removed",
    "assessment": "Manual",
    "description": "Identify any unused Elastic Block Store (EBS) volumes in your AWS account and remove them.",
    "rationale": "Any Elastic Block Store volume created in your AWS account contains data, regardless of being used or not. If you have EBS volumes (other than root volumes) that are unattached to an EC2 instance they should be removed to prevent unauthorized access or data leak to any sensitive data on these volumes. Impact: Once a EBS volume is deleted, the data will be lost. If this is data that you need to archive, create an encrypted EBS snapshot before deleting them.",
    "audit": "From Console: 1. Login to the EC2 console using https://console.aws.amazon.com/ec2/ 2. Under Elastic Block Store, click Volumes. 3. Find the State column 4. Sort by Available 5. Any Volumes listed as Available can be deleted as that is the indication the volume is not attached to an instance. Capture this list of volume names and refer to the remediation below. Note: EBS volumes can be in different regions. Make sure to review all the regions being utilized. From Command Line: 1. Run describe-volumes aws ec2 describe-volumes --filter Name=status,Values=available --query \"Volumes[*].{ID:VolumeId}\" 2. This will provide a list of all the volumes not attached to an instance Capture this list of volume names and refer to the remediation below. Note: EBS volumes can be in different regions. Make sure to review all the regions being utilized.",
    "remediation": "From Console: 1. Login to the EC2 console using https://console.aws.amazon.com/ec2/ 2. Under Elastic Block Store, click Volumes. 3. Find the State column 4. Sort by Available 5. Select the Volume that you want to delete. 6. Click Actions, Delete volume, Yes, Delete Note: EBS volumes can be in different regions. Make sure to review all the regions being utilized. From Command Line: Using the list of available volumes identified in the Audit above 1. Run the delete-volume command aws ec2 delete-volume --volume-id <vol-name> 2. This will delete the volume identified. Note: Using this command will not prompt you for confirmation. It will delete the volume and you will not be able to recover it. Please make sure you have the correct volume and that you have created a snapshot if it is something that needs to be archived. Note: EBS volumes can be in different regions. Make sure to review all the regions being utilized. References: 1. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/describ e-volumes.html 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/delete- volume.html",
    "profile_applicability": "•  Level 1",
    "impact": "Once a EBS volume is deleted, the data will be lost. If this is data that you need to archive, create an encrypted EBS snapshot before deleting them.",
    "references": "1. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/describ e-volumes.html 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/delete- volume.html",
    "function_names": [
      "ebs_volume_unused_removed",
      "ebs_volume_unused_over_30d_removed",
      "ebs_volume_unused_over_90d_removed",
      "ebs_volume_unattached_removed",
      "ebs_volume_unattached_over_30d_removed",
      "ebs_volume_unattached_over_90d_removed"
    ]
  },
  {
    "id": "2.3",
    "title": "Ensure Tag Policies are Enabled",
    "assessment": "Manual",
    "description": "Tag policies help you standardize tags on all tagged resources across your organization.",
    "rationale": "You can use tag policies to define tag keys (including how they should be capitalized) and their allowed values.",
    "audit": "From the Console 1. Login to AWS Organizations using https://console.aws.amazon.com/organizations/ 2. In the left pane click on Policies 3. Confirm Tag policies status is enabled. If Tag policies status is disabled refer to the remediation below. From the CLI 1. Run the list-policies command aws organizations list-policies --filter TAG_POLICY 2. If information displays it means you have a tagging policy in place. 3. If empty brackets display [] refer to the remediation below.",
    "remediation": "From the Console: You must sign in as an IAM user, assume an IAM role, or sign in as the root user (not recommended) in the organization’s management account. 1. Login to AWS Organizations using https://console.aws.amazon.com/organizations/ 2. In the Left pane click on Policies 3. Click on Tag policies 4. Click on Enable Tag Policies 5. The page is update with a list of the Available policies and the ability to create one. From the Command Line: You must use an IAM user, assume an IAM role, or sign in as the root user (not recommended) in the organization’s management account. 1. Run the enable-policy-type command aws organizations enable-policy-type --root-id <RootID>  --policy-type TAG_POLICIES The list of PolicyTypes in the output will now include the specified policy type with the Status of ENABLED. References: 1. https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_polici es_enable-disable.html#enable-policy-type",
    "profile_applicability": "•  Level 1",
    "references": "1. https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_polici es_enable-disable.html#enable-policy-type",
    "function_names": [
      "organizations",
      "organizations_tag_policy_standardized_tags"
    ]
  },
  {
    "id": "2.4",
    "title": "Ensure an Organizational EC2 Tag Policy has been Created",
    "assessment": "Manual",
    "description": "A tag policy enables you to define tag compliance rules to help you maintain consistency in the tags attached to your organization's resources.",
    "rationale": "You can use an EC2 tag policy to enforce your tag strategy across all of your EC2 resources.",
    "audit": "From the Console: 1. Login to the AWS Organizations using https://console.aws.amazon.com/organizations/ 2. On the left click Policies 3. Click on Tag policies 4. Confirm that a policy name exists with a description 5. Click on the policy for EC2 Tagging as indicated in the name, description or both. 6. Click on Edit policy 7. Confirm that Tag key capitalization compliance is checked 8. Confirm that Prevent non-compliant operations for this tag is checked. 9. Confirm that ec2:image, ec2:instance and ec2:reserved-instances are listed. If the tag policy does not exist with the settings listed above refer to the remediation below.",
    "remediation": "From the Console: You must sign in as an IAM user, assume an IAM role, or sign in as the root user (not recommended) in the organization’s management account. To create a tag policy 1. Login to the AWS Organizations using https://console.aws.amazon.com/organizations/ 2. Left hand side Click on Policies 3. Under Support policy types click on Tag policies 4. Under Available policies click on Create policy 5. Enter policy name 6. Enter policy description (Indicate this is the EC2 tag policy) 7. For New tag key 1, specify the name of a tag key to add. 8. For Tag key capitalization compliance select the box for Use the capitalization to enable this option mandating a specific capitalization for the tag key using this policy. 9. For Resource types to enforce check the box for Prevent non-compliant operations for this tag 10. Click on Specify resource types 11. Expand EC2 12. Select ec2:image, ec2:instance, ec2:reserved-instances 13. Click Save changes 14. Click Create policy References: 1. https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_polici es_tag-policies-create.html",
    "profile_applicability": "•  Level 1",
    "references": "1. https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_polici es_tag-policies-create.html",
    "function_names": [
      "organizations",
      "ec2_tag_policy_organization_defined",
      "ec2_tag_policy_consistency_enforced"
    ]
  },
  {
    "id": "2.5",
    "title": "Ensure no AWS EC2 Instances are Older than 180 days",
    "assessment": "Manual",
    "description": "Identify any running AWS EC2 instances older than 180 days.",
    "rationale": "An EC2 instance is not supposed to run indefinitely and having instance older than 180 days can increase the risk of problems and issues.",
    "audit": "From the Console: 1. Login to EC2 using https://console.aws.amazon.com/ec2/ 2. On the left Click INSTANCES, click Instances. 3. Select the EC2 instance. The Instance State must be 'running'. 4. Select the Description tab. 5. Check the Launch time. 6. Determine the instance active age. 7. If the selected EC2 instance active age is greater than 180 days, refer to the remediation below. 8. Repeat steps no. 3 – 7 to verify the launch date for all instances. 9. Go through the other AWS regions and repeat the audit process. From the CLI 1. Run the describe-instances command aws ec2 describe-instances --region us-east-1 --output json --filters \"Name=instance-state-code,Values=16\" --query \"Reservations[*].Instances[*].{Instance:InstanceId}\"  2 The output should look like this: [ [ { \"Instance\": \"i-1234567abcdefghi0\" } ], [ { \"Instance\": \"i-1234567abcdefghi0\" } ], [ { \"Instance\": \"i-1234567abcdefghi0\" } ], [ { \"Instance\": \"i-1234567abcdefghi0\" } ] ] 3 Run the describe-instances command for each instance ID listed: aws ec2 describe-instances --region us-east-1 --instance-ids i- 1234567abcdefghi0 --query \"Reservations[*].Instances[*].LaunchTime\" 4. The command output should return the instance launch date in human readable format: \"2021-06-11T15:04:52+00:00\" `` 5. If the selected instance was launched more than 180 days ago, refer to the remediation below. 6. Repeat steps 3 and 4 to verify the launch date for all instances listed. 7. Repeat steps 1 – 6 for the other AWS regions.",
    "remediation": "From the Console: 1. Login to EC2 using https://console.aws.amazon.com/ec2/ 2. On the left Click INSTANCES, click Instances. 3. Select the EC2 instance identified above in the audit. The Instance State must be 'running'. 4. Click Actions, click Instance State, click Stop. 5. Wait for the Instance State to read 'stopped'. 6. Click 'Actions' click 'Instance State', click 'Start' 7. Select the Description tab. 8. Check the Launch time. Confirm that the instance active age is now set to today's date and time.",
    "profile_applicability": "•  Level 1",
    "function_names": [
      "compute_instance_max_age_over_180d",
      "ec2",
      "compute_instance_rotation_within_180d",
      "compute_instance_recent_within_180d"
    ]
  },
  {
    "id": "2.6",
    "title": "Ensure detailed monitoring is enable for production EC2 Instances",
    "assessment": "Manual",
    "description": "Ensure that detailed monitoring is enabled for your Amazon EC2 instances.",
    "rationale": "Monitoring is an important part of maintaining the reliability, availability, and performance of your Amazon EC2 instances Impact: Data is available in 1-minute periods. For the instances where you've enabled detailed monitoring, you can also get aggregated data across groups of similar instances. You are charged per metric that is sent to CloudWatch. You are not charged for data storage. Due to this added cost it is recommended that you only enable this on critical instances.",
    "audit": "From the Console: 1. Login to EC2 using https://console.aws.amazon.com/ec2/ 2. On the left Click INSTANCES, click Instances. 3. Select the EC2 instance you want to review. 4. Select the Description tab. 5. Check the Launch time. 6. Determine the level of monitoring by reviewing the 'Monitoring attribute'. 7. If the value is set to basic refer to the remediation below. 8. Repeat steps no. 3 – 7 to verify the monitoring level for all instances. 9. Go through the other AWS regions and repeat the audit process. From the CLI 1. Run the describe-instances command aws ec2 describe-instances --region us-east-1 --output json --filters \"Name=monitoring-state,Values=disabled\" --query \"Reservations[*].Instances[*].{Instance:InstanceId}\"  2. The output should be a list of running instances that have enhanced monitoring disabled. 3. Based on this list of instance ids refer to the remediation below.",
    "remediation": "From the Console: 1. Login to EC2 using https://console.aws.amazon.com/ec2/ 2. On the left Click INSTANCES, click Instances. 3. Select the EC2 instance you want to review. 4. Select the Monitoring tab. 5. Click on 'Enable Detailed Monitoring` 6. Click on Yes, Enable 7. Repeat steps no. 3 – 6 for any other instances that require detailed monitoring to be enabled. From the CLI 1. Run the monitor-instances command using the list of instances collected in the audit. aws ec2 monitor-instances --instance-ids <i-instancename> 2. The output will show 'state: pending' 3. Wait a few minutes and run the same command again for that instance and it will show enabled.",
    "profile_applicability": "•  Level 2",
    "impact": "Data is available in 1-minute periods. For the instances where you've enabled detailed monitoring, you can also get aggregated data across groups of similar instances. You are charged per metric that is sent to CloudWatch. You are not charged for data storage. Due to this added cost it is recommended that you only enable this on critical instances.",
    "function_names": [
      "compute_instance_monitoring_enabled_detailed",
      "compute_instance_detailed_monitoring_enabled_production",
      "ec2"
    ]
  },
  {
    "id": "2.7",
    "title": "Ensure Default EC2 Security groups are not being used.",
    "assessment": "Manual",
    "description": "When an EC2 instance is launched a specified custom security group should be assigned to the instance.",
    "rationale": "When an EC2 Instance is launched the default security group is automatically assigned. In error a lot of instances are launched in this way, and if the default security group is configured to allow unrestricted access, it will increase the attack footprint allowing the opportunity for malicious activity.",
    "audit": "From the Console: 1. Login to EC2 using https://console.aws.amazon.com/ec2/ 2. On the left Click INSTANCES, click Instances. 3. On the EC2 Instances page, click inside the attributes filter box 4. Click the Security Group Name from the dropdown list 5. Type default for the attribute value. (This filter will detect the EC2 instances currently associated with the default security group) 6. Refer to the remediation below using list of Ec2 Instance ids captured. NOTE Repeat the audit process for all other regions used. From the CLI 1. Run the describe-instances command aws ec2 describe-instances --region us-east-1 --output json --filters \"Name=instance.group-name,Values=default\" --query \"Reservations[*].Instances[*].{Instance:InstanceId}\" 2. The command output should return an empty list if the default security group is not being used. 3. If there is a list of instance IDs then the default security group is currently attached to those EC2 instances. 4. Refer to the remediation below using list of EC2 Instance ids captured. NOTE Repeat the audit process for all other regions used.",
    "remediation": "From the Console: 1. Login to EC2 using https://console.aws.amazon.com/ec2/ 2. On the left Click Network & Security, click Security Groups. 3. Select Security Groups 4. Click on the default Security Group you want to review. 5. Click Actions, View details. 6. Select the Inbound rules tab 7. Click on Edit inbound rules 8. Click on Delete for all the rules listed 9. Once there are no rules listed click on 'Save rules` 10. Repeat steps no. 3 – 8 for any other default security groups listed. References: 1. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/describ e-security-groups.html 2. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/default-custom- security-groups.html#default-security-group",
    "profile_applicability": "•  Level 1",
    "references": "1. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/describ e-security-groups.html 2. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/default-custom- security-groups.html#default-security-group",
    "function_names": [
      "ec2"
    ]
  },
  {
    "id": "2.8",
    "title": "Ensure the Use of IMDSv2 is Enforced on All Existing Instances",
    "assessment": "Manual",
    "description": "Ensure the Instance Metadata Service Version 2 (IMDSv2) method is enabled on all running instances.",
    "rationale": "The IMDSv2 method uses session-based controls to help protect access and control of Amazon Elastic Compute Cloud (Amazon EC2) instance metadata. With IMDSv2, controls can be implemented to restrict changes to instance metadata. Impact: Once you enforce IMDSv2, then IMDSv1 no longer works, and applications that use IMDSv1 might not function correctly. Before enforcing IMDSv2, verify that any applications that use Amazon EC2 metadata are upgraded to a version that supports IMDSv2.",
    "audit": "From the Console: 1. At this time the instance metadata setting for existing instances can only be reviewed and confirmed using AWS CLI. From the CLI 1. Run the describe-instances command aws ec2 describe-instances --region us-east-1 --output text --filter \"Name=metadata-options.http-tokens,Values=optional\" --query \"Reservations[*].Instances[*].{Instance:InstanceId}\" 2 The output should look like this: i-1234567abcdefghi0 i-1234567abcdefghi0 i-1234567abcdefghi0 The list above contains all the instances that have the metadata version set to optional which means either IMDSv1 or INDSv2 an be used. Refer to the remediation below. Repeat steps 1 – 2 for the other AWS regions.",
    "remediation": "From the Console: 1. At this time the instance metadata setting for existing instances can only be changed using AWS CLI. From the CLI 1. Run the modify-instance-metadata-options command using the list of Instances collect in the audit aws ec2 modify-instance-metadata-options --instance-id i-1234567abcdefghi0 -- http-tokens required --http-endpoint enabled 2. The output should show the information for the instance and the metadata changes: { \"InstanceId\": \"i-1234567abcdefghi0\", \"InstanceMetadataOptions\": { \"State\": \"pending\", \"HttpTokens\": \"required\", \"HttpPutResponseHopLimit\": 1, \"HttpEndpoint\": \"enabled\" } } 3. Repeat for the other instances and regions collected during the audit. References: 1. https://aws.amazon.com/premiumsupport/knowledge-center/ssm-ec2-enforce- imdsv2/ 2. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/configuring-instance- metadata-service.html 3. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/configuring-instance- metadata-options.html 4. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/launching- instance.html#configure_instance_details_step 5. https://docs.aws.amazon.com/config/latest/developerguide/ec2-imdsv2- check.html 6. https://docs.aws.amazon.com/systems-manager-automation- runbooks/latest/userguide/automation-aws-enforce-ec2-imdsv2.html",
    "profile_applicability": "•  Level 2",
    "impact": "Once you enforce IMDSv2, then IMDSv1 no longer works, and applications that use IMDSv1 might not function correctly. Before enforcing IMDSv2, verify that any applications that use Amazon EC2 metadata are upgraded to a version that supports IMDSv2.",
    "references": "1. https://aws.amazon.com/premiumsupport/knowledge-center/ssm-ec2-enforce- imdsv2/ 2. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/configuring-instance- metadata-service.html 3. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/configuring-instance- metadata-options.html 4. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/launching- instance.html#configure_instance_details_step 5. https://docs.aws.amazon.com/config/latest/developerguide/ec2-imdsv2- check.html 6. https://docs.aws.amazon.com/systems-manager-automation- runbooks/latest/userguide/automation-aws-enforce-ec2-imdsv2.html",
    "function_names": [
      "compute_instance_imdsv2_required",
      "compute_instance_metadata_version_2_required",
      "compute_instance_imdsv2_only",
      "compute_instance_metadata_version_2_only"
    ]
  },
  {
    "id": "2.9",
    "title": "Ensure use of AWS Systems Manager to manage EC2 instances",
    "assessment": "Manual",
    "description": "An inventory and management of Amazon Elastic Compute Cloud (Amazon EC2) instances is made possible with AWS Systems Manager.",
    "rationale": "Use AWS Systems Manager to provide detailed system configurations, operating system patch levels, services name and type, software installations, application name, publisher and version, and other details about your environment.",
    "audit": "From the Console 1. Login to EC2 using https://console.aws.amazon.com/systems-manager/ 2. On the left Click Node Management, click Inventory. 3. On the Dashboard confirm that all of your Instances are listed as part of your inventory. If any instances are missing or AWS Systems Manager is not configured, refer to the remediation below.",
    "remediation": "From the Console These directions already assume your AWS account is setup. They will walk you through how to create non-Admin IAM users and groups for System Manager. **Note - There is additional guidance provided by AWS on the process. 1. Create a user group a. Login to IAM using https://console.aws.amazon.com/iam/ b. On the left Click Access management, click User groups, and then click Create Group. c. On the Create user group page, enter a name for the group d. Select and add the users required to the Group e. Attach permissions policies by selecting ResourceGroupsandTagEditorFullAccess policy. f. Then for Full access to Systems Manager console, click the AmazonSSMFullAccess policy. • OR g. For access to view Systems Manager data, and not create or update resources, click the AmazonSSMReadOnlyAccess policy. h. For access to the Built-In Insights and Dashboard by CloudWatch pages in the Systems Manager console, add these policies: • AWSHealthFullAccess • AWSConfigUserAccess • CloudWatchReadOnlyAccess i. Click Create group. If you need additional users follow the next step. If not skip to Step 3. 2. Create users and assign permissions. a. Login to IAM using https://console.aws.amazon.com/iam/ b. On the left Click Access management, click Users, and then click Add users. c. User name, enter the name that the user will use to sign in to AWS Systems Manager. d. To allow the user access to development tools, select the check box next to Access key - Programmatic access. This creates an access key for the new user. You can view or download the access keys when you get to the Final page. e. To allow user access to the AWS Management Console, select the check box next to AWS Management Console access. If you click Custom password, enter an initial password for the user. You can optionally select Require password reset to force the user to create a new password the next time the user signs in. f. Click Next: Permissions. g. To Set permissions, click Add user to group. h. In the group list, click the group you created in step 1 i. Then click Next: Tags. j. (Optional) Add one or more tags k. Click Next: Review to see the list of group memberships that the new user is joining. l. Click Create user. 3. To add permissions for an existing user a. In the IAM console, click Users. b. click the name of the user to add to a group c. Then click Add permission. d. For Add user to group, select the box next to the group to add the user to e. Add any other available permission policies to assign to the user. f. Click Next: Review to see the list of group memberships that will be added to the new user. g. Click Add permissions. 4. Create an IAM instance profile for Systems Manager a. Login to the IAM console at https://console.aws.amazon.com/iam/ b. In the left, click Roles, and then click Create role. c. Under Select type of trusted entity, click AWS service. d. Click EC2, and then click Next: Permissions. e. On the Attach permissions policies page, do the following: Use the Search field to locate the AmazonSSMManagedInstanceCore. Select the box next to it. The console retains your selection even if you search for other policies. • **Note - If you plan to join instances to an Active Directory managed by AWS Directory Service, search for AmazonSSMDirectoryServiceAccess and select the box next to its name • **Note - If you plan to use EventBridge or CloudWatch Logs to manage or monitor your instance, search for CloudWatchAgentServerPolicy and select the box next to its name. f. Click Next: Tags. g. Add one or more tag-key value pairs to organize, track, or control access for this role, h. Click Next: Review. i. For Role name, enter a name for your new instance profile • **Note - Make a note of the role name. You will click this role when you create new instances that you want to manage by using Systems Manager. j. For Role description, enter a description for this instance profile. k. Click Create role. The system returns you to the Roles page. 5. Attach the Systems Manager instance profile to an existing instance a. Login to the EC2 console at https://console.aws.amazon.com/ec2/ b. In he left pane, under Instances, click Instances. c. Select the instance from the list. d. In the Actions menu, click Security, Modify IAM role. e. Select the instance profile you created using the procedure in Step 4. f. Click Save. 6. Attach an IAM instance profile to an Amazon EC2 instance a. Login to the EC2 console at https://console.aws.amazon.com/ec2/ b. Select or confirm the AWS Region for the instance. c. Click Launch Instance. d. Locate the AMI for the instance type you want to create, and then click Select. e. Select the type of instance to launch, then click Next: Configure Instance Details. f. On the Configure Instance Details page, in the IAM role dropdown list, select the instance profile you created in Step 4 g. For other options on the page, make selections that meet your requirements for the instance. h. Complete the wizard. If you create other instances that you want to configure using Systems Manager, specify the instance profile for each instance References: 1. https://docs.aws.amazon.com/systems-manager/latest/userguide/systems- manager-setting-up.html",
    "profile_applicability": "•  Level 2",
    "references": "1. https://docs.aws.amazon.com/systems-manager/latest/userguide/systems- manager-setting-up.html",
    "function_names": [
      "ec2"
    ]
  },
  {
    "id": "2.10",
    "title": "Ensure unused ENIs are removed",
    "assessment": "Manual",
    "description": "Identify and delete any unused Amazon AWS Elastic Network Interfaces in order to adhere to best practices and to avoid reaching the service limit. An AWS Elastic Network Interface (ENI) is pronounced unused when is not attached anymore to an EC2 instance.",
    "rationale": "",
    "audit": "From the Console: 1. Login to EC2 using https://console.aws.amazon.com/ec2/ 2. On the left Click NETWORK & SECURITY, click Network Interfaces. 3. Select the ENI that you want to review 4. Go to the Details tab 5. Check the value set for the Status attribute 6. If it says available, refer to the remediation below. 7. Repeat steps 3 - 6 to determine the current status for any other ENIs within the current region. NOTE Repeat the audit process for all other regions used. From the CLI 1. Run describe-network-interfaces command aws ec2 describe-network-interfaces --region us-east-1 --output json -- filters Name=status,Values=available --query \"NetworkInterfaces[*].{ENI:NetworkInterfaceId}\" 2. The command output should return an empty list if the default security group is not being used. 3. If there is a list of ENI IDs then refer to the remediation below. 4. Repeat steps 1 - 3 to determine the current status for any other ENIs within the current region. NOTE Repeat the audit process for all other regions used.",
    "remediation": "From the Console: 1. Login to EC2 using https://console.aws.amazon.com/ec2/ 2. On the left Click NETWORK & SECURITY, click Network Interfaces. 3. Select the ENI that you want to remove 4. Click 'Actions', then 'delete' 5. Click Delete 6. Repeat steps 3 - 5 any other ENIs listed in the audit within the current region. NOTE Repeat the audit process for all other regions used. From the CLI 1. Run the delete-network-interface command with the ENI names collected above in the audit. aws ec2 delete-network-interface --region us-east-1 --network-interface-id eni-1234abcd 2. This will remove the ENI that is not being used. 3. Repeat steps 1 - 2 for any ENIs within the current region. NOTE Repeat the audit process for all other regions used.",
    "profile_applicability": "•  Level 1",
    "function_names": [
      "ec2"
    ]
  },
  {
    "id": "2.11",
    "title": "Ensure instances stopped for over 90 days are removed",
    "assessment": "Manual",
    "description": "Enable this rule to help with the baseline configuration of Amazon Elastic Compute Cloud (Amazon EC2) instances by checking whether Amazon EC2 instances have been stopped for more than the allowed number of days, according to your organization’s standards.",
    "rationale": "",
    "audit": "From the Console 1. Login to the EC2 console at https://console.aws.amazon.com/ec2/. 2. In the left pane, click Instances, click Instances. 3. Select the Instance for review. 4. Under the Details tab 5. Review the Launch time. If the Launch time of the selected Instance is greater than 90 days, the Instance has been offline and is considered outdated. 6. Repeat steps no. 3 – 5 to verify the Launch date for the other instances. Repeat all steps for the other regions. Refer to the remediation procedure below if any of the Launch times are over 90 days.",
    "remediation": "From the Console 1. Login to the EC2 console at https://console.aws.amazon.com/ec2/. 2. In the left pane, click Instances, click Instances. 3. Select the Instance for that hasn't been used for over 90 days. 4. Under the Details tab 5. Click Instance state, click Terminate instance. 6. Click Terminate. 7.Repeat steps no. 3 – 6 the other instances with a launch date equal to or over 90 days. Repeat all steps for the other regions. References: 1. https://docs.aws.amazon.com/config/latest/developerguide/ec2-stopped- instance.html",
    "profile_applicability": "•  Level 1",
    "references": "1. https://docs.aws.amazon.com/config/latest/developerguide/ec2-stopped- instance.html",
    "function_names": [
      "compute_instance_removed_over_90d",
      "ec2",
      "compute_instance_cleanup_old_stopped",
      "compute_instance_deleted_long_inactive"
    ]
  },
  {
    "id": "2.12",
    "title": "Ensure EBS volumes attached to an EC2 instance is marked for deletion upon instance termination",
    "assessment": "Manual",
    "description": "This rule ensures that Amazon Elastic Block Store volumes that are attached to Amazon Elastic Compute Cloud (Amazon EC2) instances are marked for deletion when an instance is terminated. If an Amazon EBS volume isn’t deleted when the instance that it’s attached to is terminated, it may violate the concept of least functionality.",
    "rationale": "",
    "audit": "From the Console: 1. Login to EC2 using https://console.aws.amazon.com/ec2/ 2. On the left Click INSTANCES, click Instances. 3. Select the EC2 instance you want to review. 4. Select the Storage tab. 5. Scroll down until you reach the 'Volume ID' and review the setting for 'Delete on termination' 6. If the value is set to No refer to the remediation below. 7. Repeat steps no. 3 – 6 to verify the setting. 8. Go through the other AWS regions and repeat the audit process for all instances. From the CLI 1. Run the describe-instances command aws ec2 describe-instances --region us-east-1 --output json --filters \"Name=block-device-mapping.delete-on-termination,Values=false\" --query \"Reservations[*].Instances[*].{Instance:InstanceId}\" 2. The output should be a list of instances that have not set 'Delete on termination'. 3. Make note of the list of instance ids and refer to the remediation below. 4. Repeat steps no. 1 -3 with the other AWS regions.",
    "remediation": "From the Console: 1. At this time the delete on termination setting for existing instances can only be changed using AWS CLI. From the CLI 1. Run the modify-instance-attribute command using the list of instances collected in the audit. aws ec2 modify-instance-attribute --instance-id i-123456abcdefghi0 --block- device-mappings \"[{\\\"DeviceName\\\": \\\"/dev/sda\\\",\\\"Ebs\\\":{\\\"DeleteOnTermination\\\":true}}]\" 2. Repeat steps no. 1 with the other instances discovered in all AWS regions. **Note - If you get any errors running the modify-instance-attribute command confirm the instance id and the Device Name for that instance is correct. The above command is referencing the typical default device name. References: 1. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/modify- instance-attribute.html 2. https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeInstan ces.html",
    "profile_applicability": "•  Level 1",
    "references": "1. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/modify- instance-attribute.html 2. https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeInstan ces.html",
    "function_names": [
      "compute_ebs_volume_delete_on_termination_enabled",
      "ec2",
      "ebs_volume_delete_on_termination_disabled",
      "compute_instance_ebs_volume_auto_delete_enabled"
    ]
  },
  {
    "id": "2.13",
    "title": "Ensure Secrets and Sensitive Data are not stored directly in EC2 User Data",
    "assessment": "Manual",
    "description": "User Data can be specified when launching an ec2 instance. Examples include specifying parameters for configuring the instance or including a simple script.",
    "rationale": "The user data is not protected by authentication or cryptographic methods. Therefore, sensitive data, such as passwords or long-lived encryption keys should not be stored as user data. Impact: Anyone who has access to the instance and configuration can view the user data.",
    "audit": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services and click EC2 under Compute. 3. Click on Instances. 4. For each instance, click Actions -> Instance Settings -> Edit user data 5. For each instance, review the user data to ensure there are no secrets or sensitive data stored. 6. If secrets or sensitive data is found, refer to the remediation below. 7. Repeat steps 2-7 for all regions used. From the Command line 1. Run aws ec2 describe-instances to retrieve information about all instances in the AWS region. The output will include instance ids. 2. Run aws ec2 describe-instance-attribute for each instance in AWS account. aws ec2 describe-instance-attribute --instance-id \"ID of instance\" --attribute userData Note: User Data may be Base64 encoded. Decode the output as necessary.  3. Review user data to ensure no secrets or sensitive information are stored. 4. Repeat the Audit for all the other AWS regions.",
    "remediation": "From the Console 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services and click EC2 under Compute. 3. Click on Instances. 4. If the instance is currently running, stop the instance first. Note: ensure there is no negative impact from stopping the instance prior to stopping the instance. 5. For each instance, click Actions -> Instance Settings -> Edit user data 6. For each instance, edit the user data to ensure there are no secrets or sensitive data stored. A Secret Management solution such as AWS Secrets Manager can be used here as a more secure mechanism of storing necessary sensitive data. 7. Repeat this remediation for all the other AWS regions. Note: If the ec2 instances are created via automation or infrastructure-as-code, edit the user data in those pipelines and code. References: 1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance- metadata.html",
    "profile_applicability": "•  Level 1",
    "impact": "Anyone who has access to the instance and configuration can view the user data.",
    "references": "1. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance- metadata.html",
    "function_names": [
      "ec2"
    ]
  },
  {
    "id": "2.14",
    "title": "Ensure EC2 Auto Scaling Groups Propagate Tags to EC2 Instances that it launches",
    "assessment": "Automated",
    "description": "Tags can help with managing, identifying, organizing, searching for, and filtering resources. Additionally, tags can help with security and compliance. Tags can be propagated from an Auto Scaling group to the EC2 instances that it launches.",
    "rationale": "Without tags, EC2 instances created via Auto Scaling can be without tags and could be out of compliance with security policy.",
    "audit": "AWS Console 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services and click EC2 under Compute. 3. Select Auto Scaling Groups. 4. For each Auto Scaling Group's Details, ensure that all tags have Tag new instances set to Yes. 5. Repeat Steps 1-4 for each AWS Region used. AWS CLI 1. Run aws autoscaling describe-auto-scaling-groups. 2. Ensure PropogateAtLaunch is true under Tags for each Tag for the Auto Scaling Group. 3. Repeat Steps 1-2 for each AWS Region used.",
    "remediation": "AWS Console 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services and click EC2 under Compute. 3. Select Auto Scaling Groups. 4. Click Edit for each Auto Scaling Group. 5. Check the Tag new instances Box for the Auto Scaling Group. 6. Click Update. 7. Repeat Steps 1-6 for each AWS Region used. AWS CLI 1. Run aws autoscaling create-or-update-tags for tags that are not set to PropogateAtLaunch for each Auto Scaling Group that does not have this property set to true. aws autoscaling create-or-update-tags \\ --tags ResourceId=example-autoscaling-group,ResourceType=auto-scaling- group,Key=TagKey,Value=TagValue,PropagateAtLaunch=true 2. Repeat Step 1 for each AWS Region used. References: 1. https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling- tagging.html Additional Information: Note: Tags may be specified via the launch template. The tag values for instances from the launch template will be overridden if there are any duplicate keys specified for the Auto Scaling group.",
    "profile_applicability": "•  Level 1",
    "references": "1. https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling- tagging.html Additional Information: Note: Tags may be specified via the launch template. The tag values for instances from the launch template will be overridden if there are any duplicate keys specified for the Auto Scaling group.",
    "function_names": [
      "ec2"
    ]
  },
  {
    "id": "3.1",
    "title": "Ensure Amazon ECS task definitions using 'host' network mode do not allow privileged or root user access to the host",
    "assessment": "Automated",
    "description": "Ensure that Amazon ECS task definitions using host network mode do not allow privileged or root user access. This protects the host container instance from unauthorized access and privilege escalation. Note: This recommendation assumes that only the latest active revision of a task definition is in use. If older revisions are in use, apply the audit and remediation procedures to those revisions as needed.",
    "rationale": "Combining host networking mode with privileged or root user access significantly increases the risk of container breakout, where a compromised container can gain control of the host system. Impact: There may be some administrative effort required to ensure Amazon ECS applications function as expected without privileged or root user access.",
    "audit": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Task definitions. 3. Click the name of a task definition. 4. Click on the latest active revision of the task definition. 5. If Network mode is set to host, click JSON. 6. For each element under containerDefinitions, ensure that privileged is set to false or is absent, and ensure that user is not set to root or is absent. 7. Repeat steps 1-6 for each task definition. From Command Line: Run the following command to list task definitions: aws ecs list-task-definitions For the latest revision of a task definition, run the following command: aws ecs describe-task-definition --task-definition <task-definition-arn> If networkMode is set to host, ensure that for each element under containerDefinitions, privileged is set to false or is absent, and ensure that user is not set to root or is absent. Repeat for each task definition.",
    "remediation": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Task definitions. 3. Click the name of a task definition. 4. Click on the latest active revision of the task definition. 5. Click Create new revision. 6. Click Create new revision with JSON. 7. For each element under containerDefinitions, set privileged to false, or remove \"privileged\": true. 8. For each element under containerDefinitions, set user to an appropriate non-root user, or remove \"user\": \"root\". 9. Click Create. 10. Repeat steps 1-9 for each task definition requiring remediation. Note: When a task definition is updated, running tasks launched from the previous task definition remain unchanged. Updating a running task requires redeploying it with the new task definition. Default Value: When creating a task definition with host network mode, the privileged and user parameters are unset by default. References: 1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition s.html 2. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition _parameters.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describ e-task-definition.html Additional Information: • AWS recommends using the awsvpc network mode unless you have a specific need to use a different network mode. • The privileged parameter is not supported for Windows containers or tasks using the Fargate launch type.",
    "profile_applicability": "•  Level 1",
    "impact": "There may be some administrative effort required to ensure Amazon ECS applications function as expected without privileged or root user access.",
    "references": "1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition s.html 2. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition _parameters.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describ e-task-definition.html Additional Information: • AWS recommends using the awsvpc network mode unless you have a specific need to use a different network mode. • The privileged parameter is not supported for Windows containers or tasks using the Fargate launch type.",
    "function_names": [
      "ecs",
      "ecs"
    ]
  },
  {
    "id": "3.2",
    "title": "Ensure 'assignPublicIp' is set to 'DISABLED' for Amazon ECS services",
    "assessment": "Automated",
    "description": "Ensure that assignPublicIp is set to DISABLED for Amazon ECS services, to restrict direct exposure of containers to the public internet.",
    "rationale": "Enabling public IP assignment could expose container application servers to unintended or unauthorized access. Impact: Disabling assignPublicIp introduces administrative, operational, and potential cost overhead due to the need to configure and maintain private networking and associated resources.",
    "audit": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Clusters. 3. Click the name of a cluster. 4. Under Services, click the name of a service. 5. Click Configuration and networking. 6. Under Network configuration, ensure Auto-assign public IP is set to Turned off. 7. Repeat steps 1-6 for each ECS cluster and service. From Command Line: Run the following command to list clusters: aws ecs list-clusters Run the following command to list services in a cluster: aws ecs list-services --cluster <cluster-arn> Run the following command to view the details of a service: aws ecs describe-services --cluster <cluster-arn> --services <service-arn> Under networkConfiguration > awsvpcConfiguration, ensure assignPublicIp is set to DISABLED. Repeat for each cluster and service.",
    "remediation": "From Command Line: For each service requiring remediation, run the following command to set assignPublicIp to DISABLED: aws ecs update-service --cluster <cluster-arn> --service <service-arn> -- network-configuration '{\"awsvpcConfiguration\":{\"subnets\":[\"<subnet- id>\"],\"securityGroups\":[\"<security-group-id>\"],\"assignPublicIp\":\"DISABLED\"}}' Default Value: By default, assignPublicIp is set to ENABLED. References: 1. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- clusters.html 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- services.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describ e-services.html 4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/update- service.html 5. https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_AwsVpcCo nfiguration.html",
    "profile_applicability": "•  Level 1",
    "impact": "Disabling assignPublicIp introduces administrative, operational, and potential cost overhead due to the need to configure and maintain private networking and associated resources.",
    "references": "1. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- clusters.html 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- services.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describ e-services.html 4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/update- service.html 5. https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_AwsVpcCo nfiguration.html",
    "function_names": [
      "ecs",
      "ecs"
    ]
  },
  {
    "id": "3.3",
    "title": "Ensure Amazon ECS task definitions do not have 'pidMode' set to 'host'",
    "assessment": "Automated",
    "description": "A process ID (PID) namespace isolates processes, preventing system processes from being visible to containers and allowing for PID reuse. Ensure that Amazon ECS task definitions are not configured to share a host's process namespace with their containers. Note: This recommendation assumes that only the latest active revision of a task definition is in use. If older revisions are in use, apply the audit and remediation procedures to those revisions as needed.",
    "rationale": "Setting the pidMode parameter to host shares the host's PID namespace with containers, allowing them to view and interact with all host processes. This reduces isolation and may lead to unauthorized access and manipulation of host processes by malicious or compromised containers.",
    "audit": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Task definitions. 3. Click the name of a task definition. 4. Click on the latest active revision of the task definition. 5. Click JSON. 6. If the pidMode parameter is present, ensure it is not set to host. 7. Repeat steps 1-6 for each task definition. From Command Line: Run the following command to list task definitions: aws ecs list-task-definitions For the latest revision of a task definition, run the following command: aws ecs describe-task-definition --task-definition <task-definition-arn> -- query 'taskDefinition.pidMode' Ensure that the command does not return \"host\". Repeat for each task definition.",
    "remediation": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Task definitions. 3. Click the name of a task definition. 4. Click on the latest active revision of the task definition. 5. Click Create new revision. 6. Click Create new revision with JSON. 7. Set pidMode to task, or remove the pidMode parameter as appropriate. 8. Click Create. 9. Repeat steps 1-8 for each task definition requiring remediation. Note: When a task definition is updated, running tasks launched from the previous task definition remain unchanged. Updating a running task requires redeploying it with the new task definition. Default Value: If no value is specified, the default is a private namespace for each container. References: 1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition _parameters.html 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- task-definitions.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describ e-task-definition.html",
    "profile_applicability": "•  Level 1",
    "references": "1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition _parameters.html 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- task-definitions.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describ e-task-definition.html",
    "function_names": [
      "ecs"
    ]
  },
  {
    "id": "3.4",
    "title": "Ensure Amazon ECS task definitions do not have 'privileged' set to 'true'",
    "assessment": "Automated",
    "description": "Ensure that Amazon ECS task definitions do not grant privileged access to the host container instance. Note: This recommendation assumes that only the latest active revision of a task definition is in use. If older revisions are in use, apply the audit and remediation procedures to those revisions as needed.",
    "rationale": "Restricting privileged access enhances security of the host container instance by maintaining isolation and reducing the risk of privilege escalation. Impact: There may be some administrative effort required to ensure Amazon ECS applications function as expected without privileged access.",
    "audit": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Task definitions. 3. Click the name of a task definition. 4. Click on the latest active revision of the task definition. 5. Click JSON. 6. For each element under containerDefinitions, ensure that privileged is set to false or is absent. 7. Repeat steps 1-6 for each task definition. From Command Line: Run the following command to list task definitions: aws ecs list-task-definitions For the latest revision of a task definition, run the following command: aws ecs describe-task-definition --task-definition <task-definition-arn> -- query 'taskDefinition.containerDefinitions[*].privileged' Ensure that the command does not return true. Repeat for each task definition.",
    "remediation": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Task definitions. 3. Click the name of a task definition. 4. Click on the latest active revision of the task definition. 5. Click Create new revision. 6. Click Create new revision with JSON. 7. For each element under containerDefinitions, set privileged to false, or remove \"privileged\": true. 8. Click Create. 9. Repeat steps 1-8 for each task definition requiring remediation. Note: When a task definition is updated, running tasks launched from the previous task definition remain unchanged. Updating a running task requires redeploying it with the new task definition. Default Value: By default, privileged is set to false. References: 1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition _parameters.html 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- task-definitions.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describ e-task-definition.html",
    "profile_applicability": "•  Level 1",
    "impact": "There may be some administrative effort required to ensure Amazon ECS applications function as expected without privileged access.",
    "references": "1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition _parameters.html 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- task-definitions.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describ e-task-definition.html",
    "function_names": [
      "ecs",
      "ecs"
    ]
  },
  {
    "id": "3.5",
    "title": "Ensure 'readonlyRootFilesystem' is set to 'true' for Amazon ECS task definitions",
    "assessment": "Automated",
    "description": "Ensure the readonlyRootFilesystem parameter is enabled in Amazon ECS task definitions to restrict write access to the filesystem. Note: This recommendation assumes that only the latest active revision of a task definition is in use. If older revisions are in use, apply the audit and remediation procedures to those revisions as needed.",
    "rationale": "Enabling readonlyRootFilesystem minimizes security risks by ensuring the container's filesystem cannot be altered unless specific read-write permissions are granted.",
    "audit": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Task definitions. 3. Click the name of a task definition. 4. Click on the latest active revision of the task definition. 5. Click JSON. 6. For each element under containerDefinitions, ensure readonlyRootFilesystem is set to true. 7. Repeat steps 1-6 for each task definition. From Command Line: Run the following command to list task definitions: aws ecs list-task-definitions For the latest revision of a task definition, run the following command: aws ecs describe-task-definition --task-definition <task-definition-arn> -- query 'taskDefinition.containerDefinitions[*].readonlyRootFilesystem' Ensure that the command returns only true. Repeat for each task definition.",
    "remediation": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Task definitions. 3. Click the name of a task definition. 4. Click on the latest active revision of the task definition. 5. Click Create new revision. 6. Click Create new revision with JSON. 7. For each element under containerDefinitions, set readonlyRootFilesystem to true. 8. Click Create. 9. Repeat steps 1-8 for each task definition requiring remediation. Note: When a task definition is updated, running tasks launched from the previous task definition remain unchanged. Updating a running task requires redeploying it with the new task definition. Default Value: By default, readonlyRootFilesystem is set to false. References: 1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition _parameters.html 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- task-definitions.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describ e-task-definition.html",
    "profile_applicability": "•  Level 1",
    "references": "1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition _parameters.html 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- task-definitions.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describ e-task-definition.html",
    "function_names": [
      "ecs"
    ]
  },
  {
    "id": "3.6",
    "title": "Ensure secrets are not passed as container environment variables in Amazon ECS task definitions",
    "assessment": "Automated",
    "description": "Ensure that sensitive secrets, such as AWS_ACCESS_KEY_ID, are not passed as environment variables in Amazon ECS task definitions. Use more secure methods, such as secrets management services like AWS Secrets Manager or AWS Systems Manager Parameter Store, to inject these credentials into containers. Note: This recommendation assumes that only the latest active revision of a task definition is in use. If older revisions are in use, apply the audit and remediation procedures to those revisions as needed.",
    "rationale": "Passing secrets as environment variables exposes them to potential compromise, as they can be easily accessed by any process running within the container or by unauthorized users. This practice can lead to the unintended leakage of sensitive information. Impact: There is some administrative overhead involved in configuring and integrating secrets management solutions.",
    "audit": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Task definitions. 3. Click the name of a task definition. 4. Click on the latest active revision of the task definition. 5. Click JSON. 6. For each element under containerDefinitions, ensure that the environment parameter does not contain AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, or ECS_ENGINE_AUTH_DATA. 7. Repeat steps 1-6 for each task definition. From Command Line: Run the following command to list task definitions: aws ecs list-task-definitions For the latest revision of a task definition, run the following command: aws ecs describe-task-definition --task-definition <task-definition-arn> -- query 'taskDefinition.containerDefinitions[*].environment[*].name' Ensure that the command does not contain AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, or ECS_ENGINE_AUTH_DATA. Repeat for each task definition.",
    "remediation": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Task definitions. 3. Click the name of a task definition. 4. Click on the latest active revision of the task definition. 5. Click Create new revision. 6. Click Create new revision with JSON. 7. For each element under containerDefinitions, in the environment parameter, remove any objects with a name matching AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, or ECS_ENGINE_AUTH_DATA. 8. Click Create. 9. Repeat steps 1-8 for each task definition requiring remediation. Note: When a task definition is updated, running tasks launched from the previous task definition remain unchanged. Updating a running task requires redeploying it with the new task definition. Default Value: By default, secrets are not present as container environment variables in task definitions. References: 1. https://docs.aws.amazon.com/systems-manager/latest/userguide/sysman- paramstore-su-create.html 2. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying- sensitive-data.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- task-definitions.html 4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describ e-task-definition.html",
    "profile_applicability": "•  Level 1",
    "impact": "There is some administrative overhead involved in configuring and integrating secrets management solutions.",
    "references": "1. https://docs.aws.amazon.com/systems-manager/latest/userguide/sysman- paramstore-su-create.html 2. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/specifying- sensitive-data.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- task-definitions.html 4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describ e-task-definition.html",
    "function_names": [
      "ecs"
    ]
  },
  {
    "id": "3.7",
    "title": "Ensure logging is configured for Amazon ECS task definitions",
    "assessment": "Automated",
    "description": "Configure logging for Amazon ECS task definitions to capture detailed application and container activity. Note: This recommendation assumes that only the latest active revision of a task definition is in use. If older revisions are in use, apply the audit and remediation procedures to those revisions as needed.",
    "rationale": "Logging facilitates effective monitoring, troubleshooting, and incident response, improving security and enabling rapid threat detection. Impact: Logging can incur costs for storage and processing, along with initial configuration and ongoing management.",
    "audit": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Task definitions. 3. Click the name of a task definition. 4. Click on the latest active revision of the task definition. 5. Click JSON. 6. Ensure that at least one element under containerDefinitions has a logConfiguration property defined, and that the value for logDriver is not null. 7. Repeat steps 1-6 for each task definition. From Command Line: Run the following command to list task definitions: aws ecs list-task-definitions For the latest revision of a task definition, run the following command: aws ecs describe-task-definition --task-definition <task-definition-arn> -- query 'taskDefinition.containerDefinitions[*].logConfiguration' Ensure that the command returns at least one logConfiguration object, and that the value for logDriver is not null. Repeat for each task definition.",
    "remediation": "From Console 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Task definitions. 3. Click the name of a task definition. 4. Click on the latest active revision of the task definition. 5. Click Create new revision. 6. Click Create new revision again. 7. For at least one container, under Logging > Log collection, check the box next to Use log collection and further configure the log collection options as needed. 8. Click Create. 9. Repeat steps 1-8 for each task definition requiring remediation. Note: When a task definition is updated, running tasks launched from the previous task definition remain unchanged. Updating a running task requires redeploying it with the new task definition. Default Value: Logging is enabled by default when a task definition is created via the console. References: 1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition _parameters.htm 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- task-definitions.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describ e-task-definition.html",
    "profile_applicability": "•  Level 1",
    "impact": "Logging can incur costs for storage and processing, along with initial configuration and ongoing management.",
    "references": "1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition _parameters.htm 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- task-definitions.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describ e-task-definition.html",
    "function_names": [
      "ecs",
      "ecs"
    ]
  },
  {
    "id": "3.8",
    "title": "Ensure Amazon ECS Fargate services are using the latest Fargate platform version",
    "assessment": "Automated",
    "description": "Ensure that Amazon ECS Fargate services use the latest Fargate platform version to benefit from the latest security enhancements, performance improvements, and feature updates.",
    "rationale": "Using the latest Fargate platform version ensures services benefit from up-to-date security patches and features. Impact: Updating to the latest Fargate platform version may require minor operational effort.",
    "audit": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Clusters. 3. Click the name of a cluster. 4. Under Services, from the Filter launch type drop-down menu, select FARGATE. 5. Click the name of a service. 6. Click Configuration and networking. 7. Under Service configuration, ensure Platform version is set to 1.4.0 or LATEST for Linux, or 1.0.0 or LATEST for Windows. 8. Repeat steps 1-7 for each ECS cluster and Fargate service. From Command Line: Run the following command to list clusters: aws ecs list-clusters Run the following command to list services in a cluster: aws ecs list-services --cluster <cluster-arn> Run the following command to view the details of a service: aws ecs describe-services --cluster <cluster-arn> --services <service-arn> -- query 'services[*].[platformFamily,platformVersion]' --output table Where platformFamily is Linux, ensure platformVersion is 1.4.0 or LATEST. Where platformFamily is Windows, ensure platformVersion is 1.0.0 or LATEST. Repeat for each cluster and service.",
    "remediation": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Clusters. 3. Click the name of a cluster. 4. Under Services, from the Filter launch type drop-down menu, select FARGATE. 5. Click the name of a service. 6. Click Update service. 7. Expand the Compute configuration (advanced) section. 8. Under Platform version, select LATEST from the drop-down menu. 9. Click Update. 10. Repeat steps 1-9 for each ECS cluster and Fargate service requiring remediation. From Command Line: For each service requiring remediation, run the following command to set platformVersion to LATEST: aws ecs update-service --cluster <cluster-arn> --service <service-arn> -- platform-version LATEST Default Value: The platform version for Fargate services is LATEST by default. References: 1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform- fargate.html 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- clusters.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- services.html 4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describ e-services.html",
    "profile_applicability": "•  Level 1",
    "impact": "Updating to the latest Fargate platform version may require minor operational effort.",
    "references": "1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/platform- fargate.html 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- clusters.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- services.html 4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describ e-services.html",
    "function_names": [
      "ecs"
    ]
  },
  {
    "id": "3.9",
    "title": "Ensure monitoring is enabled for Amazon ECS clusters",
    "assessment": "Automated",
    "description": "Enable AWS CloudWatch Container Insights for Amazon ECS clusters to monitor resource usage, performance, and application health through metrics and logs.",
    "rationale": "Monitoring ECS clusters with Container Insights improves visibility, supports faster issue detection, and enhances security by identifying anomalies and resource bottlenecks. Impact: Enabling AWS CloudWatch Container Insights for ECS clusters incurs costs for metrics, log ingestion, storage, and alarms.",
    "audit": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Clusters. 3. For each cluster listed in the CloudWatch monitoring column, ensure that Container Insights is displayed. From Command Line: Run the following command to list clusters: aws ecs list-clusters Run the following command to view the settings for a cluster: aws ecs describe-clusters --clusters <cluster-arn> --include SETTINGS --query 'clusters[*].settings' Ensure containerInsights is set to enabled or enhanced.",
    "remediation": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Clusters. 3. Click the name of a cluster. 4. Click Update cluster. 5. Under Monitoring, select the radio button next to Container Insights or `Container Insights with enhanced observability. 6. Click Update. 7. Repeat steps 1-6 for each ECS cluster requiring remediation. From Command Line: For each cluster requiring remediation, run the following command to enable containerInsights: aws ecs update-cluster-settings --cluster <cluster-arn> --settings name=containerInsights,value=enabled Default Value: Monitoring is disabled by default for Amazon ECS clusters. References: 1. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/ContainerIn sights.html 2. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/container- insights-detailed-ecs-metrics.html",
    "profile_applicability": "•  Level 2",
    "impact": "Enabling AWS CloudWatch Container Insights for ECS clusters incurs costs for metrics, log ingestion, storage, and alarms.",
    "references": "1. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/ContainerIn sights.html 2. https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/container- insights-detailed-ecs-metrics.html",
    "function_names": [
      "ecs"
    ]
  },
  {
    "id": "3.10",
    "title": "Ensure Amazon ECS services are tagged",
    "assessment": "Automated",
    "description": "Ensure all Amazon ECS services have resource tags to facilitate asset management, tracking, and compliance.",
    "rationale": "Consistent tagging supports compliance and helps identify unauthorized or misconfigured resources. Impact: There is minimal administrative overhead associated with implementing and maintaining resource tags.",
    "audit": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Clusters. 3. Click the name of a cluster. 4. Under Services, click the name of a service. 5. Click Tags. 6. Ensure at least one tag is listed that does not begin with aws:. Tags prefixed with aws: are AWS-managed. 7. Repeat steps 1-6 for each ECS cluster and service. From Command Line: Run the following command to list clusters: aws ecs list-clusters Run the following command to list services in a cluster: aws ecs list-services --cluster <cluster-arn> Run the following command to view the tags for a service: aws ecs list-tags-for-resource --resource-arn <service-arn> Ensure that tags are returned that do not begin with aws:. Tags prefixed with aws: are AWS-managed. Repeat for each cluster and service.",
    "remediation": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Clusters. 3. Click the name of a cluster. 4. Under Services, click the name of a service. 5. Click Tags. 6. Click Manage tags. 7. Click Add tag. 8. Provide a Key and optional Value for the tag. 9. Click Save. 10. Repeat steps 1-9 for each ECS cluster and service requiring remediation. Default Value: By default, Amazon ECS services are not tagged. References: 1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-using- tags.html 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- clusters.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- services.html 4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- tags-for-resource.html",
    "profile_applicability": "•  Level 1",
    "impact": "There is minimal administrative overhead associated with implementing and maintaining resource tags.",
    "references": "1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-using- tags.html 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- clusters.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- services.html 4. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- tags-for-resource.html",
    "function_names": [
      "ecs"
    ]
  },
  {
    "id": "3.11",
    "title": "Ensure Amazon ECS clusters are tagged",
    "assessment": "Automated",
    "description": "Ensure all Amazon ECS clusters have resource tags to facilitate asset management, tracking, and compliance.",
    "rationale": "Consistent tagging supports compliance and helps identify unauthorized or misconfigured resources. Impact: There is minimal administrative overhead associated with implementing and maintaining resource tags.",
    "audit": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Clusters. 3. Click the name of a cluster. 4. Click Tags. 5. Ensure at least one tag is listed that does not begin with aws:. Tags prefixed with aws: are AWS-managed. 6. Repeat steps 1-5 for each ECS cluster. From Command Line: Run the following command to list clusters: aws ecs list-clusters Run the following command to view the tags for a cluster: aws ecs list-tags-for-resource --resource-arn <service-arn> Ensure that tags are returned that do not begin with aws:. Tags prefixed with aws: are AWS-managed. Repeat for each cluster.",
    "remediation": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Clusters. 3. Click the name of a cluster. 4. Click Tags. 5. Click Manage tags. 6. Click Add tag. 7. Provide a Key and optional Value for the tag. 8. Click Save. 9. Repeat steps 1-8 for each ECS cluster requiring remediation. Default Value: By default, Amazon ECS clusters have only AWS-managed tags. References: 1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-using- tags.html 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- clusters.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- tags-for-resource.html",
    "profile_applicability": "•  Level 1",
    "impact": "There is minimal administrative overhead associated with implementing and maintaining resource tags.",
    "references": "1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-using- tags.html 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- clusters.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- tags-for-resource.html",
    "function_names": [
      "ecs"
    ]
  },
  {
    "id": "3.12",
    "title": "Ensure Amazon ECS task definitions are tagged",
    "assessment": "Automated",
    "description": "Ensure all Amazon ECS task definitions have resource tags to facilitate asset management, tracking, and compliance. Note: This recommendation assumes that only the latest active revision of a task definition is in use. If older revisions are in use, apply the audit and remediation procedures to those revisions as needed.",
    "rationale": "Consistent tagging supports compliance and helps identify unauthorized or misconfigured resources. Impact: There is minimal administrative overhead associated with implementing and maintaining resource tags.",
    "audit": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Task definitions. 3. Click the name of a task definition. 4. Click on the latest active revision of the task definition. 5. Click Tags. 6. Ensure at least one tag is listed that does not begin with aws:. Tags prefixed with aws: are AWS-managed. 7. Repeat steps 1-6 for each ECS task definition. From Command Line: Run the following command to list task definitions: aws ecs list-task-definitions For the latest revision of a task definition, run the following command to view the tags: aws ecs list-tags-for-resource --resource-arn <task-definition-arn> Ensure that tags are returned that do not begin with aws:. Tags prefixed with aws: are AWS-managed. Repeat for each task definition.",
    "remediation": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Task definitions. 3. Click the name of a task definition. 4. Click on the latest active revision of the task definition. 5. Click Create new revision. 6. Click Create new revision again. 7. Expand the Tags section. 8. Click Add tag. 9. Provide a Key and optional Value for the tag. 10. Click Create. 11. Repeat steps 1-10 for each task definition requiring remediation. Note: When a task definition is updated, running tasks launched from the previous task definition remain unchanged. Updating a running task requires redeploying it with the new task definition. Default Value: By default, Amazon ECS task definitions are not tagged. References: 1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-using- tags.html 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- task-definitions.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- tags-for-resource.html",
    "profile_applicability": "•  Level 1",
    "impact": "There is minimal administrative overhead associated with implementing and maintaining resource tags.",
    "references": "1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-using- tags.html 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- task-definitions.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- tags-for-resource.html",
    "function_names": [
      "ecs"
    ]
  },
  {
    "id": "3.13",
    "title": "Ensure only trusted images are used with Amazon ECS",
    "assessment": "Automated",
    "description": "Ensure that only trusted container images from verified sources or private repositories are used with Amazon ECS to maintain the integrity and security of workloads. Note: This recommendation assumes that only the latest active revision of a task definition is in use. If older revisions are in use, apply the audit and remediation procedures to those revisions as needed.",
    "rationale": "Using trusted images reduces the risk of vulnerabilities, malware, or unauthorized modifications compromising ECS tasks. Impact: Minor costs for scanning, storage, and administrative effort to enforce policies and manage approved images.",
    "audit": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Task definitions. 3. Click the name of a task definition. 4. Click on the latest active revision of the task definition. 5. Click JSON. 6. For each element under containerDefinitions, ensure that image is set to an image trusted by your organization. 7. Repeat steps 1-6 for each task definition. From Command Line: Run the following command to list task definitions: aws ecs list-task-definitions For the latest revision of a task definition, run the following command: aws ecs describe-task-definition --task-definition <task-definition-arn> -- query 'taskDefinition.containerDefinitions[*].image' Ensure that the command returns only images trusted by your organization. Repeat for each task definition.",
    "remediation": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Task definitions. 3. Click the name of a task definition. 4. Click on the latest active revision of the task definition. 5. Click Create new revision. 6. Click Create new revision with JSON. 7. For each element under containerDefinitions, set image to an appropriate image trusted by your organization. 8. Repeat steps 1-7 for each task definition requiring remediation. Note: When a task definition is updated, running tasks launched from the previous task definition remain unchanged. Updating a running task requires redeploying it with the new task definition. References: 1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/container- considerations.html 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- task-definitions.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describ e-task-definition.html",
    "profile_applicability": "•  Level 1",
    "impact": "Minor costs for scanning, storage, and administrative effort to enforce policies and manage approved images.",
    "references": "1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/container- considerations.html 2. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/list- task-definitions.html 3. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describ e-task-definition.html",
    "function_names": [
      "ecs"
    ]
  },
  {
    "id": "3.14",
    "title": "Ensure 'assignPublicIp' is set to 'DISABLED' for Amazon ECS task sets",
    "assessment": "Automated",
    "description": "Ensure that assignPublicIp is set to DISABLED for Amazon ECS task sets, to prevent task sets from being publicly accessible.",
    "rationale": "Enabling public IP assignment could expose task sets to unintended or unauthorized access. Impact: Disabling assignPublicIp introduces administrative, operational, and potential cost overhead due to the need to configure and maintain private networking and associated resources.",
    "audit": "From Command Line: Run the following command to list clusters: aws ecs list-clusters Run the following command to list services in a cluster: aws ecs list-services --cluster <cluster-arn> Run the following command to view the task sets for a service: aws ecs describe-task-sets --cluster <cluster-arn> --service <service-arn> For each task set, under networkConfiguration > awsvpcConfiguration, ensure assignPublicIp is set to DISABLED. Repeat for each cluster and service.",
    "remediation": "Default Value: By default, assignPublicIp is set to ENABLED. References: 1. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describ e-task-sets.html 2. https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_TaskSet.ht ml",
    "profile_applicability": "•  Level 1",
    "impact": "Disabling assignPublicIp introduces administrative, operational, and potential cost overhead due to the need to configure and maintain private networking and associated resources.",
    "references": "1. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/describ e-task-sets.html 2. https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_TaskSet.ht ml",
    "function_names": [
      "ecs"
    ]
  },
  {
    "id": "5.1",
    "title": "Apply updates to any apps running in Lightsail",
    "assessment": "Manual",
    "description": "Amazon Lightsail is a virtual private server (VPS) provider and is the easiest way to get started with AWS for developers, small businesses, students, and other users who need a solution to build and host their applications on cloud.",
    "rationale": "Lightsail offers a range of operating system and application templates that are automatically installed when you create a new Lightsail instance. Application templates include WordPress, Drupal, Joomla!, Ghost, Magento, Redmine, LAMP, Nginx (LEMP), MEAN, Node.js, Django, and more. You can install additional software on your instances by using the in-browser SSH or your own SSH client.",
    "audit": "To confirm that you are running the latest version of the application you are using is a manual process. Often dependent on the application itself and the operating system you are utilizing for the Lightsail instance. From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Lightsail under Compute. 3. This will open up the Lightsail console. 4. Select the Instance you want to review. 5. Make sure the instance status is running. 6. Connect to the instance. 7. Depending on the instance OS and the application you are running determine what version it is and if there are any updates. 8. If there are updates refer to the remediation below. 9. Repeat steps no. 4 – 8 to verify if any Lightsail instances require application updates.",
    "remediation": "To process and apply the latest updates for the application you are using is a manual process. Often dependent on the application itself and the operating system you are utilizing for the Lightsail instance. From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Lightsail under Compute. 3. This will open up the Lightsail console. 4. Select the Instance you want to update. 5. Make sure the instance status is running. 6. Click on Snapshots 7. Under Manual snapshots click on + Create snapshot 8. Give it a name you will recognize 9. Click on create while in process it will show 'Snapshotting...' 10. Once the date and time and snapshot name appears it is completed. 11. Click on Connect 12. Run the updates for the application discovered above in the Audit. 13. Repeat steps no. 4 – 12 to apply any application updates required on the Lightsail instances that you are running. References: 1. https://lightsail.aws.amazon.com/ls/docs/en_us/overview 2. https://aws.amazon.com/lightsail/features/?opdp2=features/?pg=ln&sec=hs",
    "profile_applicability": "•  Level 1",
    "references": "1. https://lightsail.aws.amazon.com/ls/docs/en_us/overview 2. https://aws.amazon.com/lightsail/features/?opdp2=features/?pg=ln&sec=hs",
    "function_names": [
      "lightsail_instance_updates_applied",
      "lightsail_instance_patch_compliance",
      "lightsail_instance_security_updates_current",
      "lightsail_instance_os_updates_installed",
      "lightsail_instance_software_up_to_date",
      "lightsail_instance_vulnerability_patches_applied",
      "lightsail_instance_maintenance_updates_enabled"
    ]
  },
  {
    "id": "5.2",
    "title": "Change default Administrator login names and passwords for applications",
    "assessment": "Manual",
    "description": "Change the default settings for the administrator login names and passwords of the application software that you install on Lightsail instances.",
    "rationale": "Default administrator login names and passwords for applications used on Lightsail instances can be used by hackers and individuals to break into your servers.",
    "audit": "To confirm that you have updated or changed the default administrator name and password for any application you are using is a manual process. Often dependent on the application itself and the operating system you are utilizing for the Lightsail instance. From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Lightsail under Compute. 3. This will open up the Lightsail console. 4. Select the Instance you want to review. 5. Make sure the instance status is running. 6. Connect to the instance. 7. Depending on the instance OS and the application you are running determine what the default administrator name is set to and what the password is. 8. If the default administrator username and or password is still at the default settings please refer to the remediation below. 9. Repeat steps no. 4 – 8 to verify if any Lightsail instances require application updates.",
    "remediation": "To process and apply the latest updates for the application you are using is a manual process. Often dependent on the application itself and the operating system you are utilizing for the Lightsail instance. From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Lightsail under Compute. 3. This will open up the Lightsail console. 4. Select the Instance you want to update the default administrator settings. 5. Make sure the instance status is running. 6. Click on Snapshots 7. Under Manual snapshots click on + Create snapshot 8. Give it a name you will recognize 9. Click on create while in process it will show Snapshotting... 10. Once the date and time and snapshot name appears it is completed. 11. Click on Connect 12. Run the process to change either the default administrator name or password or both. 13. Repeat steps no. 4 – 12 to apply any application default administrator changes required on the Lightsail instances that you are running. References: 1. https://lightsail.aws.amazon.com/ls/docs/en_us/all",
    "profile_applicability": "•  Level 1",
    "references": "1. https://lightsail.aws.amazon.com/ls/docs/en_us/all",
    "function_names": [
      "lightsail_instance_default_admin_credentials_changed",
      "lightsail_application_admin_login_renamed",
      "lightsail_application_admin_password_changed",
      "lightsail_instance_admin_credentials_customized",
      "lightsail_application_default_credentials_modified"
    ]
  },
  {
    "id": "5.3",
    "title": "Disable SSH and RDP ports for Lightsail instances when not needed.",
    "assessment": "Manual",
    "description": "Any ports enable within Lightsail by default are open and exposed to the world. For SSH and RDP access you should remove and disable these ports when not is use.",
    "rationale": "Any ports enable within Lightsail by default are open and exposed to the world. This can result in outside traffic trying to access or even deny access to the Lightsail instances. Removing and disabling a protocol when not in use even if restricted by IP address is the safest solution especially when it is not required for access.",
    "audit": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Lightsail under Compute. 3. This will open up the Lightsail console. 4. Select the Windows or Linux Instance you want to review. 5. Go to the Networking section. 6. If it is a Windows instance confirm that SSH has been removed. If it is a Linux instance confirm RDP has been removed. 7. If either still exists in the IPV4 Firewall list refer to the remediation below. 8. If the server needs HTTP, TCP Port 80 confirm that the application forwards Port 80 to HTTPS, TCP Port 443. 9. If the server does not need HTTP refer to the remediation below. 10. Confirm that there are no other unused or unneeded ports. 11. If the system has other ports that are not required or in use refer to the remediation below. From the Command Line: 1. Run aws lightsail get-instances aws lightsail get-instances --query \"instances[*].name\" This command will provide a list of Instance names. \"WordPress-1\", \"Windows_Server_2019-1\" 2. Run aws lightsail get-instance-port-states for each instance listed above aws lightsail get-instance-port-states --instance-name <instance_name> This command will provide a list of available Ports for the Instance name. \"portStates\": [ { \"fromPort\": 80, \"toPort\": 80, \"protocol\": \"tcp\", \"state\": \"open\", \"cidrs\": [ \"0.0.0.0/0\" ], \"cidrListAliases\": [] }, { \"fromPort\": 22, \"toPort\": 22, \"protocol\": \"tcp\", \"state\": \"open\", \"cidrs\": [ \"0.0.0.0/0\" ], \"cidrListAliases\": [] }, { \"fromPort\": 443, \"toPort\": 443, \"protocol\": \"tcp\", \"state\": \"open\", \"cidrs\": [ \"0.0.0.0/0\" ], \"cidrListAliases\": [] If it is a Linux host and has Port 3398 listed, HTTP Port 80 listed or any other ports listed that are not required refer to the remediation below. If it is a Windows host and has Port 22 listed, HTTP Port 80 listed or any other ports listed that are not required refer to the remediation below.",
    "remediation": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Lightsail under Compute. 3. This will open up the Lightsail console. 4. Select the Windows or Linux Instance you want to review. 5. Go to the Networking section. 6. If it is a Windows instance confirm that SSH has been removed. If it is a Linux instance confirm RDP has been removed. 7. If either ssh(Port 22) is in the Windows system and RDP(Port 3389) is in the Linux system click the bucket icon to delete it. 8. If the server needs HTTP, TCP Port 80 confirm that the application forwards Port 80 to HTTPS, TCP Port 443. 9. If the server does not need HTTP click the bucket icon to delete it. 10. Confirm that there are no other unused or unneeded ports. 11. If the system has other ports that are not required or in use click the bucket icon to delete it. From the Command Line: 1. Run aws lightsail close-instance-public-ports For Windows: aws lightsail close-instance-public-ports --instance-name <Windows_Instance_Name> --port-info fromPort=22,protocol=TCP,toPort=22 For Linux: aws lightsail close-instance-public-ports --instance-name <Linux_Instance_Name> --port-info fromPort=3389,protocol=TCP,toPort=3389 For HTTP: aws lightsail close-instance-public-ports --instance-name <ANY_Instance_Name> --port-info fromPort=80,protocol=TCP,toPort=80 2. Repeat for all instance names identified in the audit that have SSH, RDP or HTTP's open and are not required based on the OS or the use of the system. References: 1. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/lightsail/ind ex.html#cli-aws-lightsail",
    "profile_applicability": "•  Level 1",
    "references": "1. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/lightsail/ind ex.html#cli-aws-lightsail",
    "function_names": [
      "lightsail_instance_ssh_disabled",
      "lightsail_instance_rdp_disabled",
      "lightsail_instance_unused_ports_closed",
      "lightsail_instance_default_ports_restricted",
      "lightsail_instance_remote_access_disabled"
    ]
  },
  {
    "id": "5.4",
    "title": "Ensure SSH is restricted to only IP address that should have this access.",
    "assessment": "Manual",
    "description": "Any ports enable within Lightsail by default are open and exposed to the world. For SSH and RDP access you should identify which IP address need access.",
    "rationale": "Any ports enable within Lightsail by default are open and exposed to the world. This can result in outside traffic trying to access or even deny access to the Lightsail instances. Removing and adding approved IP address required for access.",
    "audit": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Lightsail under Compute. 3. This will open up the Lightsail console. 4. Select the Linux Instance you want to review. 5. Go to the Networking section. 6. Confirm that the SSH Port is restricted to an IP address Application Protocol Port or range / Code Restricted to SSH  TCP  22   101.221.11.11 7. If SSH is needed and it is open to Any IPv4 address refer to the remediation below. From the Command Line: 1. Run aws lightsail get-instances aws lightsail get-instances --query \"instances[*].name\" This command will provide a list of Instance names. \"WordPress-1\", \"Windows_Server_2019-1\"  2. Run aws lightsail get-instance-port-states for any Linux instances listed aws lightsail get-instance-port-states --instance-name <instance_name> This command will provide a list of available Ports for the Instance name. { \"fromPort\": 22, \"toPort\": 22, \"protocol\": \"tcp\", \"state\": \"open\", \"cidrs\": [ \"0.0.0.0/0\" \"101.221.11.11/32\" ], \"cidrListAliases\": [] }, 3. Review the Port 22 settings and confirm that the only IP Addresses that should have access to the instance are listed in the cidrs as shown above. 4. If it is open to all ports (0.0.0.0/0) of there is an IP address listed that shouldn't have access refer to the remediation below.",
    "remediation": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Lightsail under Compute. 3. This will open up the Lightsail console. 4. Select the Linux Instance you want to review. 5. Go to the Networking section. 6. Under IPv4 networking find the SSH rule as shown below. Application Protocol Port or range / Code Restricted to SSH  TCP  22   Any IPv4 address  7. Click on the edit icon 8. Click on the check box next to Restrict to IP address 9. Under Source IP address (192.0.2.0) or range (192.0.2.0- 192.0.2.255 or 192.0.2.0/24) type the IP address' you want. From the Command Line: 1. Run aws lightsail put-ins aws lightsail put-instance-public-ports --instance-name <instance_name> -- port-info fromPort=22,protocol=TCP,toPort=22,cidrs=110.111.221.100/32,110.111.221.202/3 2 This command will enter the IP addresses that should have access to the instances identified above in the Audit. 2. Run aws lightsail get-instance-port-states for the Linux instance to confirm the new setting. aws lightsail get-instance-port-states --instance-name <instance_name> This command will provide a list of available Ports and show how the cidr value for Port 22 is now set. { \"fromPort\": 22, \"toPort\": 22, \"protocol\": \"tcp\", \"state\": \"open\", \"cidrs\": [ \"110.111.221.100/32\", \"110.111.221.202/32\" ], \"cidrListAliases\": [] },  3. Repeat the remediation below for all other instances identified in the Audit. References: 1. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/lightsail/ind ex.html#cli-aws-lightsail",
    "profile_applicability": "•  Level 1",
    "references": "1. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/lightsail/ind ex.html#cli-aws-lightsail",
    "function_names": [
      "lightsail_instance_ssh_restricted_to_approved_ips",
      "lightsail_instance_rdp_restricted_to_approved_ips",
      "lightsail_instance_ingress_restricted_to_approved_ips",
      "lightsail_firewall_ssh_restricted_to_approved_ips",
      "lightsail_firewall_rdp_restricted_to_approved_ips",
      "lightsail_firewall_ingress_restricted_to_approved_ips",
      "lightsail_networking_ssh_restricted_to_approved_ips",
      "lightsail_networking_rdp_restricted_to_approved_ips"
    ]
  },
  {
    "id": "5.5",
    "title": "Ensure RDP is restricted to only IP address that should have this access.",
    "assessment": "Manual",
    "description": "Any ports enable within Lightsail by default are open and exposed to the world. For SSH and RDP access you should identify which IP address need access.",
    "rationale": "Any ports enable within Lightsail by default are open and exposed to the world. This can result in outside traffic trying to access or even deny access to the Lightsail instances. Removing and adding approved IP address required for access.",
    "audit": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Lightsail under Compute. 3. This will open up the Lightsail console. 4. Select the Windows Instance you want to review. 5. Go to the Networking section. 6. Confirm that the RDP Port is restricted to an IP address Application Protocol Port or range / Code Restricted to RDP  TCP  3389   101.221.11.11 7. If RDP is needed and it is open to Any IPv4 address refer to the remediation below. From the Command Line: 1. Run aws lightsail get-instances aws lightsail get-instances --query \"instances[*].name\" This command will provide a list of Instance names. \"WordPress-1\", \"Windows_Server_2019-1\"  2. Run aws lightsail get-instance-port-states for any Windows instances listed aws lightsail get-instance-port-states --instance-name <instance_name> This command will provide a list of available Ports for the Instance name. { \"fromPort\": 3389, \"toPort\": 3389, \"protocol\": \"tcp\", \"state\": \"open\", \"cidrs\": [ \"0.0.0.0/0\" ], \"cidrListAliases\": [] }, 3. Review the Port 22 settings and confirm that the only IP Addresses that should have access to the instance are listed in the cidrs as shown above. 4. If it is open to all ports (0.0.0.0/0) of there is an IP address listed that shouldn't have access refer to the remediation below.",
    "remediation": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Lightsail under Compute. 3. This will open up the Lightsail console. 4. Select the Windows Instance you want to review. 5. Go to the Networking section. 6. Under IPv4 networking find the SSH rule as shown below. Application Protocol Port or range / Code Restricted to RDP  TCP  3389   Any IPv4 address 7. Click on the edit icon 8. Click on the check box next to Restrict to IP address 9. Under Source IP address (192.0.2.0) or range (192.0.2.0- 192.0.2.255 or 192.0.2.0/24) type the IP address' you want.  From the Command Line: 1. Run aws lightsail put-ins aws lightsail put-instance-public-ports --instance-name <instance_name> -- port-info fromPort=3389,protocol=TCP,toPort=3389,cidrs=110.111.221.100/32,110.111.221.2 02/32 This command will enter the IP addresses that should have access to the instances identified above in the Audit. 2. Run aws lightsail get-instance-port-states for the Windows instance to confirm the new setting. aws lightsail get-instance-port-states --instance-name <instance_name> This command will provide a list of available Ports and show how the cidr value for Port 3389 is now set. \"portStates\": [ { \"fromPort\": 3389, \"toPort\": 3389, \"protocol\": \"tcp\", \"state\": \"open\", \"cidrs\": [ \"110.111.221.100/32\", \"110.111.221.202/32\" ], \"cidrListAliases\": [] } 3. Repeat the remediation below for all other Windows instances identified in the Audit. References: 1. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/lightsail/ind ex.html#cli-aws-lightsail",
    "profile_applicability": "•  Level 1",
    "references": "1. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/lightsail/ind ex.html#cli-aws-lightsail",
    "function_names": [
      "lightsail_instance_rdp_restricted_to_allowed_ips",
      "lightsail_instance_ssh_restricted_to_allowed_ips",
      "lightsail_instance_ingress_restricted_to_allowed_ips",
      "lightsail_firewall_rdp_restricted_to_allowed_ips",
      "lightsail_firewall_ssh_restricted_to_allowed_ips",
      "lightsail_network_rdp_access_controlled",
      "lightsail_network_ssh_access_controlled",
      "lightsail_instance_public_access_restricted",
      "lightsail_firewall_public_access_restricted",
      "lightsail_instance_ingress_rules_restricted"
    ]
  },
  {
    "id": "5.6",
    "title": "Disable IPv6 Networking if not in use within your organization.",
    "assessment": "Manual",
    "description": "Any protocols enable within Lightsail by default that aren't being used should be disabled.",
    "rationale": "Any ports enable within Lightsail by default are open and exposed to the world. This can result in outside traffic trying to access or even deny access to the Lightsail instances. Removing and disabling a protocol when not in use even if restricted by IP address is the safest solution especially when it is not required for access.",
    "audit": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Lightsail under Compute. 3. This will open up the Lightsail console. 4. Select the Windows or Linux Instance you want to review. 5. Go to the Networking section. 6. Under IPv6 networking confirm that it reads IPv6 networking is disabled. 7. If it reads IPv6 networking is enabled refer to the remediation below.",
    "remediation": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Lightsail under Compute. 3. This will open up the Lightsail console. 4. Select the Windows or Linux Instance you want to review. 5. Go to the Networking section. 6. Under IPv6 networking click on the check mark next to IPv6 networking is enabled. 7. In the Disable IPv6 for this instance? 8. Click on Yes, disable",
    "profile_applicability": "•  Level 1",
    "function_names": [
      "lightsail_instance_ipv6_disabled",
      "lightsail_networking_unused_protocols_disabled",
      "lightsail_instance_unused_networking_disabled",
      "lightsail_ipv6_unused_disabled",
      "lightsail_networking_ipv6_disabled_if_unused"
    ]
  },
  {
    "id": "5.7",
    "title": "Ensure you are using an IAM policy to manage access to buckets in Lightsail.",
    "assessment": "Manual",
    "description": "The following policy grants a user access to manage a specific bucket in the Amazon Lightsail object storage service.",
    "rationale": "This policy grants access to buckets through the Lightsail console, the AWS Command Line Interface (AWS CLI), AWS API, and AWS SDKs. Impact: Users who don't have this policy will experience errors when viewing the Objects tab of the bucket management page in the Lightsail console.",
    "audit": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click IAM under Security, Identity, & Compliance. 3. Click Policies 4. Click in the Filter policies by property or policy name and press enter 5. Type Lightsail and press enter 6. Click on the policy that contains lightsail in the name 7. Make sure the Permissions tab is selected. 8. Confirm the policy looks like this { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"LightsailAccess\", \"Effect\": \"Allow\", \"Action\": \"lightsail:*\", \"Resource\": \"*\" }, { \"Sid\": \"S3BucketAccess\", \"Effect\": \"Allow\", \"Action\": \"s3:*\", \"Resource\": [ \"arn:aws:s3:::<BucketName>/*\", \"arn:aws:s3:::<BucketName>\" ] } ] } 9. If this policy is in place move to the next step. If it is not in any of the policies listed for lightsail refer to the remediation below. 10. Click on the Policy usage tab 11. Confirm that the correct Group and/or User is listed under Permissions. If there is no one listed here refer to the remediation below.",
    "remediation": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click IAM under Security, Identity, & Compliance. 3. Click Policies 4. Click Create policy 5. Click on the JSON tab 6. Copy and paste the policy below into the JSON editor replacing the text in there and filling in the Lightsail bucket names. **You can find the Lightsail bucket name in the Lightsail console, Storage, Under buckets. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"LightsailAccess\", \"Effect\": \"Allow\", \"Action\": \"lightsail:*\", \"Resource\": \"*\" }, { \"Sid\": \"S3BucketAccess\", \"Effect\": \"Allow\", \"Action\": \"s3:*\", \"Resource\": [ \"arn:aws:s3:::<BucketName>/*\", \"arn:aws:s3:::<BucketName>\" ] } ] } 7. Click Next tags 8. Add tags based on your companies outlined Tagging policy that should be in place based on the AWS Foundations Benchmark. 9. Click Next review 10. Click in Name* and give it a name that contains \"Lightsail\" 11. Review the summary. 12. Click Create policy 13. Click in the Filter policies by property or policy name and press enter 14. Type Lightsail and press enter 15. Click on the Policy name that you just created. 16. Click on the Policy usage tab 17. Click Attach 18. Add in the Users or Group that should have this permission. 19. Click Attach policy References: 1. https://lightsail.aws.amazon.com/ls/docs/en_us/articles/amazon-lightsail-bucket- management-policies",
    "profile_applicability": "•  Level 1",
    "impact": "Users who don't have this policy will experience errors when viewing the Objects tab of the bucket management page in the Lightsail console.",
    "references": "1. https://lightsail.aws.amazon.com/ls/docs/en_us/articles/amazon-lightsail-bucket- management-policies",
    "function_names": [
      "lightsail_bucket_iam_policy_restricted",
      "lightsail_bucket_access_managed_by_iam",
      "lightsail_bucket_no_public_access"
    ]
  },
  {
    "id": "5.8",
    "title": "Ensure Lightsail instances are attached to the buckets",
    "assessment": "Manual",
    "description": "Attaching an Amazon Lightsail instance to a Lightsail storage bucket gives it full programmatic access to the bucket and its objects.",
    "rationale": "When you attach instances to buckets, you don't have to manage credentials like access keys. Resource access is ideal if you're configuring software or a plugin on your instance to upload files directly to your bucket. For example, if you want to configure a WordPress instance to store media files on a bucket configuration with bucket storage resource access allows for that securely. Impact: You can attach instances that are in a running state only. Additionally, the instances have to be in the same AWS Region as the bucket or the buckets have to be in the same region as the instances.",
    "audit": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Lightsail under Compute. 3. This will open up the Lightsail console. 4. Select Storage. 5. All Lightsail buckets are listed here. 6. Click on a bucket name 7. Click Permissions. 8. Scroll down to Resource access and confirm that your instance is attached. 9. If the instance using this Storage bucket is not attached refer to the remediation below. From the Command Line: 1. Run aws lightsail get-buckets aws lightsail get-buckets This command will provide a list of Buckets tied to Lightsail.  2. If there are no buckets listed then refer to the remediation below.",
    "remediation": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Lightsail under Compute. 3. This will open up the Lightsail console. 4. Confirm that the instance you want to connect to the Storage bucket is in a running state 5. If it is move on to Step 6. If it is not click on the instance name, then click on Start. Wait for the status to read Running 6. Select Storage. 7. All Lightsail buckets are listed here. 8. Click on the bucket you want to associate with the instances. 9. Click Permissions. 10. Scroll down to Resource access. 11. Click on Attach instance 12. Click on Choose an instance 13. Select the instance 14. Click Attach 15. Repeat this for any other instances and buckets that need to be attached. From the Command Line: 1. Run aws lightsail create-bucket aws lightsail create-bucket --bucket-name test-cli-bucket2 --bundle-id small_1_0 This command will create a bucket. If you want to review the bundle size ids run this command. aws lightsail get-bucket-bundles \"bundles\": [ { \"bundleId\": \"small_1_0\", \"name\": \"Object Storage 5GB\", \"price\": 1.0, \"storagePerMonthInGb\": 5, \"transferPerMonthInGb\": 25, \"isActive\": true }, { \"bundleId\": \"medium_1_0\", \"name\": \"Object Storage 100GB\", \"price\": 3.0, \"storagePerMonthInGb\": 100, \"transferPerMonthInGb\": 250, \"isActive\": true }, { \"bundleId\": \"large_1_0\", \"name\": \"Object Storage 250GB\", \"price\": 5.0, \"storagePerMonthInGb\": 250, \"transferPerMonthInGb\": 500, \"isActive\": true Change the \"bundleId\" to the size of storage you need. Repeat and create all the S3 buckets that you need for Lightsail. References: 1. https://lightsail.aws.amazon.com/ls/docs/en_us/articles/amazon-lightsail- configuring-bucket-resource-access",
    "profile_applicability": "•  Level 1",
    "impact": "You can attach instances that are in a running state only. Additionally, the instances have to be in the same AWS Region as the bucket or the buckets have to be in the same region as the instances.",
    "references": "1. https://lightsail.aws.amazon.com/ls/docs/en_us/articles/amazon-lightsail- configuring-bucket-resource-access",
    "function_names": [
      "lightsail_instance_bucket_attached",
      "lightsail_instance_bucket_access_configured",
      "lightsail_instance_bucket_full_access_enabled",
      "lightsail_instance_bucket_programmatic_access_verified",
      "lightsail_instance_bucket_association_required"
    ]
  },
  {
    "id": "5.9",
    "title": "Ensure that your Lightsail buckets are not publicly accessible",
    "assessment": "Manual",
    "description": "You can make all objects private, public (read-only) or private while making individual objects public (read-only). By default when creating a bucket the permissions are set to \"All objects are private\".",
    "rationale": "When the Bucket access permissions are set to All objects are public (read-only) – All objects in the bucket are readable by anyone on the internet through the URL of the bucket.",
    "audit": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Lightsail under Compute. 3. This will open up the Lightsail console. 4. Select Storage. 5. All Lightsail buckets are listed here. 6. Underneath the bucket name and size there are 3 possible statements: All objects are private All objects are public (read-Only) Individual objects can be public 7. If any buckets are set to All objects are public (read-Only) and or 'Individual objects can be public' refer to the remediation below. From the Command Line: 1. Run aws lightsail get-buckets aws lightsail get-buckets This command will provide a list of Buckets tied to Lightsail. 2. Review the accessRules, getobject and allowPublicOverrides. \"accessRules\": { \"getObject\": \"private\", \"allowPublicOverrides\": false 4. If it reads \"getObject\": \"public\" or \"allowPublicOverrides\": true please make note \"name\" of the bucket also listed in the output. 5. Then refer to the remediation below.",
    "remediation": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Lightsail under Compute. 3. This will open up the Lightsail console. 4. Select Storage. 5. All Lightsail buckets are listed here. 6. Click on the bucket name that has All objects are public (read-Only) listed. 7. Click on Permissions 8. Click on Change permissions 9. Select All objects are private 10. Click Save 11. Repeat for any other Buckets within Lightsail that are set with All objects are public (read-Only) and/or Individual objects can be made public and read only From the Command Line: 1. Run aws lightsail update-bucket aws lightsail update-bucket --bucket-name <name from list in audit> --access- rules getObject=\"private\",allowPublicOverrides=false 2. The confirmation that the change was made will print out after running that command. 3. Repeat for any other buckets listed in the audit. References: 1. https://lightsail.aws.amazon.com/ls/docs/en_us/articles/amazon-lightsail- understanding-bucket-permissions",
    "profile_applicability": "•  Level 1",
    "references": "1. https://lightsail.aws.amazon.com/ls/docs/en_us/articles/amazon-lightsail- understanding-bucket-permissions",
    "function_names": [
      "lightsail_bucket_no_public_access",
      "lightsail_bucket_private_by_default",
      "lightsail_bucket_restrict_public_objects",
      "lightsail_bucket_block_public_acls",
      "lightsail_bucket_ignore_public_acls",
      "lightsail_bucket_no_public_read_access",
      "lightsail_bucket_no_public_write_access",
      "lightsail_bucket_no_public_list_access",
      "lightsail_bucket_no_public_permissions",
      "lightsail_bucket_enforce_private_objects"
    ]
  },
  {
    "id": "5.10",
    "title": "Enable storage bucket access logging",
    "assessment": "Manual",
    "description": "Access logging provides detailed records for the requests that are made to this bucket. This information can include the request type, the resources that are specified in the request, and the time and date that the request was processed. Access logs are useful for many applications.",
    "rationale": "Access log information is useful in security and access audits.",
    "audit": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Lightsail under Compute. 3. This will open up the Lightsail console. 4. Select Storage. 5. All Lightsail buckets are listed here. 6. Click on a bucket name 7. Click Logging. 8. Confirm that Access logging is set to active. If it is set to inactive refer to the remediation below.",
    "remediation": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Lightsail under Compute. 3. This will open up the Lightsail console. 4. Select Storage. 5. All Lightsail buckets are listed here. 6. Click on a bucket name 7. Click Logging. 8. Click on the X next to Access logging is inactive 9. Select a different bucket specific to store the logging information. 10. Note the path or create a path that matches your organization style. 11. Click save 12. Click OK 13. Repeat steps 6-12 for all Lightsail buckets. References: 1. https://lightsail.aws.amazon.com/ls/docs/en_us/articles/amazon-lightsail- enabling-bucket-access-logs",
    "profile_applicability": "•  Level 1",
    "references": "1. https://lightsail.aws.amazon.com/ls/docs/en_us/articles/amazon-lightsail- enabling-bucket-access-logs",
    "function_names": [
      "storage_bucket_access_logging_enabled",
      "storage_bucket_logging_enabled_all_regions",
      "storage_bucket_request_logging_enabled",
      "storage_bucket_access_logging_retention_over_90d",
      "storage_bucket_logging_destination_configured"
    ]
  },
  {
    "id": "5.11",
    "title": "Ensure your Windows Server based lightsail instances are updated with the latest security patches.",
    "assessment": "Manual",
    "description": "Windows server based Lightsail instances are still managed by the consumer and any security updates or patches have to be installed and maintained by the user.",
    "rationale": "Windows Server-based Lightsail instances need to be updated with the latest security patches so they are not vulnerable to attacks. Be sure your server is configured to download and install updates.",
    "audit": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Lightsail under Compute. 3. This will open up the Lightsail console. 4. Select the Windows Instance you want to review. 5. Make sure the instance status is running. 6. Connect to the instance using Connect using RDP. 7. Log in using the credentials you have set for this instance. 8. Open a command prompt 9. Type sconfig, and then press Enter. Windows Update Settings are at number 5 and by default are set to Automatic. If this is the current setting continue with step 10. If this is not the current setting refer to the remediation below and start at step 10. 10. To determine if any updates are required, type 6, and then press Enter. 11. Type A to search for (A)ll updates in the new command window, and then press Enter. If any updates are required refer to the remediation below and start at step 14.",
    "remediation": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Lightsail under Compute. 3. This will open up the Lightsail console. 4. Select the Windows Instance you want to review. 5. Make sure the instance status is running. 6. Connect to the instance using Connect using RDP. 7. Log in using the credentials you have set for this instance. 8. Open a command prompt 9. Type sconfig, and then press Enter. Windows Update Settings are at number 5 and by default are set to Automatic. If this is not the current setting continue with step 10. If this is the current setting skip to step 12 10. Type 5, and then press Enter. 11. Type A for Automatic and then press Enter. Wait until the setting is saved and you return back to the server configuration menu. 12. Type 6, and then press Enter. 13. Type A to search for (A)ll updates in the new command window, and then press Enter. 14. Type A again to install (A)ll updates, and then press Enter. When finished, you see a message with the installation results and more instructions (if those apply).",
    "profile_applicability": "•  Level 1",
    "function_names": [
      "lightsail_instance_security_patches_updated",
      "lightsail_windows_server_patches_installed",
      "lightsail_instance_updates_applied",
      "lightsail_windows_server_security_updates_current",
      "lightsail_instance_patch_compliance"
    ]
  },
  {
    "id": "5.12",
    "title": "Change the auto-generated password for Windows based instances.",
    "assessment": "Manual",
    "description": "When you create a Windows Server-based instance, Lightsail randomly generates a long password that is hard to guess. You use this password uniquely with your new instance. You can use the default password to connect quickly to your instance using remote desktop (RDP). You are always logged in as the Administrator on your Lightsail instance.",
    "rationale": "Like any password it should be changed from the default and over time. The randomly generated password can be hard to remember and if anyone gains access to your AWS Lightsail environment they can utilize that to access your instances. For this reason you should change the password to something you can remember. Impact: If you change your password from the unique, default password, be sure to use a strong password. You should avoid passwords that are based on names or dictionary words, or repeating sequences of characters.",
    "audit": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Lightsail under Compute. 3. This will open up the Lightsail console. 4. Select the Windows Instance you want to review. 5. Make sure the instance status is running. 6. Connect to the instance using Connect using RDP. 7. Log in using the credentials provided within the Lightsail console set for this instance. 8. If you are successful and based on your password change policy it is required that you change/update the password refer to the remediation below.",
    "remediation": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Lightsail under Compute. 3. This will open up the Lightsail console. 4. Select the Windows Instance you want to review. 5. Make sure the instance status is running. 6. Connect to the instance using Connect using RDP. 7. Log in using the credentials provided within the Lightsail console set for this instance. 8. Use the Windows Server password manager to change your password securely by press Ctrl + Alt + Del 9. Then choose Change a password. ** Be sure to keep a record of your password, because Lightsail doesn't store the new password you are setting. 10. Type in the New Password 11. Click Save Additional Information: You can use either the Lightsail-generated password or your own custom password with the browser-based RDP client in Lightsail. If you use a custom password, you will be prompted for your password every time you log in. It can be easier but not necessarily more secure to use the Lightsail-generated default password with the browser-based RDP client if you want quick access to your instance.",
    "profile_applicability": "•  Level 1",
    "impact": "If you change your password from the unique, default password, be sure to use a strong password. You should avoid passwords that are based on names or dictionary words, or repeating sequences of characters.",
    "function_names": [
      "compute_instance_password_changed",
      "compute_instance_default_password_rotated",
      "compute_windows_instance_admin_password_updated",
      "compute_instance_initial_password_modified",
      "compute_windows_instance_rdp_password_changed"
    ]
  },
  {
    "id": "6.1",
    "title": "Ensure you are using VPC Endpoints for source code access",
    "assessment": "Manual",
    "description": "App Runner needs access to your application source, so it can't be encrypted. Therefore, be sure to secure the connection between your development or deployment environment and App Runner.",
    "rationale": "Client-side encryption isn't a valid method for protecting the source image or code that you provide to App Runner for deployment. Using a VPC endpoint, you can privately connect your VPC to supported AWS services and VPC endpoint services that are powered by AWS PrivateLink. Note that this isn't required if you are deploying your app runner directly from an ECR image as ECR images can be independently encrypted.",
    "audit": "From the Console 1. Login to the AWS Console using https://console.aws.amazon.com/vpc/ 2. On the left hand side, click Endpoints. 3. On the Endpoints page. 4. Review all the endpoints listed under name. 5. Locate the Endpoint assigned and configured for App Runner. 6. If there is no Endpoint set for App Runner refer to the remediation below. 7. Either click the check box, Actions, View Details or click on the VPC endpoint ID. 8. Confirm these settings 1. Service name - `com.amazonaws.\"region\".apprunner` **Note - \"Region\" will reflect the region that you are operating in. 2. Status - Available 3. VPC ID - correctly associated for use with the service 4. Subnets tab - correctly associated for use with the service 5. Security Groups tab - correctly associated for use with the service 6. Policy tab - correctly configured for use with the service 9. If the settings listed above are not correct refer to the remediation below.",
    "remediation": "To create an interface endpoint for an App Runner From the Console 1. Login to the AWS Console using https://console.aws.amazon.com/vpc/ 2. On the left hand side, click Endpoints. 3. Click Create endpoint. 4. Under Service category, choose AWS services. 5. For Service name, select com.amazonaws.\"region\".apprunner. \"Region\" will reflect the region that your are operating in. 6. For VPC, select the VPC from which you'll access App Runner. 7. For Subnets, select one subnet per Availability Zone. 8. For Security group, select the security groups to associate with the App Runner endpoint network interfaces. 9. For Policy, select Custom to attach a VPC endpoint policy that controls the permissions that principals have for performing actions on resources over the VPC endpoint. 10. Click Create endpoint.",
    "profile_applicability": "•  Level 1",
    "function_names": [
      "app_runner_source_code_vpc_endpoint_enabled",
      "app_runner_source_code_private_connection_required",
      "app_runner_source_code_public_access_disabled",
      "app_runner_source_code_network_isolation_enabled",
      "app_runner_source_code_endpoint_policy_restricted",
      "app_runner_source_code_endpoint_service_configured",
      "app_runner_source_code_endpoint_security_group_attached",
      "app_runner_source_code_endpoint_subnet_assigned"
    ]
  },
  {
    "id": "8.1",
    "title": "Ensure AWS Batch is configured with AWS Cloudwatch Logs.",
    "assessment": "Manual",
    "description": "You can configure Batch jobs to send log information to CloudWatch Logs.",
    "rationale": "This enables you to view different logs from all your jobs in one convenient location.",
    "audit": "From the Console 1. Login to the AWS Console using https://console.aws.amazon.com/batch/ 2. On the left hand side under Console settings, Click on Permissions 3. Under Job logs section 4. Confirm that Authorize Batch to use Cloudwatch is set with a green check. 5. If is is showing a red X refer to the remediation below.",
    "remediation": "From the Console 1. Login to the AWS Console using https://console.aws.amazon.com/batch/. 2. In the left column under Console settings, Click on Permissions 3. In the Job logs section click on Edit 4. Click the Authorize Batch to use CloudWatch 5. Click Save",
    "profile_applicability": "•  Level 1",
    "function_names": [
      "batch_job_cloudwatch_logging_enabled",
      "batch_job_logging_destination_cloudwatch",
      "batch_job_log_stream_cloudwatch_enabled",
      "batch_job_log_group_cloudwatch_configured",
      "batch_job_log_driver_cloudwatch_enabled",
      "batch_job_log_encryption_cloudwatch_enabled"
    ]
  },
  {
    "id": "8.2",
    "title": "Ensure Batch roles are configured for cross-service confused deputy prevention",
    "assessment": "Manual",
    "description": "The Cross-service confused deputy problem is a security issue where an entity that doesn't have permission to perform an action can coerce a more-privileged entity to perform the action.",
    "rationale": "Cross-service impersonation can result in the confused deputy problem. Cross-service impersonation can occur when one service (the calling service) calls another service (the called service). The calling service can be manipulated to use its permissions to act on another customer's resources in a way it should not otherwise have permission to access. Impact: An IAM role is an identity you can create that has specific permissions with credentials that are valid for short durations. Roles can be assumed by entities that you trust. IAM Roles are often organization named and organization based. Searching for and reviewing the roles for this recommendation is a manual process.",
    "audit": "From the Console 1. Login to the AWS Console using https://console.aws.amazon.com/iam/ 2. On the left hand side under Access management, Click on Roles 3. Search for any roles related to Batch 4. Click on the role and the Assume Role Policy Document and confirm that the AssumeRole Action has a aws:SourceArn key that contains the full ARN of the Batch resource { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"batch.amazonaws.com\" }, \"Action\": \"sts:AssumeRole\", \"Condition\": { \"ArnLike\": { \"aws:SourceArn\": [ \"arn:aws:batch:us-east-1:123456789012:compute- environment/testCE\", ] } } } ] } 5. If it is showing an * within the ARN or does not have this condition key specified, then the Batch process has access to all of the resources defined in that environment. \"arn:aws:batch:us-east-1:123456789012:compute-environment/*\", { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"batch.amazonaws.com\" }, \"Action\": \"sts:AssumeRole\" } ] } 6. Repeat for any roles assigned to Batch that have AssumeRole 7. Refer to the remediation below",
    "remediation": "From the Console 1. Login to the AWS Console using https://console.aws.amazon.com/iam/ 2. On the left hand side under Access management, Click on Roles 3. Search for any roles identified above in the audit. 4. Click on the role and update the Action AssumeRole, aws:SourceArn to contain the full ARN of the resource \"aws:SourceArn\": [ \"arn:aws:batch:us-east-1:123456789012:compute- environment/testCE\", 5. Repeat for any roles defined in the Audit. References: 1. https://docs.aws.amazon.com/batch/latest/userguide/cross-service-confused- deputy-prevention.html Additional Information: Note: Usage of the aws:SourceAccount condition key can be used to prevent cross service confused deputy impersonation from external accounts. This condition key is not as specific as using aws:SourceArn which can be used to limit access of the IAM Role for specific resources or a group of specific resources. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"batch.amazonaws.com\" }, \"Action\": \"sts:AssumeRole\", \"Condition\": { \"StringEquals\": { \"aws:SourceAccount\": \"123456789012\" } } } ] }",
    "profile_applicability": "•  Level 1",
    "impact": "An IAM role is an identity you can create that has specific permissions with credentials that are valid for short durations. Roles can be assumed by entities that you trust. IAM Roles are often organization named and organization based. Searching for and reviewing the roles for this recommendation is a manual process.",
    "references": "1. https://docs.aws.amazon.com/batch/latest/userguide/cross-service-confused- deputy-prevention.html Additional Information: Note: Usage of the aws:SourceAccount condition key can be used to prevent cross service confused deputy impersonation from external accounts. This condition key is not as specific as using aws:SourceArn which can be used to limit access of the IAM Role for specific resources or a group of specific resources. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"batch.amazonaws.com\" }, \"Action\": \"sts:AssumeRole\", \"Condition\": { \"StringEquals\": { \"aws:SourceAccount\": \"123456789012\" } } } ] }",
    "function_names": [
      "batch_job_role_confused_deputy_prevention_enabled",
      "batch_job_role_cross_service_protection_enabled",
      "batch_role_confused_deputy_prevention_enabled",
      "batch_role_cross_service_protection_enabled",
      "batch_job_role_trusted_service_restriction_enabled",
      "batch_role_trusted_service_restriction_enabled"
    ]
  },
  {
    "id": "10.1",
    "title": "Ensure Managed Platform updates is configured",
    "assessment": "Manual",
    "description": "AWS Elastic Beanstalk regularly releases platform updates to provide fixes, software updates, and new features. With managed platform updates, you can configure your environment to automatically upgrade to the latest version of a platform during a scheduled maintenance window.",
    "rationale": "Your application remains in service during the update process with no reduction in capacity. Managed updates are available on both single-instance and load-balanced environments. They also ensure you aren't introducing any vulnerabilities by running legacy systems that require updates and patches.",
    "audit": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com/elasticbeanstalk 2. On the left hand side click Environments 3. Click on the Environment name that you want to review 4. Under the environment_name-env in the left column click Configuration 5. Scroll down under Configurations 6. Under category look for Managed updates 7. Confirm Managed updates: enabled 8. If status options reads Managed updates: disabled refer to the remediation below. 9. Repeat steps 3-8 for each environment within the current region. 10. Then repeat the Audit process for all other regions.",
    "remediation": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com/elasticbeanstalk 2. On the left hand side click Environments 3. Click on the Environment name that you want to update 4. Under the environment_name-env in the left column click Configuration 5. Scroll down under Configurations 6. Under category look for Managed updates 7. Click on Edit 8. On the Managed Platform Updates page Managed updates - click the Enable checkbox Weekly update window - set preferred maintenance window Update level- set it to Minor and patch Instance replacement - click the Enabled checkbox 9. Click Apply 10. Repeat steps 3-8 for each environment within the current region that needs Managed updates set. 11. Then repeat the remediation process for all other regions identified in the Audit. References: 1. https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/environment-platform- update-managed.html",
    "profile_applicability": "•  Level 1",
    "references": "1. https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/environment-platform- update-managed.html",
    "function_names": [
      "elastic_beanstalk_environment_managed_updates_enabled",
      "elastic_beanstalk_platform_auto_updates_enabled",
      "elastic_beanstalk_environment_maintenance_window_configured",
      "elastic_beanstalk_platform_version_auto_update_enabled",
      "elastic_beanstalk_environment_scheduled_updates_enabled"
    ]
  },
  {
    "id": "10.2",
    "title": "Ensure Persistent logs is setup and configured to S3",
    "assessment": "Manual",
    "description": "Elastic Beanstalk can be configured to automatically stream logs to the CloudWatch service.",
    "rationale": "With CloudWatch Logs, you can monitor and archive your Elastic Beanstalk application, system, and custom log files from Amazon EC2 instances of your environments.",
    "audit": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com/elasticbeanstalk 2. On the left hand side click Environments 3. Click on the Environment name that you want to review 4. Under the environment_name-env in the left column click Configuration 5. Scroll down under Configurations 6. Under category look for Softwares 7. Confirm Log streaming: enabled 8. If status options reads Log streaming: disabled refer to the remediation below. 9. Repeat steps 3-8 for each environment within the current region. 10. Then repeat the Audit process for all other regions.",
    "remediation": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com/elasticbeanstalk 2. On the left hand side click Environments 3. Click on the Environment name that you want to update 4. Under the environment_name-env in the left column click Configuration 5. Scroll down under Configurations 6. Under category look for Software 7. Click on Edit 8. On the Modify software page Instance log streaming to CloudWatch Logs Log streaming - click the Enabled checkbox Set the required retention based on Organization requirements Lifecycle - Keep logs after terminating environment 9. Click Apply 10. Repeat steps 3-8 for each environment within the current region that needs Managed updates set. References: 1. https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/AWSHowTo.cloudwatchl ogs.html",
    "profile_applicability": "•  Level 1",
    "references": "1. https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/AWSHowTo.cloudwatchl ogs.html",
    "function_names": [
      "elastic_beanstalk_environment_persistent_logs_enabled",
      "elastic_beanstalk_environment_logs_streaming_to_s3",
      "elastic_beanstalk_environment_cloudwatch_logs_exported",
      "elastic_beanstalk_environment_s3_logging_enabled",
      "elastic_beanstalk_environment_log_retention_configured"
    ]
  },
  {
    "id": "10.3",
    "title": "Ensure access logs are enabled.",
    "assessment": "Manual",
    "description": "When you enable load balancing, your AWS Elastic Beanstalk environment is equipped with an Elastic Load Balancing load balancer to distribute traffic among the instances in your environment",
    "rationale": "For security reasons it is important to have a record of all the access logs and this is enabled within the Load Balancer assigned to the Elastic Beanstalk environments.",
    "audit": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com/ec2 2. On the left hand scroll down to Load Balancing and click on Load Balancers 3. Click on the Load balancer associated with the Elastic Beanstalk Environment Typically they have AWSEB in the name. If you utilized Elastic Beanstalk to create the Load balancer the Source Security Group listed in the Description will reference `Elastic Beanstalk` 4. Under the Description tab scroll down to the Attributes section 5. Confirm Access logs is set to Enabled. 6. If status options reads Disabled refer to the remediation below. 7. Repeat steps 3-8 for each environment within the current region. 8. Then repeat the Audit process for all other regions.",
    "remediation": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com/ec2 2. On the left hand scroll down to Load Balancing and click on Load Balancers 3. Click on the Load balancer associated with the Elastic Beanstalk Environment Typically they have AWSEB in the name. If you utilized Elastic Beanstalk to create the Load balancer the Source Security Group listed in the Description will reference `Elastic Beanstalk~  4. Under the Description tab scroll down to the Attributes section 5. Under Access logs - Disabled click on Configure access logs. 6. Click the check box next to Enable access logs. 7. enter the se bucket name you have setup for the Elastic Beanstalk access logs. **Note - if you don't have a s3 bucket already created enter an organization name in accordance with policy and have it identify with Elastic Beanstalk. Then click the check box next to Create this location for me 8. Click Save 9. Scroll down under the description tab and confirm that the Access logs are set as described above. 10. Repeat steps 3-11 for each Load balancer created and used with Elastic Beanstalk environment within the current region. 11. Then repeat the remediation process for all other regions identified in the Audit. References: 1. https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using- features.managing.elb.html",
    "profile_applicability": "•  Level 1",
    "references": "1. https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using- features.managing.elb.html",
    "function_names": [
      "elasticbeanstalk_environment_access_logs_enabled",
      "elasticbeanstalk_load_balancer_logging_enabled",
      "elasticbeanstalk_environment_logging_enabled",
      "elasticbeanstalk_load_balancer_access_logs_enabled",
      "elasticbeanstalk_environment_load_balancer_logging_enabled"
    ]
  },
  {
    "id": "10.4",
    "title": "Ensure that HTTPS is enabled on load balancer",
    "assessment": "Manual",
    "description": "The simplest way to use HTTPS with an Elastic Beanstalk environment is to assign a server certificate to your environment's load balancer.",
    "rationale": "When you configure your load balancer to terminate HTTPS, the connection between the client and the load balancer is secure.",
    "audit": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com/elasticbeanstalk 2. On the left hand side click Environments 3. Click on the Environment name that you want to review 4. Under the \"environment_name-env\" in the left column click Configuration 5. Scroll down under Configurations 6. Under category look for Load balancer 7. Click Edit 8. Under the Listeners section 9. Check the Listeners section for any enabled listeners and make sure the Protocol is set to HTTPS and Enabled. 10. If the Listener is required for HTTP and is not set to HTTPS refer to the remediation below. 11. Repeat steps 3-10 for each environment within the current region. 12. Then repeat the Audit process for all other regions.",
    "remediation": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com/elasticbeanstalk 2. On the left hand side click Environments 3. Click on the Environment name that you want to review 4. Under the \"environment_name-env\" in the left column click Configuration 5. Scroll down under Configurations 6. Under category look for Load balancer 7. Click Edit 8. Under the Listeners section 9. Click Add listener Set listener port Set Listener protocol to HTTPS Set Instance Port Sent Instance protocol to HTTPS Select your SSL certificate 10. Click Add 11. Make sure it is listed as enabled. If you have other listeners not using HTTPS make sure to turn off enabled 12. Click Apply to save the configuration changes. 13. Repeat steps 3-12 for each environment within the current region. 14. Then repeat the remediation for all other regions. References: 1. https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/configuring-https.html",
    "profile_applicability": "•  Level 1",
    "references": "1. https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/configuring-https.html",
    "function_names": [
      "cloud_cdn_load_balancer_https_enabled",
      "compute_load_balancer_https_enabled",
      "elastic_beanstalk_load_balancer_https_enabled",
      "load_balancer_tls_enabled",
      "load_balancer_https_redirect_enabled",
      "load_balancer_ssl_certificate_attached",
      "load_balancer_secure_listener_enabled"
    ]
  },
  {
    "id": "11.1",
    "title": "Ensure customer-managed keys are used to encrypt AWS Fargate ephemeral storage data for Amazon ECS",
    "assessment": "Automated",
    "description": "Use customer-managed AWS KMS keys to encrypt AWS Fargate ephemeral storage data for on Amazon ECS, ensuring that sensitive data remains protected during task execution.",
    "rationale": "Customer-managed KMS keys offer enhanced control over encryption, including key rotation, access policies, and audit trails. Impact: There are costs and configuration overhead associated with setting up and managing customer-managed keys.",
    "audit": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Clusters. 3. Click the name of a cluster. 4. Ensure that Fargate ephemeral storage is not set to -. 5. Repeat steps 1-4 for each ECS cluster. From Command Line: Run the following command to list clusters: aws ecs list-clusters Run the following command to view the Fargate ephemeral storage KMS key ID configured for a cluster: aws ecs describe-clusters --clusters <cluster-arn> --include CONFIGURATIONS - -query 'clusters[*].configuration.managedStorageConfiguration.fargateEphemeralStorag eKmsKeyId' Ensure the command returns a customer-managed KMS key ARN. Repeat for each cluster.",
    "remediation": "From Console: 1. Login to the ECS console using https://console.aws.amazon.com/ecs/. 2. In the left panel, click Clusters. 3. Click the name of a cluster. 4. Click Update cluster. 5. Expand the Encryption section. 6. Under Fargate ephemeral storage, select a customer-managed KMS key. Note: Ensure the KMS key has appropriate Fargate service permissions. 7. Click Update. 8. Repeat steps 1-7 for each ECS cluster requiring remediation. Default Value: AWS Fargate ephemeral storage data is encrypted by default. References: 1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/fargate- storage-encryption.html 2. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/fargate-create- storage-key.html 3. https://awscli.amazonaws.com/v2/documentation/api/2.0.33/reference/ecs/list- clusters.html 4. https://awscli.amazonaws.com/v2/documentation/api/2.0.33/reference/ecs/descri be-clusters.html",
    "profile_applicability": "•  Level 2",
    "impact": "There are costs and configuration overhead associated with setting up and managing customer-managed keys.",
    "references": "1. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/fargate- storage-encryption.html 2. https://docs.aws.amazon.com/AmazonECS/latest/developerguide/fargate-create- storage-key.html 3. https://awscli.amazonaws.com/v2/documentation/api/2.0.33/reference/ecs/list- clusters.html 4. https://awscli.amazonaws.com/v2/documentation/api/2.0.33/reference/ecs/descri be-clusters.html",
    "function_names": [
      "ecs",
      "kms"
    ]
  },
  {
    "id": "12.1",
    "title": "Ensure AWS Config is Enabled for Lambda and Serverless",
    "assessment": "Manual",
    "description": "With AWS Config, you can track configuration changes to the Lambda functions (including deleted functions), runtime environments, tags, handler name, code size, memory allocation, timeout settings, and concurrency settings, along with Lambda IAM execution role, subnet, and security group associations.",
    "rationale": "This gives you a holistic view of the Lambda function’s lifecycle and enables you to surface that data for potential audit and compliance requirements.",
    "audit": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Config under Management & Governance. 3. This will open up the Config dashboard. 4. Click Conformance packs 5. Review the list of conformance packs. 6. If serverless is listed or included in the conformance pack you built you meet this recommendation. 7. If serverless is not listed refer to the remediation below 8. If none, see remediation section below. 9. Repeat steps 3-7 for all regions used.",
    "remediation": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Config under Management & Governance. 3. This will open up the Config dashboard. 4. Click Conformance packs 5. Click on Deploy conformance pack 6. Click on Use sample template 7. Click the down arrow under Sample template 8. Scroll down and click on Operational Best Practices for Serverless 9. Click Next 10. Give it a Conformance pack name Serverless. 11. Click Next 12. Click Deploy conformance pack 13. Click on Deploy conformance pack 14. Click on Use sample template 15. Click the down arrow under Sample template 16. Scroll down and click on Security Best Practices for Lambda 17. Click Next 18. Give it a Conformance pack name LambaSecurity. 19. Click Next 20. Click Deploy conformance pack 21. Repeat steps 2-20 for all regions used. References: 1. https://docs.aws.amazon.com/lambda/latest/dg/welcome.html",
    "profile_applicability": "•  Level 2",
    "references": "1. https://docs.aws.amazon.com/lambda/latest/dg/welcome.html",
    "function_names": [
      "config_lambda_tracking_enabled",
      "config_serverless_tracking_enabled",
      "config_lambda_configuration_logging_enabled",
      "config_serverless_configuration_logging_enabled",
      "config_lambda_resource_changes_monitored",
      "config_serverless_resource_changes_monitored",
      "config_lambda_execution_role_logging_enabled",
      "config_serverless_execution_role_logging_enabled",
      "config_lambda_network_settings_logging_enabled",
      "config_serverless_network_settings_logging_enabled"
    ]
  },
  {
    "id": "12.2",
    "title": "Ensure Cloudwatch Lambda insights is enabled",
    "assessment": "Manual",
    "description": "Ensure that Amazon CloudWatch Lambda Insights is enabled for your Amazon Lambda functions for enhanced monitoring.",
    "rationale": "Amazon CloudWatch Lambda Insights allows you to monitor, troubleshoot, and optimize your Lambda functions. The service collects system-level metrics and summarizes diagnostic information to help you identify issues with your Lambda functions and resolve them as soon as possible. CloudWatch Lambda Insights collects system-level metrics and emits a single performance log event for every invocation of that Lambda function.",
    "audit": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com/lambda/ 2. Click Functions. 3. Click on the name of the function. 4. Click on the Configuration tab 5. Click on 'Monitoring and operations tools'. 6. In the Monitoring and operations tools section check the Enhanced monitoring 7. If set to Not enabled, refer to the remediation below. 8. Repeat steps 2-7 for each Lambda function within the current region. 9. Then repeat the Audit process for all other regions. From the Command Line 1. Run aws lambda list-functions aws lambda list-functions --output table --query \"Functions[*].FunctionName\" This command will provide a table titled ListFunction 2. Run aws lambda get-function aws lambda get-function --function-name \"name_of_function\" --query \"'Configuration.Layers[*].Arn\" This command should provide the requested ARN 3. If the list of ARNs does not contain the CloudWatch Lambda Insights extension ARN, i.e. \"arn:aws:lambda:<aws- region>:12345678910:layer:LambdaInsightsExtension:<version>\", the Enhanced Monitoring feature is not enabled.  Refer to the remediation below.",
    "remediation": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com/lambda/ 2. Click Functions. 3. Click on the name of the function. 4. Click on the Configuration tab 5. Click on 'Monitoring and operations tools'. 6. In the Monitoring and operations tools section click Edit to update the monitoring configuration 7. In the CloudWatch Lambda Insights section click the Enhanced monitoring button to enable ***Note - When you enable the feature using the AWS Management Console, Amazon Lambda adds the required permissions to your function's execution role. 8. Click Save 9. Repeat steps 2-8 for each Lambda function within the current region that fails the Audit. 10. Then repeat the Audit process for all other regions.",
    "profile_applicability": "•  Level 1",
    "function_names": [
      "lambda",
      "cloudwatch",
      "lambda"
    ]
  },
  {
    "id": "12.3",
    "title": "Ensure AWS Secrets manager is configured and being used by Lambda for databases",
    "assessment": "Manual",
    "description": "Lambda functions often have to access a database or other services within your environment.",
    "rationale": "Credentials used to access databases and other AWS Services need to be managed and regularly rotated to keep access into critical systems secure. Keeping any credentials and manually updating the passwords would be cumbersome, but AWS Secrets Manager allows you to manage and rotate passwords. Impact: note - Lambda code should be checked for correct configuration to get the credentials from AWS Secrets Manager. This audit and remediation is only to confirm you have the credentials in Secrets manager.",
    "audit": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Secrets Manager under Security, Identity and Compliance. 3. Click on Secrets. 4. Review the secrets listed 5. Confirm that the secret required for Lambda functions is included in the list. 6. If it is, review your code and confirm that you are calling the credentials during runtime. 7. If the credentials are not listed refer to the remediation below. 8. Repeat steps 2-7 for all regions used.",
    "remediation": "From the Console: 1. Login to AWS Console using https://console.aws.amazon.com 2. Click All services, click Secrets Manager under Security, Identity and Compliance. 3. Click on Secrets. 4. Click on Store a new secret 5. Select the Secret type 6. Enter the information For the `3 db types` listed enter the credentials and select the database. For `other database` enter the credentials, select the db type and enter the connection parameters. For Other type of secret (Lambda) create the keys and values used. - example Username yepyep Password yepyep choose an encryption key or create a new one if you add a new key it will take you to the KMS console. Once you create the new key you can then select it here. 7. Click Next 8. Give the secret a name associated with your organization style and lambda 9. Click Next 10. Configure the auto rotation Rotation schedule leave as default Select the lambda function you use to rotate the key 11. Click Next 12. Review all the settings 13. Click Store References: 1. https://aws.amazon.com/blogs/security/how-to-securely-provide-database- credentials-to-lambda-functions-by-using-aws-secrets-manager/ 2. https://docs.aws.amazon.com/lambda/latest/dg/welcome.html",
    "profile_applicability": "•  Level 1",
    "impact": "note - Lambda code should be checked for correct configuration to get the credentials from AWS Secrets Manager. This audit and remediation is only to confirm you have the credentials in Secrets manager.",
    "references": "1. https://aws.amazon.com/blogs/security/how-to-securely-provide-database- credentials-to-lambda-functions-by-using-aws-secrets-manager/ 2. https://docs.aws.amazon.com/lambda/latest/dg/welcome.html",
    "function_names": [
      "secrets_manager_secret_lambda_rotation_enabled",
      "lambda",
      "secrets_manager_secret_encryption_enabled",
      "lambda",
      "secrets_manager_secret_min_rotation_frequency",
      "lambda_function_vpc_config_secure",
      "secrets_manager_secret_access_restricted",
      "secrets_manager_secret_versioning_enabled"
    ]
  },
  {
    "id": "12.4",
    "title": "Ensure least privilege is used with Lambda function access",
    "assessment": "Manual",
    "description": "Lambda is fully integrated with IAM, allowing you to control precisely what each Lambda function can do within the AWS Cloud. As you develop a Lambda function, you expand the scope of this policy to enable access to other resources. For example, for a function that processes objects put into an S3 bucket, it requires read access to objects stored in that bucket. Do not grant the function broader permissions to write or delete data, or operate in other buckets.",
    "rationale": "You can use AWS Identity and Access Management (IAM) to manage access to the Lambda API and resources like functions and layers. For users and applications in your account that use Lambda, you manage permissions in a permissions policy that you can apply to IAM users, groups, or roles. To grant permissions to other accounts or AWS services that use your Lambda resources, you use a policy that applies to the resource itself.",
    "audit": "Determining the exact permissions required is a manual process and can be challenging, since IAM permissions are very granular and they control access to both the data plane and control plane. Please refer to the references section below for useful documentation on developing the correct IAM policies for Lambda.",
    "remediation": "As building out the IAM permissions for Lambda here are some things to consider. • Set granular IAM permissions for Lambda functions. • Limit user access via IAM permissions to only necessary resources and operations. • Remove unused or outdated IAM Users, Roles and Permissions. • Periodically review and adjust IAM permissions. • Do not allow all-access permissions for Lambda functions as a short cut.\" References: 1. https://docs.aws.amazon.com/service- authorization/latest/reference/reference_policies_actions-resources- contextkeys.html 2. https://awspolicygen.s3.amazonaws.com/policygen.html 3. https://policysim.aws.amazon.com/home/index.jsp?# 4. https://github.com/aws-samples/aws-iamctl/ 5. https://docs.aws.amazon.com/lambda/latest/operatorguide/least-privilege- iam.html",
    "profile_applicability": "•  Level 1",
    "references": "1. https://docs.aws.amazon.com/service- authorization/latest/reference/reference_policies_actions-resources- contextkeys.html 2. https://awspolicygen.s3.amazonaws.com/policygen.html 3. https://policysim.aws.amazon.com/home/index.jsp?# 4. https://github.com/aws-samples/aws-iamctl/ 5. https://docs.aws.amazon.com/lambda/latest/operatorguide/least-privilege- iam.html",
    "function_names": [
      "lambda",
      "lambda_function_iam_policy_restricted",
      "lambda_function_s3_read_only",
      "lambda_function_no_broad_bucket_access"
    ]
  },
  {
    "id": "12.5",
    "title": "Ensure every Lambda function has its own IAM Role",
    "assessment": "Manual",
    "description": "Every Lambda function should have a one to one IAM execution role and the roles should not be shared between functions.",
    "rationale": "The Principle of Least Privilege means that any Lambda function should have the minimal amount of access required to perform its tasks. In order to accomplish this Lambda functions should not share IAM Execution roles.",
    "audit": "From the Console 1. Login to the AWS console using https://console.aws.amazon.com/lambda/ 2. In the left column, under AWS Lambda, click Functions. 3. Under Function name click on the name of the function that you want to review. 4. Click the Configuration tab 5. Under General configuration on the left column, click Permissions. 6. Under the Execution role section, Role name not the name listed as this is the IAM is the role that defines the access permissions for the selected function. 7. Repeat steps 2 – 6 for all the Lambda functions listed within the AWS region. 8. If any Lambda functions share the same Execution role, refer to the remediation below. 9. Repeat this Audit for all the AWS Regions.",
    "remediation": "From the Console 1. Login to the AWS console using https://console.aws.amazon.com/lambda/ 2. In the left column, under AWS Lambda, click Functions. 3. Under Function name click on the name of the function that you want to change/update. 4. Click the Configuration tab 5. Under General configuration on the left column, click Permissions. 6. Under the Execution role section, click Edit. 7. Scroll down to Execution role To use an existing IAM role - Click `Use an existing role` - Select the role from the `Existing role` dropdown. - The IAM role can't be associated with another Lambda function and must follow the Principle of Least Privilege. To use a new IAM role - Click `Create a new role from AWS policy templates` - Provide a unique name based on company policy in the `Role name` - Select the policy templates from the `Policy templates` dropdown. 8. Click Save 9. Repeat steps 2 – 8 for all the Lambda functions listed within the AWS region that do not have a unique IAM Execution Role. 10. Repeat this remediation process for all the AWS Regions.",
    "profile_applicability": "•  Level 1",
    "function_names": [
      "lambda_function_unique_iam_role",
      "lambda",
      "iam_role_lambda_function_one_to_one",
      "iam_role_lambda_exclusive_assignment"
    ]
  },
  {
    "id": "12.6",
    "title": "Ensure Lambda functions are not exposed to everyone.",
    "assessment": "Manual",
    "description": "A publicly accessible Amazon Lambda function is open to the public and can be reviewed by anyone. To protect against unauthorized users that are sending requests to invoke these functions they need to be changed so they are not exposed to the public.",
    "rationale": "Allowing anyone to invoke and run your Amazon Lambda functions can lead to data exposure, data loss, and unexpected charges on your AWS bill.",
    "audit": "From the Console 1. Login to the AWS Console using https://console.aws.amazon.com/lambda/. 2. In the left column, under AWS Lambda, click Functions. 3. Under Function name click on the name of the function that you want to review 4. Click the Configuration tab 5. In the left column, click Permissions. 6. In the Resource-based policy section, click View policy document 7. Review the Resource-based policy document box. Find the \"Principal\" element defined for each policy statement and check the element value. If the element has one of the following values: \" \" or { \"AWS\": \" \" }, it means it is set to \"Allow\", and if it does not contain a \"Condition\" clause to filter the access, the selected Amazon Lambda function is set to anonymous access. 8. If any of the Lambda functions have anonymous access set refer to the remediation below. 9. Repeat steps 2 – 7 for each Lambda function available within the current AWS region. 10. Repeat this Audit for all the other AWS regions. From the Command line 1. Run 'aws lambda list-functions' aws lambda list-functions --output table --query \"Functions[*].FunctionName\" This command will provide a table titles ListFunctions  2. Run aws lambda get-policy aws lambda get-policy --function-name \"name_of_function\" --output text -- query \"Policy\" This will provide an output of the policy assigned to that function. 3. Find the \"Principal\" element defined for that function. If the element has one of the following values: \" \" or { \"AWS\": \" \" }, it means it is set to \"Allow\", and if it does not contain a \"Condition\" clause to filter the access, the selected Amazon Lambda function is set to anonymous access. 4. Make note of the Function name from step 1 and the Statement name from step 2 and refer to the remediation steps below. 5. Repeat steps 1 – 3 for each Lambda function listed within the current region. 6. Repeat this Audit for all the other AWS regions.",
    "remediation": "From the Console 1. Login to the AWS Console using https://console.aws.amazon.com/lambda/. 2. In the left column, under AWS Lambda, click Functions. 3. Under Function name click on the name of the function that you want to review 4. Click the Configuration tab 5. In the left column, click Permissions. 6. In the Resource-based policy section, perform the following actions: • Under Policy statements • Select the policy statement that allows anonymous access • Click Delete to remove the non-compliant statement from the resource-based policy attached • Within the Delete statement confirmation box, click Remove • Click Add permissions to add a new policy statement that grants permissions to a trusted entity only. • On the Add permissions page configure the new policy statement to grant access to another AWS account, IAM user, IAM role, or to another AWS service. • Click Save 7. Repeat steps no. 2 – 6 for each Lambda function that fails the Audit above, within the current region. 8. Repeat this Audit for all the other AWS regions.  From the Command line 1. Run 'aws lambda remove-permission' aws lambda remove-permission --function-name \"name_of_function\" --statement- id \"SID_of_Statement\" This command will remove the access policy that is failing the audit for that function. 2. Run aws lambda add-permission aws lambda add-permission --function-name \"name_of_function\" --statement-id \"correctaccess\" --principal \"012345678910\" --action lambda:InvokeFunction This adds a new policy to the function. ***Note The --principal parameter can be the The ID of the trusted AWS account, another AWS account, IAM user, IAM role, or another AWS service. 3. The command output should display the new policy created. 4. Repeat steps 1-2 for each Lambda function from the audit for all regions. References: 1. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/lambda/ind ex.html",
    "profile_applicability": "•  Level 1",
    "references": "1. https://awscli.amazonaws.com/v2/documentation/api/latest/reference/lambda/ind ex.html",
    "function_names": [
      "lambda",
      "lambda",
      "lambda"
    ]
  },
  {
    "id": "12.7",
    "title": "Ensure Lambda functions are referencing active execution roles.",
    "assessment": "Manual",
    "description": "In order to have the necessary permissions to access the AWS cloud services and resources Amazon Lambda functions should be associated with active(available) execution roles.",
    "rationale": "A Lambda function's execution role is an Identity and Access Management (IAM) role that grants the function permission to process and access specific AWS services and resources. When Amazon Lambda functions are not referencing active execution roles, the functions are losing the ability to perform critical operations securely.",
    "audit": "From the Console 1. Login to the AWS Console using https://console.aws.amazon.com/lambda/. 2. In the left column, under AWS Lambda, click Functions. 3. Under Function name click on the name of the function that you want to review 4. Click the Configuration tab 5. In the left column, click Permissions. 6. In the Resource summary section, if it reads \"The role with name <role_name> cannot be found. (Service: LambdaConsole; Status Code: 404; Error Code: NoSuchEntity; Request ID: e3f12a73-2988-4dd5-b2d1-237c800a27f4; Proxy: null) refer to the remediation below. 7. Repeat steps 2 – 6 for each Lambda function available within the current AWS region. 8. Repeat this Audit for all the other AWS regions. From the Command line 1. Run aws lambda list-functions aws lambda list-functions --output table --query \"Functions[*].FunctionName\" This command will provide a table titled ListFunctions  2. Run aws lambda get-function aws lambda get-function --function-name \"name_of_function\" --query \"Configuration.Role\" This will provide an output returning the role ARN assigned to that function. 3. Run aws lambda get-role aws iam get-role --role-name \"name_of_role\" This will return the requested configuration information. 4. The command output should return the requested configuration information: 5. If the command output returns a An error occurred (NoSuchEntity) when calling the GetRole operation error message instead of the role's configuration, the execution role associated with the selected Lambda function is no longer available. Refer to the remediation below. 6. Repeat steps 1-5 for each Lambda function available in the selected AWS region. Perform the Audit process for other regions.",
    "remediation": "From the Console 1. Login to the AWS Console using https://console.aws.amazon.com/lambda/. 2. In the left column, under AWS Lambda, click Functions. 3. Under Function name click on the name of the function that you want to update. 4. Click the Configuration tab 5. In the left column, click Permissions. 6. In the Execution role section, click Edit 7. In the Edit basic settings page, perform one of the following actions: - Click Use an existing role if you already a execution role for the selected Lambda function. - Select the IAM role from the `Existing role` dropdown list. - Click Save. Or - Click To create a custom role, go to the `IAM console`. - Click AWS Service - Click `Lambda`. - Click `Next: Permissions - Attach the permission policies needed - Click Next: Tags - Add tags (optional) based on your Organizational policy - Click Next: Review - Enter a Role name and a Role description so you can attach the policy to the Lambda function - Click `Create role` - Refresh the Edit basic settings page - Select the new IAM role you just created from the `Existing role` dropdown list. - Click Save. 8. Repeat steps 2 – 7 to update the execution role for each misconfigured Amazon Lambda function within the current AWS region. 9. Repeat this Audit for all the other AWS regions.",
    "profile_applicability": "•  Level 1",
    "function_names": [
      "lambda"
    ]
  },
  {
    "id": "12.8",
    "title": "Ensure that Code Signing is enabled for Lambda functions.",
    "assessment": "Manual",
    "description": "Ensure that all your Amazon Lambda functions are configured to use the Code Signing feature in order to restrict the deployment of unverified code.",
    "rationale": "Code Signing, ensures that the function code is signed by an approved (trusted) source, and that it has not been altered since signing, and that the code signature has not expired or been revoked.",
    "audit": "From the Console 1. Login to the AWS console using https://console.aws.amazon.com/lambda/ 2. In the left column, under AWS Lambda, click Functions. 3. Under Function name click on the name of the function that you want to review. 4. Click the Configuration tab 5. Under General configuration on the left column, click Code signing. 6. Under the Code signing configuration section check for any code signing configurations created for the function. 7. If there are no code signing configurations available or listed is not enabled, refer to the remediation 8. Repeat steps 2-7 for each Lambda function within the current region. 9. Then repeat the Audit process for all other regions. From the Command Line 1. Run aws lambda list-functions aws lambda list-functions --output table --query \"Functions[*].FunctionName\" This command will provide a table titled ListFunctions 2. Run aws lambda get-function-code-signing-config aws lambda get-function-code-signing-config --function-name \"name_of_function\" --query \"CodeSigningConfigArn\" 3. The command output should return an array with the requested ARN(s) 4. If the get-function-code-signing-config command output returns null, there are no code signing configurations for the Lambda function. 5. Refer to the remediation below. 6. Repeat step 2-5 for each Lambda function available in the selected AWS region. 7. Perform the Audit process for all other regions used.",
    "remediation": "From the Console 1. Login to the AWS console using https://console.aws.amazon.com/signer 2. Click on Create Signing Profile if none are set up. If you already have some created in the left panel click on Signing Profiles, Create Signing Profile. ***Note a Signing Profile is a trusted publisher and is analogous to the use of a digital signing certificate to generate signatures for your application code. 3. On the Create Signing Profile setup page provide Profile name Specify the Signature Validity period (6 months up to 12 months is recomended) 4. Click on Create Profile 5. Go to the Amazon Lambda console https://console.aws.amazon.com/lambda/. 6. In the left panel, under Additional resources, click on Code signing configurations. 7. Click on Create configuration 8. On the Create code signing configuration setup page: • Description box - provide a short description to identify this configuration • Click inside the Signing profile version ARN box and select the Signing Profile created above. • For Signature validation policy, click the signature validation policy suitable for your Lambda function. **Note - A signature check can fail if the code is not signed by an allowed Signing Profile, or if the signature has expired or has been revoked. • Click Enforce – blocking the deployment of the code and also issue a warning. • Click Create configuration  9. Go to the Amazon Lambda console https://console.aws.amazon.com/lambda/. 10. Click Functions. 11. Under Function name click on the name of the function that you want to review 12. Click the Configuration tab 13. In the left menu click Code signing. 14. Click Edit 15. On the Edit code signing, select the code signing configuration created above from the drop down 16. Click Save The Lambda function is now configured to use code signing. 17. Next Upload a signed .zip file or provide an S3 URL of a signed .zip made by a signing job in AWS Signer. 18. To start a signing job, go to AWS Signer console at https://console.aws.amazon.com/signer. 19. In the left panel, click on Signing Jobs. 20. Start a Signing Job to generate a signature for your code package and place the signed code package in the specified destination path. 21. Start Signing Job setup page: - Select the Signing Profile created in dropdown list. - Code asset source location, specify the Amazon S3 location of the code package (.zip file) to be signed. Only S3 buckets available in the current region are displayed and can be used - Signature destination path with prefix where the signed code package should be uploaded. - Start Job to deploy your new Signing Job - Job status reads Succeeded, you can find the signed .zip package in your assigned S3 bucket. 22. Publish the signed code package to the selected Lambda function. 23. Amazon Lambda will perform signature checks to verify that the code has not been altered since signing **Note - The service verifies if the code is signed by one of the allowed signing profiles available. 24. Repeat steps for each Lambda function that was captured in the Audit.",
    "profile_applicability": "•  Level 1",
    "function_names": [
      "lambda"
    ]
  },
  {
    "id": "12.9",
    "title": "Ensure there are no Lambda functions with admin privileges within your AWS account",
    "assessment": "Manual",
    "description": "Ensure that your Amazon Lambda functions don't have administrative permissions potentially giving the function access to all AWS cloud services and resources.",
    "rationale": "In order to promote the Principle of Least Privilege (POLP) and provide your functions the minimal amount of access required to perform their tasks the right IAM execution role associated with the function should be used. Instead of providing administrative permissions you should grant the role the necessary permissions that the function really needs.",
    "audit": "From the Console 1. Login in to the AWS Console using https://console.aws.amazon.com/lambda/ 2. In the left column, under AWS Lambda, click Functions. 3. Under Function name click on the name of the function that you want to review 4. Click the Configuration tab 5. Click on Permissions in the left column. 6. In the Execution role section, click the Role name to access the IAM role details. **Note this will bring you to the IAM Console. 7. Select the Permissions tab to view the identity–based policies attached 8. In the Permissions policies section click on the Policy name. 9. Select the Permissions tab. **Note The policy summary should show below in JSON format. 10. Within the {} JSON policy, identify the \"Action\" element defined for each statement and check the value. 11. If any of the \"Action\" element values are set to \"*\" and the \"Effect\" element is set to \"Allow\", the role policy provides access to all the supported AWS cloud services and resources. 12. Repeat this step for each IAM policy attached to the selected execution role. If one or more policies allow access to all AWS services and resources, the execution role provides administrative permissions. Refer to the remediation below. Repeat steps for each Lambda function within the current region. Then repeat the Audit process for all other regions.",
    "remediation": "From the Console 1. Login in to the AWS Console using https://console.aws.amazon.com/lambda/ 2. In the left column, under AWS Lambda, click Functions. 3. Under Function name click on the name of the function that you want to remediate 4. Click the Configuration tab 5. Click on Permissions in the left column. 6. In the Execution role section, click the Edit 7. Edit basic settings configuration page: - associate the function with an existing, compliant IAM role - click Use an existing role from the Execution role - select the required role from the Existing role dropdown - click Save OR - apply a new execution role to your Lambda function - click Create a new role from AWS policy templates - Provide a name for the new role based on org policy - select only the necessary permission set(s) from the Policy templates - optional dropdown list. - click Save 8. Repeat steps for each Lambda function within the current region that failed the Audit.",
    "profile_applicability": "•  Level 1",
    "function_names": [
      "lambda",
      "lambda_function_iam_role_restricted",
      "lambda_function_restrict_iam_role"
    ]
  },
  {
    "id": "12.10",
    "title": "Ensure Lambda functions do not allow unknown cross account access via permission policies.",
    "assessment": "Manual",
    "description": "Ensure that all your Amazon Lambda functions are configured to allow access only to trusted AWS accounts in order to protect against unauthorized cross-account access.",
    "rationale": "Allowing unknown (unauthorized) AWS accounts to invoke your Amazon Lambda functions can lead to data exposure and data loss. To prevent any unauthorized invocation requests for your Lambda functions, restrict access only to trusted AWS accounts.",
    "audit": "From the Console 1. Login to the AWS Console using https://console.aws.amazon.com/lambda/. 2. In the left column, under AWS Lambda, click Functions. 3. Under Function name click on the name of the function that you want to review 4. Click the Configuration tab 5. In the left column, click Permissions. 6. In the Resource-based policy statements section, click View policy document 7. Review the Resource-based policy document box. Find the \"Principal\" element and check the element value (ARN). 8. Confirm that each AWS account ARN is an approved AWS account. If one or more of the ARNs is not an AWS account defined within your organization, refer to the remediation below. 9. Repeat steps no. 2-8 for each Lambda function available within the current AWS region. 10. Repeat this Audit for all the other AWS regions. From the Command Line 1 Run aws lambda list-functions aws lambda list-functions --output table --query \"Functions[*].FunctionName\" 2 This command will provide a table titled ListFunctions 3 Run aws lambda get-policy on the functions listed aws lambda get-policy --function-name \"name_of_function\" --output text -- query \"Policy\" 4. This will provide an output of the policy assigned to that function. 5. Identify the \"Principal\" element for each function for the ARN. 6. Confirm that each AWS account ARN is an approved AWS account. If one or more of the ARNs is not an AWS account defined within your organization, refer to the remediation below. 7. Repeat steps 2–5 for each Lambda function available. 8. Run the Audit in the other AWS cloud regions",
    "remediation": "From the Console 1. Login to the AWS Console using https://console.aws.amazon.com/lambda/. 2. In the left column, under AWS Lambda, click Functions. 3. Under Function name click on the name of the function that you want to review 4. Click the Configuration tab 5. In the left column, click Permissions. 6. In the Resource-based policy statements section, select the policy statement that allows the unknown AWS Account cross-account access 7. Click Edit 8. On the Edit permissions page, replace or remove the AWS Account(s) ARN of the unauthorized principal in the Principal box 9. Click Save 10. Repeat steps for each Lambda function that failed the Audit",
    "profile_applicability": "•  Level 1",
    "function_names": [
      "lambda",
      "lambda"
    ]
  },
  {
    "id": "12.11",
    "title": "Ensure that the runtime environment versions used for your Lambda functions do not have end of support dates.",
    "assessment": "Manual",
    "description": "Always using a recent version of the execution environment configured for your Amazon Lambda functions adheres to best practices for the newest software features, the latest security patches and bug fixes, and performance and reliability.",
    "rationale": "When you execute your Lambda functions using recent versions of the implemented runtime environment, you should benefit from new features and enhancements, better security, along with performance and reliability.",
    "audit": "From the Console 1. Login to the AWS Console using https://console.aws.amazon.com/lambda/. 2. In the left column, under AWS Lambda, click Functions. 3. Under Function name click on the name of the function that you want to review 4. Click Code tab 5. In the Runtime settings section, check the Runtime attribute value to determine the runtime version. 6. Compare the function runtime with the updated list of Amazon Lambda runtimes. Link is in the resource section 7. If the version you are using is not the latest or is on the EOL list, the selected Amazon Lambda function is using an old and deprecated runtime environment. 8. Refer to the remediation below. 9. Repeat steps 2-6 for each Lambda function within the current region. Then repeat the Audit process for all other regions. From the Command Line 1. Run aws lambda list-functions aws lambda list-functions --output table --query 'Functions[*].FunctionName' This command will provide a table titled ListFunctions  2. Run aws lambda get-function-configuration using the Function names returned in the table. aws lambda get-function-configuration --function-name \"name_of_fuunction\" -- query 'Runtime'  3. The command output should return the execution environment 4. Compare the function runtime with the updated list of Amazon Lambda runtimes. Link is in the resource section 5. If the version you are using is not the latest or is on the EOL list, the selected Amazon Lambda function is using an old and deprecated runtime environment. 6. Refer to the remediation below.",
    "remediation": "From the Console 1. Login to the AWS Console using https://console.aws.amazon.com/lambda/. 2. In the left column, under AWS Lambda, click Functions. 3. Under Function name click on the name of the function that you want to review 4. Click Code tab 5. Go to the Runtime settings section. 6. Click Edit 7. On the Edit runtime settings page, select the latest supported version of the runtime environment from the dropdown list. **Note - make sure the correct architecture is also selected. 8. Click Save 9. Select the Code tab 10. Click Test from the Code source section. 11. Once the testing is completed, the execution result of your Lambda function will be listed 12. Repeat steps for each Lambda function that failed the Audit within the current region. From the Command Line 1. Run aws lambda update-function-configuration using the name of the Function you need to remediate aws lambda update-function-configuration --output table --query 'Functions[*].FunctionName' This command will provide a table titled ListFunctions  2. Run aws lambda get-function-configuration using the Function names returned in the table. aws lambda get-function-configuration --function-name \"name_of_fuunction\" -- function-name \"name_of_function\" --runtime \"python3.9\" 3. The command output should return the metadata available for the reconfigured function. 4. Repeat steps 1-2 to upgrade the runtime environment for each Amazon Lambda function found in the Audit. References: 1. https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtimes.html",
    "profile_applicability": "•  Level 1",
    "references": "1. https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtimes.html",
    "function_names": [
      "lambda"
    ]
  },
  {
    "id": "12.12",
    "title": "Ensure encryption in transit is enabled for Lambda environment variables",
    "assessment": "Manual",
    "description": "As you can set your own environmental variables for Lambda it is important to also encrypt them for in transit protection.",
    "rationale": "Lambda environment variables should be encrypted in transit for client-side protection as they can store sensitive information.",
    "audit": "From the Console 1. Login to the AWS Console using https://console.aws.amazon.com/lambda/. 2. In the left column, under AWS Lambda, click Functions. 3. Under Function name click on the name of the function that you want to review 4. Click the Configuration tab 5. In the left column, click Environment variables. 6. In the Environment variables section, click Edit 7. On the Edit environment variables page, review the Values. If they are a long value that resembles this: AQICAHhxbKJYcFAU16CbU4IVpzi5CwK Encryption is in place for that Key. If the value is in plain text refer to the remediation below. 8. Repeat steps 2 – 7 for each Lambda function available within the current AWS region. 9. Repeat this Audit for all the other AWS regions. From the Command line 1. Run 'aws lambda list-functions' aws lambda list-functions --output table --query \"Functions[*].FunctionName\" This command will provide a table titled ListFunctions  2. Run aws lambda get-function aws lambda get-function --function-name \"name_of_function\" --query \"Configuration.Environment\" This will provide an output of the environment variables created for that function. 3. Review the Values in the table. If they contain a long value that resembles this: AQICAHhxbKJYcFAU16CbU4IVpzi5CwK. Encryption is in place for that Key. If the value is in plain text refer to the remediation below. 4. Repeat steps 1 – 3 for each Lambda function listed within the current region. 5. Repeat this Audit for all the other AWS regions.",
    "remediation": "From the Console 1. Login to the AWS Console using https://console.aws.amazon.com/lambda/. 2. In the left column, under AWS Lambda, click Functions. 3. Under Function name click on the name of the function that you want to review 4. Click the Configuration tab 5. In the left column, click Environment variables. 6. In the Environment variables section, click Edit 7. Click the check box for Enable helpers for encryption in transit 8. Click the Encrypt option for all the variable that need to be encrypted. 9. Repeat steps 2 – 8 for each Lambda function identified in the Audit within the current AWS region. 10. Repeat this remediation for all the other AWS regions.",
    "profile_applicability": "•  Level 1",
    "function_names": [
      "lambda"
    ]
  },
  {
    "id": "16.1",
    "title": "Ensure communications between your applications and clients is encrypted.",
    "assessment": "Manual",
    "description": "SimSpace Weaver doesn't manage communications between your apps and the clients.",
    "rationale": "Be sure to implement some form of authentication and encryption for all client sessions while using SimSpace Weaver.",
    "audit": "There is no setting for encryption setup for your clients and applications within SimSpace Weaver service. For this audit you have to confirm that the communication is configured in the app and the client with encryption to protect that traffic.",
    "remediation": "Confirm that the communication you have configured between you application and clients that run inside of SimSpace Weaver are encrypted. References: 1. https://docs.aws.amazon.com/simspaceweaver/latest/userguide/security_best- practices.html",
    "profile_applicability": "•  Level 1",
    "references": "1. https://docs.aws.amazon.com/simspaceweaver/latest/userguide/security_best- practices.html",
    "function_names": [
      "cloudfront",
      "compute_load_balancer_https_redirect_enabled",
      "compute_load_balancer_https_enabled",
      "network_ssl_certificate_valid",
      "network_ssl_certificate_not_expired",
      "network_ssl_certificate_trusted_ca",
      "application_api_endpoint_https_enabled"
    ]
  }
]